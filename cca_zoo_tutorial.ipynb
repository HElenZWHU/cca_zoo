{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cca-zoo-tutorial.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO/crxmhCnicA+3BiPg789j",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "584fdc4d944e404fbec98f86efa75312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ac19664456264647bbeca68ddc6655ef",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1b991f2f67f64cb5b7bf731525b395fb",
              "IPY_MODEL_32dca46dccaa463a960c9a2126e4db7c"
            ]
          }
        },
        "ac19664456264647bbeca68ddc6655ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b991f2f67f64cb5b7bf731525b395fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_908c393d151947178361f62ee2ff25f4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6d5a9c430115476a9e6ead3714c1c7a7"
          }
        },
        "32dca46dccaa463a960c9a2126e4db7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_695402ab55b84c41a0a77fbc7c4dc085",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 26427392/? [00:20&lt;00:00, 9566950.97it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_27a8cdbc24194b3f99e7565e0a4f1c1a"
          }
        },
        "908c393d151947178361f62ee2ff25f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6d5a9c430115476a9e6ead3714c1c7a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "695402ab55b84c41a0a77fbc7c4dc085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "27a8cdbc24194b3f99e7565e0a4f1c1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b65f75d69ebe4a1ca9af518fb50670a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_46b3f939e4194d04862132acf42acaf1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_770a949cb5fd48d6b42bffe5e4847517",
              "IPY_MODEL_7bcf70c62b8645f5986cfa209496ccbc"
            ]
          }
        },
        "46b3f939e4194d04862132acf42acaf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "770a949cb5fd48d6b42bffe5e4847517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d9d6c364d6fa49f1ac8f7f4d92e74708",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_725d935fe83f4bdaa64ab54cf3eb41a6"
          }
        },
        "7bcf70c62b8645f5986cfa209496ccbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e899c58bcdc94dbe9a333c7824aa5d08",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 32768/? [00:00&lt;00:00, 76631.06it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_81df0d8444484c5cb6b7a4d91ace7bca"
          }
        },
        "d9d6c364d6fa49f1ac8f7f4d92e74708": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "725d935fe83f4bdaa64ab54cf3eb41a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e899c58bcdc94dbe9a333c7824aa5d08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "81df0d8444484c5cb6b7a4d91ace7bca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "548bca106df645758186afe18256d8b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_68bfdd43b87f4a2db88751939265abff",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_632ba899fe1b4476aca03b690a8b24fd",
              "IPY_MODEL_0aa017a592504a79a2b80a021eb63794"
            ]
          }
        },
        "68bfdd43b87f4a2db88751939265abff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "632ba899fe1b4476aca03b690a8b24fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f945cc7ff46c449aabc7341b768d53c5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b3fe9588b98546769319592f64ec13bb"
          }
        },
        "0aa017a592504a79a2b80a021eb63794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_77d42ba4336745c2ba4f62d37c889adc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4423680/? [00:17&lt;00:00, 1433246.23it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2ce2aaef57924614b61f4e63b6518f0f"
          }
        },
        "f945cc7ff46c449aabc7341b768d53c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b3fe9588b98546769319592f64ec13bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "77d42ba4336745c2ba4f62d37c889adc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2ce2aaef57924614b61f4e63b6518f0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa8326acc52446cdbb165a14611ddac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_afa54ba134b147c0acd5257c8d2c0038",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d1d0dbba5095495880ae25fee60bd301",
              "IPY_MODEL_9fb9f7d982704e1596b99042169c79a1"
            ]
          }
        },
        "afa54ba134b147c0acd5257c8d2c0038": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d1d0dbba5095495880ae25fee60bd301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_41a3d1842a5844d8b20e982b9c700fdc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_40ff34ffb6df43508d932bc40b0ce34f"
          }
        },
        "9fb9f7d982704e1596b99042169c79a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_81b5fb354c5747ecaaf581974e612c73",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8192/? [00:03&lt;00:00, 2161.59it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4819b69f61784659871c1d827a667402"
          }
        },
        "41a3d1842a5844d8b20e982b9c700fdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "40ff34ffb6df43508d932bc40b0ce34f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "81b5fb354c5747ecaaf581974e612c73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4819b69f61784659871c1d827a667402": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jameschapman19/cca_zoo/blob/master/cca_zoo_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFVm_oT3cmZH",
        "outputId": "e3037933-a993-4168-b6fd-541c2fd8b9e3"
      },
      "source": [
        "!pip install cca-zoo --upgrade\r\n",
        "!pip install scipy --upgrade"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cca-zoo\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/a1/371f6838d30b72f38bba242ae3d7d9d488c2659a63b6be9bb7ad3a052b7d/cca_zoo-1.1.22-py3-none-any.whl (43kB)\n",
            "\r\u001b[K     |███████▌                        | 10kB 12.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 30kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 40kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: seaborn in /usr/local/lib/python3.7/dist-packages (from cca-zoo) (0.11.1)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from cca-zoo) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from cca-zoo) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard in /usr/local/lib/python3.7/dist-packages (from cca-zoo) (2.4.1)\n",
            "Collecting scipy>=1.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/3a/9e0649ab2d5ade703baa70ef980aa08739226e5d6a642f084bb201a92fc2/scipy-1.6.1-cp37-cp37m-manylinux1_x86_64.whl (27.4MB)\n",
            "\u001b[K     |████████████████████████████████| 27.4MB 156kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.7/dist-packages (from cca-zoo) (3.2.2)\n",
            "Collecting mvlearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/a1/77ee37d526442c7680734d9a30e671f6dcaca7b38ce49e50f76796301e07/mvlearn-0.4.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 41.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from cca-zoo) (1.7.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from cca-zoo) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: Pillow in /usr/local/lib/python3.7/dist-packages (from cca-zoo) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: torchvision in /usr/local/lib/python3.7/dist-packages (from cca-zoo) (0.8.2+cu101)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->cca-zoo) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->cca-zoo) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->cca-zoo) (1.8.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->cca-zoo) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->cca-zoo) (1.27.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->cca-zoo) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->cca-zoo) (54.0.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->cca-zoo) (3.3.4)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard->cca-zoo) (0.36.2)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->cca-zoo) (0.4.2)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->cca-zoo) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->cca-zoo) (1.32.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->cca-zoo) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->cca-zoo) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cca-zoo) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cca-zoo) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cca-zoo) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from mvlearn->cca-zoo) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->cca-zoo) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->cca-zoo) (4.2.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->cca-zoo) (4.7.2)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->cca-zoo) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->cca-zoo) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->cca-zoo) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->cca-zoo) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->cca-zoo) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->cca-zoo) (3.7.0)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->cca-zoo) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard->cca-zoo) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->cca-zoo) (3.4.0)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->cca-zoo) (3.1.0)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy, mvlearn, cca-zoo\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "Successfully installed cca-zoo-1.1.22 mvlearn-0.4.1 scipy-1.6.1\n",
            "Requirement already up-to-date: scipy in /usr/local/lib/python3.7/dist-packages (1.6.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFsRNCJ0crH8",
        "outputId": "711d7abd-c182-4d80-ac72-12d43a61f3b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394,
          "referenced_widgets": [
            "584fdc4d944e404fbec98f86efa75312",
            "ac19664456264647bbeca68ddc6655ef",
            "1b991f2f67f64cb5b7bf731525b395fb",
            "32dca46dccaa463a960c9a2126e4db7c",
            "908c393d151947178361f62ee2ff25f4",
            "6d5a9c430115476a9e6ead3714c1c7a7",
            "695402ab55b84c41a0a77fbc7c4dc085",
            "27a8cdbc24194b3f99e7565e0a4f1c1a",
            "b65f75d69ebe4a1ca9af518fb50670a6",
            "46b3f939e4194d04862132acf42acaf1",
            "770a949cb5fd48d6b42bffe5e4847517",
            "7bcf70c62b8645f5986cfa209496ccbc",
            "d9d6c364d6fa49f1ac8f7f4d92e74708",
            "725d935fe83f4bdaa64ab54cf3eb41a6",
            "e899c58bcdc94dbe9a333c7824aa5d08",
            "81df0d8444484c5cb6b7a4d91ace7bca",
            "548bca106df645758186afe18256d8b1",
            "68bfdd43b87f4a2db88751939265abff",
            "632ba899fe1b4476aca03b690a8b24fd",
            "0aa017a592504a79a2b80a021eb63794",
            "f945cc7ff46c449aabc7341b768d53c5",
            "b3fe9588b98546769319592f64ec13bb",
            "77d42ba4336745c2ba4f62d37c889adc",
            "2ce2aaef57924614b61f4e63b6518f0f",
            "fa8326acc52446cdbb165a14611ddac9",
            "afa54ba134b147c0acd5257c8d2c0038",
            "d1d0dbba5095495880ae25fee60bd301",
            "9fb9f7d982704e1596b99042169c79a1",
            "41a3d1842a5844d8b20e982b9c700fdc",
            "40ff34ffb6df43508d932bc40b0ce34f",
            "81b5fb354c5747ecaaf581974e612c73",
            "4819b69f61784659871c1d827a667402"
          ]
        }
      },
      "source": [
        "# Imports\r\n",
        "import numpy as np\r\n",
        "from cca_zoo import wrappers\r\n",
        "from cca_zoo import data\r\n",
        "import itertools\r\n",
        "import os\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from torch.utils.data import Subset\r\n",
        "from torch import optim\r\n",
        "\r\n",
        "# Load MNIST Data\r\n",
        "os.chdir('..')\r\n",
        "N = 500\r\n",
        "dataset = data.Noisy_MNIST_Dataset(mnist_type='FashionMNIST', train=True)\r\n",
        "ids = np.arange(min(2 * N, len(dataset)))\r\n",
        "np.random.shuffle(ids)\r\n",
        "train_ids, val_ids = np.array_split(ids, 2)\r\n",
        "val_dataset = Subset(dataset, val_ids)\r\n",
        "train_dataset = Subset(dataset, train_ids)\r\n",
        "test_dataset = data.Noisy_MNIST_Dataset(mnist_type='FashionMNIST', train=False)\r\n",
        "test_ids = np.arange(min(N, len(test_dataset)))\r\n",
        "np.random.shuffle(test_ids)\r\n",
        "test_dataset = Subset(test_dataset, test_ids)\r\n",
        "train_view_1, train_view_2, train_rotations, train_OH_labels, train_labels = train_dataset.dataset.to_numpy(\r\n",
        "    train_dataset.indices)\r\n",
        "val_view_1, val_view_2, val_rotations, val_OH_labels, val_labels = val_dataset.dataset.to_numpy(val_dataset.indices)\r\n",
        "test_view_1, test_view_2, test_rotations, test_OH_labels, test_labels = test_dataset.dataset.to_numpy(\r\n",
        "    test_dataset.indices)\r\n",
        "\r\n",
        "# Settings\r\n",
        "\r\n",
        "# The number of latent dimensions across models\r\n",
        "latent_dims = 2\r\n",
        "# The number of folds used for cross-validation/hyperparameter tuning\r\n",
        "cv_folds = 5\r\n",
        "# For running hyperparameter tuning in parallel (0 if not)\r\n",
        "jobs = 2\r\n",
        "# Number of iterations for iterative algorithms\r\n",
        "max_iter = 2\r\n",
        "# number of epochs for deep models\r\n",
        "epochs = 50"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ../../data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "584fdc4d944e404fbec98f86efa75312",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../../data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ../../data/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ../../data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b65f75d69ebe4a1ca9af518fb50670a6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../../data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ../../data/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ../../data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "548bca106df645758186afe18256d8b1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../../data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ../../data/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ../../data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa8326acc52446cdbb165a14611ddac9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../../data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ../../data/FashionMNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOryUM6ShmQf"
      },
      "source": [
        "# Canonical Correlation Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSGgSD7vgh1b"
      },
      "source": [
        "\"\"\"\r\n",
        "### Linear CCA by eigendecomposition\r\n",
        "\"\"\"\r\n",
        "linear_cca = wrappers.CCA(latent_dims=latent_dims)\r\n",
        "\r\n",
        "linear_cca.fit(train_view_1, train_view_2)\r\n",
        "\r\n",
        "linear_cca_results = np.stack(\r\n",
        "    (linear_cca.train_correlations[0, 1], linear_cca.predict_corr(test_view_1, test_view_2)[0, 1]))\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "### Linear CCA by alternating least squares (can pass more than 2 views)\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "linear_cca_als = wrappers.CCA_ALS(latent_dims=latent_dims)\r\n",
        "\r\n",
        "linear_cca_als.fit(train_view_1, train_view_2)\r\n",
        "\r\n",
        "linear_cca_als_results = np.stack(\r\n",
        "    (linear_cca_als.train_correlations[0, 1], linear_cca_als.predict_corr(test_view_1, test_view_2)[0, 1]))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZtZUfZ3huKE"
      },
      "source": [
        "# Partial Least Squares\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei3rASx3ghtJ"
      },
      "source": [
        "\"\"\"\r\n",
        "### PLS with scikit-learn (only permits 2 views)\r\n",
        "\"\"\"\r\n",
        "pls = wrappers.PLS(latent_dims=latent_dims)\r\n",
        "\r\n",
        "pls.fit(train_view_1, train_view_2)\r\n",
        "\r\n",
        "pls_results = np.stack(\r\n",
        "    (pls.train_correlations[0, 1], pls.predict_corr(test_view_1, test_view_2)[0, 1]))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88vAaUxIi1H7"
      },
      "source": [
        "# Extension to multiple views\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Fx0dj8GghbD"
      },
      "source": [
        "\"\"\"\r\n",
        "### (Regularized) Generalized CCA(can pass more than 2 views)\r\n",
        "\"\"\"\r\n",
        "# small ammount of regularisation added since data is not full rank\r\n",
        "c=[0.5,0.5,0.5]\r\n",
        "\r\n",
        "gcca = wrappers.GCCA(latent_dims=latent_dims,c=c)\r\n",
        "\r\n",
        "gcca.fit(train_view_1, train_view_2,train_view_1)\r\n",
        "\r\n",
        "gcca_results = np.stack((gcca.train_correlations[0, 1], gcca.predict_corr(test_view_1, test_view_2)[0, 1]))\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "### (Regularized) Multiset CCA(can pass more than 2 views)\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "mcca = wrappers.MCCA(latent_dims=latent_dims, c=c)\r\n",
        "\r\n",
        "mcca.fit(train_view_1, train_view_2,train_view_1)\r\n",
        "\r\n",
        "mcca_results = np.stack((mcca.train_correlations[0, 1], mcca.predict_corr(test_view_1, test_view_2)[0, 1]))\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "### Multiset CCA by alternating least squares\r\n",
        "\"\"\"\r\n",
        "mcca_als = wrappers.CCA_ALS(latent_dims=latent_dims, max_iter=max_iter)\r\n",
        "\r\n",
        "mcca_als.fit(train_view_1, train_view_2,train_view_1)\r\n",
        "\r\n",
        "mcca_als_results = np.stack(\r\n",
        "    (mcca_als.train_correlations[0, 1], mcca_als.predict_corr(test_view_1, test_view_2)[0, 1]))\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "### Multiset PLS by alternating least squares\r\n",
        "\"\"\"\r\n",
        "mcca_pls = wrappers.PLS(latent_dims=latent_dims, max_iter=max_iter)\r\n",
        "\r\n",
        "mcca_pls.fit(train_view_1, train_view_2,train_view_1)\r\n",
        "\r\n",
        "mcca_pls_results = np.stack(\r\n",
        "    (mcca_als.train_correlations[0, 1], mcca_pls.predict_corr(test_view_1, test_view_2)[0, 1]))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-J9QturUVUE"
      },
      "source": [
        "# Weighted GCCA/Missing Observation GCCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58A4v1p_UVio"
      },
      "source": [
        "#observation_matrix\r\n",
        "K = np.ones((3, N))\r\n",
        "K[0, 200:] = 0\r\n",
        "K[1, :100] = 0\r\n",
        "\r\n",
        "#view weights\r\n",
        "view_weights=[1,2,1.2]\r\n",
        "\r\n",
        "c=[0.5,0.5,0.5]\r\n",
        "\r\n",
        "gcca = wrappers.GCCA(latent_dims=latent_dims,c=c,K=K,view_weights=view_weights)\r\n",
        "\r\n",
        "gcca.fit(train_view_1, train_view_2,train_view_1)\r\n",
        "\r\n",
        "gcca_results = np.stack((gcca.train_correlations[0, 1], gcca.predict_corr(test_view_1, test_view_2)[0, 1]))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9847WJ3liT6v"
      },
      "source": [
        "# Rgularised CCA solutions based on alternating minimisation/alternating least squares\r\n",
        "\r\n",
        "We implement Witten's penalized matrix decomposition form of sparse CCA using 'pmd'\r\n",
        "\r\n",
        "We implement Waaijenborg's penalized CCA using elastic net using 'elastic'\r\n",
        "\r\n",
        "We implement Mai's sparse CCA using 'scca'\r\n",
        "\r\n",
        "Furthermore, any of these methods can be extended to multiple views. Witten describes this method explicitly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts_yQvzdhDQe",
        "outputId": "49abbb9f-0774-4109-dbc6-0e499a583678"
      },
      "source": [
        "\"\"\"\r\n",
        "### Ridge CCA (can pass more than 2 views)\r\n",
        "\"\"\"\r\n",
        "c1 = [0.1, 0.3, 0.7, 0.9]\r\n",
        "c2 = [0.1, 0.3, 0.7, 0.9]\r\n",
        "param_candidates = {'c': list(itertools.product(c1, c2))}\r\n",
        "\r\n",
        "ridge = wrappers.rCCA(latent_dims=latent_dims).gridsearch_fit(\r\n",
        "    train_view_1,\r\n",
        "    train_view_2,\r\n",
        "    param_candidates=param_candidates,\r\n",
        "    folds=cv_folds,\r\n",
        "    verbose=True, jobs=jobs,\r\n",
        "    plot=True)\r\n",
        "\r\n",
        "ridge_results = np.stack((ridge.train_correlations[0, 1, :], ridge.predict_corr(test_view_1, test_view_2)[0, 1, :]))\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "### Sparse CCA (Penalized Matrix Decomposition) (can pass more than 2 views)\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "# PMD\r\n",
        "c1 = [1, 3, 7, 9]\r\n",
        "c2 = [1, 3, 7, 9]\r\n",
        "param_candidates = {'c': list(itertools.product(c1, c2))}\r\n",
        "\r\n",
        "pmd = wrappers.PMD(latent_dims=latent_dims, max_iter=max_iter).gridsearch_fit(\r\n",
        "    train_view_1,\r\n",
        "    train_view_2,\r\n",
        "    param_candidates=param_candidates,\r\n",
        "    folds=cv_folds,\r\n",
        "    verbose=True, jobs=jobs,\r\n",
        "    plot=True)\r\n",
        "\r\n",
        "pmd_results = np.stack((pmd.train_correlations[0, 1, :], pmd.predict_corr(test_view_1, test_view_2)[0, 1, :]))\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "### Sparse CCA (can pass more than 2 views)\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "# Sparse CCA\r\n",
        "c1 = [0.00001, 0.0001]\r\n",
        "c2 = [0.00001, 0.0001]\r\n",
        "param_candidates = {'c': list(itertools.product(c1, c2))}\r\n",
        "\r\n",
        "scca = wrappers.SCCA(latent_dims=latent_dims, max_iter=max_iter).gridsearch_fit(\r\n",
        "    train_view_1,\r\n",
        "    train_view_2,\r\n",
        "    param_candidates=param_candidates,\r\n",
        "    folds=cv_folds,\r\n",
        "    verbose=True,\r\n",
        "    jobs=jobs, plot=True)\r\n",
        "\r\n",
        "scca_results = np.stack(\r\n",
        "    (scca.train_correlations[0, 1, :], scca.predict_corr(test_view_1, test_view_2)[0, 1, :]))\r\n",
        "\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "### Elastic CCA (can pass more than 2 views)\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "# Elastic CCA\r\n",
        "c1 = [0.001, 0.0001]\r\n",
        "c2 = [0.001, 0.0001]\r\n",
        "l1_1 = [0.01, 0.1]\r\n",
        "l1_2 = [0.01, 0.1]\r\n",
        "param_candidates = {'c': list(itertools.product(c1, c2)), 'l1_ratio': list(itertools.product(l1_1, l1_2))}\r\n",
        "\r\n",
        "elastic = wrappers.ElasticCCA(latent_dims=latent_dims,\r\n",
        "                              max_iter=max_iter).gridsearch_fit(train_view_1,\r\n",
        "                                                                train_view_2,\r\n",
        "                                                                param_candidates=param_candidates,\r\n",
        "                                                                folds=cv_folds,\r\n",
        "                                                                verbose=True,\r\n",
        "                                                                jobs=jobs,\r\n",
        "                                                                plot=True)\r\n",
        "\r\n",
        "elastic_results = np.stack(\r\n",
        "    (elastic.train_correlations[0, 1, :], elastic.predict_corr(test_view_1, test_view_2)[0, 1, :]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cross validation\n",
            "number of folds:  5\n",
            "Best score :  1.3529892529635505\n",
            "Standard deviation :  0.059119304363148245\n",
            "{'c': (0.9, 0.9)}\n",
            "cross validation\n",
            "number of folds:  5\n",
            "Best score :  1.2857203069492038\n",
            "Standard deviation :  0.07696203372638133\n",
            "{'c': (9, 9)}\n",
            "cross validation\n",
            "number of folds:  5\n",
            "Best score :  1.0367573399679475\n",
            "Standard deviation :  0.05797312103256841\n",
            "{'c': (0.0001, 1e-05)}\n",
            "cross validation\n",
            "number of folds:  5\n",
            "Best score :  1.1020018271387282\n",
            "Standard deviation :  0.11042487305609101\n",
            "{'c': (0.001, 0.001), 'l1_ratio': (0.1, 0.01)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaHqF5CljrCb"
      },
      "source": [
        "# Kernel CCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtH38KO8hLFL",
        "outputId": "2702251b-b2dc-4b6d-b7e1-0d921527251f"
      },
      "source": [
        "\"\"\"\r\n",
        "### Kernel CCA\r\n",
        "\r\n",
        "Similarly, we can use kernel CCA methods with [method='kernel']\r\n",
        "\r\n",
        "We can use different kernels and their associated parameters in a similar manner to before\r\n",
        "- regularized linear kernel CCA: parameters :  'kernel'='linear', 0<'c'<1\r\n",
        "- polynomial kernel CCA: parameters : 'kernel'='poly', 'degree', 0<'c'<1\r\n",
        "- gaussian rbf kernel CCA: parameters : 'kernel'='gaussian', 'sigma', 0<'c'<1\r\n",
        "\"\"\"\r\n",
        "# %%\r\n",
        "# r-kernel cca\r\n",
        "c1 = [0.9, 0.99]\r\n",
        "c2 = [0.9, 0.99]\r\n",
        "\r\n",
        "param_candidates = {'kernel': ['linear'], 'c': list(itertools.product(c1, c2))}\r\n",
        "\r\n",
        "kernel_reg = wrappers.KCCA(latent_dims=latent_dims).gridsearch_fit(train_view_1, train_view_2,\r\n",
        "                                                                   folds=cv_folds,\r\n",
        "                                                                   param_candidates=param_candidates,\r\n",
        "                                                                   verbose=True, jobs=jobs,\r\n",
        "                                                                   plot=True)\r\n",
        "kernel_reg_results = np.stack((\r\n",
        "    kernel_reg.train_correlations[0, 1, :],\r\n",
        "    kernel_reg.predict_corr(test_view_1, test_view_2)[0, 1, :]))\r\n",
        "\r\n",
        "# kernel cca (poly)\r\n",
        "param_candidates = {'kernel': ['poly'], 'degree': [2, 3], 'c': list(itertools.product(c1, c2))}\r\n",
        "\r\n",
        "kernel_poly = wrappers.KCCA(latent_dims=latent_dims).gridsearch_fit(train_view_1, train_view_2,\r\n",
        "                                                                    folds=cv_folds,\r\n",
        "                                                                    param_candidates=param_candidates,\r\n",
        "                                                                    verbose=True, jobs=jobs,\r\n",
        "                                                                    plot=True)\r\n",
        "\r\n",
        "kernel_poly_results = np.stack((\r\n",
        "    kernel_poly.train_correlations[0, 1, :],\r\n",
        "    kernel_poly.predict_corr(test_view_1, test_view_2)[0, 1, :]))\r\n",
        "\r\n",
        "# kernel cca (gaussian)\r\n",
        "param_candidates = {'kernel': ['rbf'], 'sigma': [1e+1, 1e+2, 1e+3], 'c': list(itertools.product(c1, c2))}\r\n",
        "\r\n",
        "kernel_gaussian = wrappers.KCCA(latent_dims=latent_dims).gridsearch_fit(train_view_1, train_view_2,\r\n",
        "                                                                        folds=cv_folds,\r\n",
        "                                                                        param_candidates=param_candidates,\r\n",
        "                                                                        verbose=True, jobs=jobs,\r\n",
        "                                                                        plot=True)\r\n",
        "\r\n",
        "kernel_gaussian_results = np.stack((\r\n",
        "    kernel_gaussian.train_correlations[0, 1, :],\r\n",
        "    kernel_gaussian.predict_corr(test_view_1, test_view_2)[0, 1, :]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cross validation\n",
            "number of folds:  5\n",
            "Best score :  1.541090705230807\n",
            "Standard deviation :  0.03833964743929596\n",
            "{'kernel': 'linear', 'c': (0.99, 0.99)}\n",
            "cross validation\n",
            "number of folds:  5\n",
            "Best score :  1.0910477287449436\n",
            "Standard deviation :  0.03801607770360919\n",
            "{'kernel': 'poly', 'degree': 3, 'c': (0.9, 0.9)}\n",
            "cross validation\n",
            "number of folds:  5\n",
            "Best score :  1.1812386613423436\n",
            "Standard deviation :  0.04826994218032073\n",
            "{'kernel': 'rbf', 'sigma': 100.0, 'c': (0.9, 0.9)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44ltKrtIkICK"
      },
      "source": [
        "# Deep CCA\r\n",
        "\r\n",
        "DCCA can be optimized using Andrew's original tracenorm objective or Wang's DCCA by nonlinear orthogonal iterations using the argument als=True."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0nTlPSEhVeP",
        "outputId": "06a07955-2aa3-4ce2-9702-59dcd5046db0"
      },
      "source": [
        "\"\"\"\r\n",
        "### Deep Learning\r\n",
        "\r\n",
        "We also have deep CCA methods (and autoencoder variants)\r\n",
        "- Deep CCA (DCCA)\r\n",
        "- Deep Canonically Correlated Autoencoders (DCCAE)\r\n",
        "\r\n",
        "We introduce a Config class from configuration.py. This contains a number of default settings for running DCCA.\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "from cca_zoo import deepwrapper, objectives, dcca, deep_models\r\n",
        "\r\n",
        "# %%\r\n",
        "# DCCA\r\n",
        "print('DCCA')\r\n",
        "encoder_1 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\r\n",
        "encoder_2 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\r\n",
        "dcca_model = dcca.DCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2])\r\n",
        "\r\n",
        "dcca_model = deepwrapper.DeepWrapper(dcca_model)\r\n",
        "\r\n",
        "dcca_model.fit(train_dataset, val_dataset, epochs=epochs)\r\n",
        "\r\n",
        "dcca_results = np.stack((dcca_model.train_correlations[0, 1], dcca_model.predict_corr(test_view_1, test_view_2)[0, 1]))\r\n",
        "\r\n",
        "\r\n",
        "# DCCA_NOI\r\n",
        "# Note that als=True\r\n",
        "print('DCCA by non-linear orthogonal iterations')\r\n",
        "encoder_1 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\r\n",
        "encoder_2 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\r\n",
        "dcca_noi_model = dcca.DCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2], als=True)\r\n",
        "\r\n",
        "dcca_noi_model = deepwrapper.DeepWrapper(dcca_noi_model)\r\n",
        "\r\n",
        "dcca_noi_model.fit(train_dataset, val_dataset, epochs=epochs)\r\n",
        "\r\n",
        "dcca_noi_results = np.stack(\r\n",
        "    (dcca_noi_model.train_correlations[0, 1], dcca_noi_model.predict_corr(test_view_1, test_view_2)[0, 1]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DCCA\n",
            "total parameters:  201476\n",
            "====> Epoch: 1 Average train loss: -0.1992\n",
            "====> Epoch: 1 Average val loss: -0.4696\n",
            "Min loss -0.47\n",
            "====> Epoch: 2 Average train loss: -0.4284\n",
            "====> Epoch: 2 Average val loss: -1.0864\n",
            "Min loss -1.09\n",
            "====> Epoch: 3 Average train loss: -0.9979\n",
            "====> Epoch: 3 Average val loss: -1.1795\n",
            "Min loss -1.18\n",
            "====> Epoch: 4 Average train loss: -1.2693\n",
            "====> Epoch: 4 Average val loss: -1.2537\n",
            "Min loss -1.25\n",
            "====> Epoch: 5 Average train loss: -1.2971\n",
            "====> Epoch: 5 Average val loss: -1.3359\n",
            "Min loss -1.34\n",
            "====> Epoch: 6 Average train loss: -1.3230\n",
            "====> Epoch: 6 Average val loss: -1.3458\n",
            "Min loss -1.35\n",
            "====> Epoch: 7 Average train loss: -1.3473\n",
            "====> Epoch: 7 Average val loss: -1.3718\n",
            "Min loss -1.37\n",
            "====> Epoch: 8 Average train loss: -1.3747\n",
            "====> Epoch: 8 Average val loss: -1.4354\n",
            "Min loss -1.44\n",
            "====> Epoch: 9 Average train loss: -1.3934\n",
            "====> Epoch: 9 Average val loss: -1.4116\n",
            "====> Epoch: 10 Average train loss: -1.3941\n",
            "====> Epoch: 10 Average val loss: -1.4448\n",
            "Min loss -1.44\n",
            "====> Epoch: 11 Average train loss: -1.4597\n",
            "====> Epoch: 11 Average val loss: -1.4718\n",
            "Min loss -1.47\n",
            "====> Epoch: 12 Average train loss: -1.4233\n",
            "====> Epoch: 12 Average val loss: -1.5010\n",
            "Min loss -1.50\n",
            "====> Epoch: 13 Average train loss: -1.4612\n",
            "====> Epoch: 13 Average val loss: -1.5127\n",
            "Min loss -1.51\n",
            "====> Epoch: 14 Average train loss: -1.4918\n",
            "====> Epoch: 14 Average val loss: -1.4952\n",
            "====> Epoch: 15 Average train loss: -1.4847\n",
            "====> Epoch: 15 Average val loss: -1.4731\n",
            "====> Epoch: 16 Average train loss: -1.4826\n",
            "====> Epoch: 16 Average val loss: -1.5339\n",
            "Min loss -1.53\n",
            "====> Epoch: 17 Average train loss: -1.5503\n",
            "====> Epoch: 17 Average val loss: -1.5161\n",
            "====> Epoch: 18 Average train loss: -1.4844\n",
            "====> Epoch: 18 Average val loss: -1.5169\n",
            "====> Epoch: 19 Average train loss: -1.5306\n",
            "====> Epoch: 19 Average val loss: -1.5139\n",
            "====> Epoch: 20 Average train loss: -1.5354\n",
            "====> Epoch: 20 Average val loss: -1.5649\n",
            "Min loss -1.56\n",
            "====> Epoch: 21 Average train loss: -1.5363\n",
            "====> Epoch: 21 Average val loss: -1.5993\n",
            "Min loss -1.60\n",
            "====> Epoch: 22 Average train loss: -1.5755\n",
            "====> Epoch: 22 Average val loss: -1.5881\n",
            "====> Epoch: 23 Average train loss: -1.5976\n",
            "====> Epoch: 23 Average val loss: -1.5722\n",
            "====> Epoch: 24 Average train loss: -1.5495\n",
            "====> Epoch: 24 Average val loss: -1.5895\n",
            "====> Epoch: 25 Average train loss: -1.5569\n",
            "====> Epoch: 25 Average val loss: -1.5485\n",
            "====> Epoch: 26 Average train loss: -1.6229\n",
            "====> Epoch: 26 Average val loss: -1.5410\n",
            "====> Epoch: 27 Average train loss: -1.5606\n",
            "====> Epoch: 27 Average val loss: -1.6014\n",
            "Min loss -1.60\n",
            "====> Epoch: 28 Average train loss: -1.5679\n",
            "====> Epoch: 28 Average val loss: -1.6011\n",
            "====> Epoch: 29 Average train loss: -1.5612\n",
            "====> Epoch: 29 Average val loss: -1.6006\n",
            "====> Epoch: 30 Average train loss: -1.6209\n",
            "====> Epoch: 30 Average val loss: -1.6112\n",
            "Min loss -1.61\n",
            "====> Epoch: 31 Average train loss: -1.6166\n",
            "====> Epoch: 31 Average val loss: -1.5986\n",
            "====> Epoch: 32 Average train loss: -1.5954\n",
            "====> Epoch: 32 Average val loss: -1.5975\n",
            "====> Epoch: 33 Average train loss: -1.6025\n",
            "====> Epoch: 33 Average val loss: -1.5746\n",
            "====> Epoch: 34 Average train loss: -1.6413\n",
            "====> Epoch: 34 Average val loss: -1.5988\n",
            "====> Epoch: 35 Average train loss: -1.6014\n",
            "====> Epoch: 35 Average val loss: -1.5754\n",
            "====> Epoch: 36 Average train loss: -1.5938\n",
            "====> Epoch: 36 Average val loss: -1.6131\n",
            "Min loss -1.61\n",
            "====> Epoch: 37 Average train loss: -1.6129\n",
            "====> Epoch: 37 Average val loss: -1.5997\n",
            "====> Epoch: 38 Average train loss: -1.6173\n",
            "====> Epoch: 38 Average val loss: -1.6044\n",
            "====> Epoch: 39 Average train loss: -1.6817\n",
            "====> Epoch: 39 Average val loss: -1.6220\n",
            "Min loss -1.62\n",
            "====> Epoch: 40 Average train loss: -1.6359\n",
            "====> Epoch: 40 Average val loss: -1.6244\n",
            "Min loss -1.62\n",
            "====> Epoch: 41 Average train loss: -1.6689\n",
            "====> Epoch: 41 Average val loss: -1.5995\n",
            "====> Epoch: 42 Average train loss: -1.6552\n",
            "====> Epoch: 42 Average val loss: -1.6079\n",
            "====> Epoch: 43 Average train loss: -1.6738\n",
            "====> Epoch: 43 Average val loss: -1.6423\n",
            "Min loss -1.64\n",
            "====> Epoch: 44 Average train loss: -1.6739\n",
            "====> Epoch: 44 Average val loss: -1.6043\n",
            "====> Epoch: 45 Average train loss: -1.6524\n",
            "====> Epoch: 45 Average val loss: -1.6063\n",
            "====> Epoch: 46 Average train loss: -1.6580\n",
            "====> Epoch: 46 Average val loss: -1.6465\n",
            "Min loss -1.65\n",
            "====> Epoch: 47 Average train loss: -1.6685\n",
            "====> Epoch: 47 Average val loss: -1.6107\n",
            "====> Epoch: 48 Average train loss: -1.7001\n",
            "====> Epoch: 48 Average val loss: -1.5992\n",
            "====> Epoch: 49 Average train loss: -1.6801\n",
            "====> Epoch: 49 Average val loss: -1.6117\n",
            "====> Epoch: 50 Average train loss: -1.6602\n",
            "====> Epoch: 50 Average val loss: -1.6408\n",
            "DCCA by non-linear orthogonal iterations\n",
            "total parameters:  201476\n",
            "====> Epoch: 1 Average train loss: -0.1696\n",
            "====> Epoch: 1 Average val loss: -0.4969\n",
            "Min loss -0.50\n",
            "====> Epoch: 2 Average train loss: -0.4053\n",
            "====> Epoch: 2 Average val loss: -0.4166\n",
            "====> Epoch: 3 Average train loss: -0.4247\n",
            "====> Epoch: 3 Average val loss: -0.1255\n",
            "====> Epoch: 4 Average train loss: -0.1948\n",
            "====> Epoch: 4 Average val loss: -0.1882\n",
            "====> Epoch: 5 Average train loss: -0.1495\n",
            "====> Epoch: 5 Average val loss: -0.3112\n",
            "====> Epoch: 6 Average train loss: -0.2856\n",
            "====> Epoch: 6 Average val loss: -0.2890\n",
            "====> Epoch: 7 Average train loss: -0.2578\n",
            "====> Epoch: 7 Average val loss: -0.1977\n",
            "====> Epoch: 8 Average train loss: -0.1473\n",
            "====> Epoch: 8 Average val loss: -0.1393\n",
            "====> Epoch: 9 Average train loss: -0.1504\n",
            "====> Epoch: 9 Average val loss: -0.0704\n",
            "====> Epoch: 10 Average train loss: -0.0684\n",
            "====> Epoch: 10 Average val loss: -0.0571\n",
            "====> Epoch: 11 Average train loss: -0.1101\n",
            "====> Epoch: 11 Average val loss: -0.2104\n",
            "====> Epoch: 12 Average train loss: -0.2353\n",
            "====> Epoch: 12 Average val loss: -0.2164\n",
            "====> Epoch: 13 Average train loss: -0.1656\n",
            "====> Epoch: 13 Average val loss: -0.1358\n",
            "====> Epoch: 14 Average train loss: -0.1720\n",
            "====> Epoch: 14 Average val loss: -0.1459\n",
            "====> Epoch: 15 Average train loss: -0.1428\n",
            "====> Epoch: 15 Average val loss: -0.1074\n",
            "====> Epoch: 16 Average train loss: -0.1007\n",
            "====> Epoch: 16 Average val loss: -0.0723\n",
            "====> Epoch: 17 Average train loss: -0.0783\n",
            "====> Epoch: 17 Average val loss: -0.0947\n",
            "====> Epoch: 18 Average train loss: -0.1069\n",
            "====> Epoch: 18 Average val loss: -0.0257\n",
            "====> Epoch: 19 Average train loss: -0.0464\n",
            "====> Epoch: 19 Average val loss: -0.0609\n",
            "====> Epoch: 20 Average train loss: -0.0425\n",
            "====> Epoch: 20 Average val loss: -0.0285\n",
            "====> Epoch: 21 Average train loss: -0.0745\n",
            "====> Epoch: 21 Average val loss: -0.0467\n",
            "====> Epoch: 22 Average train loss: -0.0132\n",
            "====> Epoch: 22 Average val loss: -0.0419\n",
            "====> Epoch: 23 Average train loss: -0.0455\n",
            "====> Epoch: 23 Average val loss: -0.0336\n",
            "====> Epoch: 24 Average train loss: -0.0285\n",
            "====> Epoch: 24 Average val loss: -0.0475\n",
            "====> Epoch: 25 Average train loss: -0.0593\n",
            "====> Epoch: 25 Average val loss: -0.0396\n",
            "====> Epoch: 26 Average train loss: -0.0408\n",
            "====> Epoch: 26 Average val loss: -0.0755\n",
            "====> Epoch: 27 Average train loss: -0.0487\n",
            "====> Epoch: 27 Average val loss: -0.1176\n",
            "====> Epoch: 28 Average train loss: -0.1017\n",
            "====> Epoch: 28 Average val loss: -0.1155\n",
            "====> Epoch: 29 Average train loss: -0.0847\n",
            "====> Epoch: 29 Average val loss: -0.1188\n",
            "====> Epoch: 30 Average train loss: -0.0872\n",
            "====> Epoch: 30 Average val loss: -0.1184\n",
            "====> Epoch: 31 Average train loss: -0.1212\n",
            "====> Epoch: 31 Average val loss: -0.1080\n",
            "====> Epoch: 32 Average train loss: -0.1023\n",
            "====> Epoch: 32 Average val loss: -0.0680\n",
            "====> Epoch: 33 Average train loss: -0.0713\n",
            "====> Epoch: 33 Average val loss: -0.0581\n",
            "====> Epoch: 34 Average train loss: -0.0599\n",
            "====> Epoch: 34 Average val loss: -0.0404\n",
            "====> Epoch: 35 Average train loss: -0.0465\n",
            "====> Epoch: 35 Average val loss: -0.0228\n",
            "====> Epoch: 36 Average train loss: -0.0258\n",
            "====> Epoch: 36 Average val loss: -0.0281\n",
            "====> Epoch: 37 Average train loss: -0.0457\n",
            "====> Epoch: 37 Average val loss: -0.0347\n",
            "====> Epoch: 38 Average train loss: -0.0305\n",
            "====> Epoch: 38 Average val loss: -0.0244\n",
            "====> Epoch: 39 Average train loss: -0.0421\n",
            "====> Epoch: 39 Average val loss: -0.0560\n",
            "====> Epoch: 40 Average train loss: -0.0431\n",
            "====> Epoch: 40 Average val loss: -0.0303\n",
            "====> Epoch: 41 Average train loss: -0.0426\n",
            "====> Epoch: 41 Average val loss: -0.0340\n",
            "====> Epoch: 42 Average train loss: -0.0519\n",
            "====> Epoch: 42 Average val loss: -0.0515\n",
            "====> Epoch: 43 Average train loss: -0.0304\n",
            "====> Epoch: 43 Average val loss: -0.0630\n",
            "====> Epoch: 44 Average train loss: -0.0513\n",
            "====> Epoch: 44 Average val loss: -0.0841\n",
            "====> Epoch: 45 Average train loss: -0.0709\n",
            "====> Epoch: 45 Average val loss: -0.0642\n",
            "====> Epoch: 46 Average train loss: -0.0727\n",
            "====> Epoch: 46 Average val loss: -0.0814\n",
            "====> Epoch: 47 Average train loss: -0.1005\n",
            "====> Epoch: 47 Average val loss: -0.0953\n",
            "====> Epoch: 48 Average train loss: -0.0825\n",
            "====> Epoch: 48 Average val loss: -0.0755\n",
            "====> Epoch: 49 Average train loss: -0.1056\n",
            "====> Epoch: 49 Average val loss: -0.1099\n",
            "====> Epoch: 50 Average train loss: -0.0814\n",
            "====> Epoch: 50 Average val loss: -0.0859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1_ce5uMJUJ8"
      },
      "source": [
        "# DCCA with custom optimizers and schedulers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGC3HS2YJUk1",
        "outputId": "9bb45e3a-3daa-409a-ce5b-8e233c502c5d"
      },
      "source": [
        "# DCCA\r\n",
        "optimizers = [optim.Adam(encoder_1.parameters(), lr=1e-4), optim.Adam(encoder_2.parameters(), lr=1e-4)]\r\n",
        "schedulers = [optim.lr_scheduler.CosineAnnealingLR(optimizers[0], 1),\r\n",
        "              optim.lr_scheduler.ReduceLROnPlateau(optimizers[1])]\r\n",
        "dcca_model = dcca.DCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2],\r\n",
        "                                objective=objectives.CCA, optimizers=optimizers, schedulers=schedulers)\r\n",
        "# hidden_layer_sizes are shown explicitly but these are also the defaults\r\n",
        "dcca_model = deepwrapper.DeepWrapper(dcca_model)\r\n",
        "dcca_model.fit(train_dataset, val_dataset,epochs=20)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total parameters:  201476\n",
            "====> Epoch: 1 Average train loss: -0.1003\n",
            "====> Epoch: 1 Average val loss: -0.1052\n",
            "Min loss -0.11\n",
            "====> Epoch: 2 Average train loss: -0.1133\n",
            "====> Epoch: 2 Average val loss: -0.1389\n",
            "Min loss -0.14\n",
            "====> Epoch: 3 Average train loss: -0.1222\n",
            "====> Epoch: 3 Average val loss: -0.1342\n",
            "====> Epoch: 4 Average train loss: -0.1494\n",
            "====> Epoch: 4 Average val loss: -0.1637\n",
            "Min loss -0.16\n",
            "====> Epoch: 5 Average train loss: -0.1330\n",
            "====> Epoch: 5 Average val loss: -0.1813\n",
            "Min loss -0.18\n",
            "====> Epoch: 6 Average train loss: -0.2063\n",
            "====> Epoch: 6 Average val loss: -0.2123\n",
            "Min loss -0.21\n",
            "====> Epoch: 7 Average train loss: -0.1922\n",
            "====> Epoch: 7 Average val loss: -0.2314\n",
            "Min loss -0.23\n",
            "====> Epoch: 8 Average train loss: -0.2298\n",
            "====> Epoch: 8 Average val loss: -0.2817\n",
            "Min loss -0.28\n",
            "====> Epoch: 9 Average train loss: -0.2450\n",
            "====> Epoch: 9 Average val loss: -0.3244\n",
            "Min loss -0.32\n",
            "====> Epoch: 10 Average train loss: -0.2932\n",
            "====> Epoch: 10 Average val loss: -0.2934\n",
            "====> Epoch: 11 Average train loss: -0.3131\n",
            "====> Epoch: 11 Average val loss: -0.3457\n",
            "Min loss -0.35\n",
            "====> Epoch: 12 Average train loss: -0.2983\n",
            "====> Epoch: 12 Average val loss: -0.3755\n",
            "Min loss -0.38\n",
            "====> Epoch: 13 Average train loss: -0.3658\n",
            "====> Epoch: 13 Average val loss: -0.3640\n",
            "====> Epoch: 14 Average train loss: -0.3403\n",
            "====> Epoch: 14 Average val loss: -0.3913\n",
            "Min loss -0.39\n",
            "====> Epoch: 15 Average train loss: -0.3691\n",
            "====> Epoch: 15 Average val loss: -0.4095\n",
            "Min loss -0.41\n",
            "====> Epoch: 16 Average train loss: -0.3695\n",
            "====> Epoch: 16 Average val loss: -0.4171\n",
            "Min loss -0.42\n",
            "====> Epoch: 17 Average train loss: -0.4150\n",
            "====> Epoch: 17 Average val loss: -0.4715\n",
            "Min loss -0.47\n",
            "====> Epoch: 18 Average train loss: -0.4246\n",
            "====> Epoch: 18 Average val loss: -0.4843\n",
            "Min loss -0.48\n",
            "====> Epoch: 19 Average train loss: -0.4622\n",
            "====> Epoch: 19 Average val loss: -0.4674\n",
            "====> Epoch: 20 Average train loss: -0.4830\n",
            "====> Epoch: 20 Average val loss: -0.4782\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeepWrapper(device='cpu',\n",
              "            model=DCCA(\n",
              "  (encoders): ModuleList(\n",
              "    (0): Encoder(\n",
              "      (layers): Sequential(\n",
              "        (0): Sequential(\n",
              "          (0): Linear(in_features=784, out_features=128, bias=True)\n",
              "          (1): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (fc): Linear(in_features=128, out_features=2, bias=True)\n",
              "    )\n",
              "    (1): Encoder(\n",
              "      (layers): Sequential(\n",
              "        (0): Sequential(\n",
              "          (0): Linear(in_features=784, out_features=128, bias=True)\n",
              "          (1): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (fc): Linear(in_features=128, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "),\n",
              "            tensorboard=False, tensorboard_tag=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NZ5ZB9cNx-o"
      },
      "source": [
        "# DGCCA and DMCCA for more than 2 views\r\n",
        "\r\n",
        "The only change we need to make is to the objective argument to perform DGCCA and DMCCA."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAClfNMYNxq4",
        "outputId": "d6a04aed-65a3-4153-c3d3-906f88c1d616"
      },
      "source": [
        "# DGCCA\r\n",
        "print('DGCCA')\r\n",
        "encoder_1 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\r\n",
        "encoder_2 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\r\n",
        "dgcca_model = dcca.DCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2], objective=objectives.GCCA)\r\n",
        "\r\n",
        "dgcca_model = deepwrapper.DeepWrapper(dgcca_model)\r\n",
        "\r\n",
        "dgcca_model.fit(train_dataset, val_dataset, epochs=epochs)\r\n",
        "\r\n",
        "dgcca_results = np.stack(\r\n",
        "    (dgcca_model.train_correlations[0, 1], dgcca_model.predict_corr(test_view_1, test_view_2)[0, 1]))\r\n",
        "\r\n",
        "# DMCCA\r\n",
        "print('DMCCA')\r\n",
        "encoder_1 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\r\n",
        "encoder_2 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\r\n",
        "dmcca_model = dcca.DCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2], objective=objectives.MCCA)\r\n",
        "\r\n",
        "dmcca_model = deepwrapper.DeepWrapper(dmcca_model)\r\n",
        "\r\n",
        "dmcca_model.fit(train_dataset, val_dataset, epochs=epochs)\r\n",
        "\r\n",
        "dmcca_results = np.stack(\r\n",
        "    (dmcca_model.train_correlations[0, 1], dmcca_model.predict_corr(test_view_1, test_view_2)[0, 1]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DGCCA\n",
            "total parameters:  201476\n",
            "====> Epoch: 1 Average train loss: -0.1636\n",
            "====> Epoch: 1 Average val loss: -0.6327\n",
            "Min loss -0.63\n",
            "====> Epoch: 2 Average train loss: -0.7176\n",
            "====> Epoch: 2 Average val loss: -1.1977\n",
            "Min loss -1.20\n",
            "====> Epoch: 3 Average train loss: -1.2958\n",
            "====> Epoch: 3 Average val loss: -1.3110\n",
            "Min loss -1.31\n",
            "====> Epoch: 4 Average train loss: -1.2916\n",
            "====> Epoch: 4 Average val loss: -1.3415\n",
            "Min loss -1.34\n",
            "====> Epoch: 5 Average train loss: -1.3092\n",
            "====> Epoch: 5 Average val loss: -1.3802\n",
            "Min loss -1.38\n",
            "====> Epoch: 6 Average train loss: -1.3512\n",
            "====> Epoch: 6 Average val loss: -1.3728\n",
            "====> Epoch: 7 Average train loss: -1.4042\n",
            "====> Epoch: 7 Average val loss: -1.4120\n",
            "Min loss -1.41\n",
            "====> Epoch: 8 Average train loss: -1.4188\n",
            "====> Epoch: 8 Average val loss: -1.4291\n",
            "Min loss -1.43\n",
            "====> Epoch: 9 Average train loss: -1.3925\n",
            "====> Epoch: 9 Average val loss: -1.4063\n",
            "====> Epoch: 10 Average train loss: -1.4053\n",
            "====> Epoch: 10 Average val loss: -1.4349\n",
            "Min loss -1.43\n",
            "====> Epoch: 11 Average train loss: -1.4698\n",
            "====> Epoch: 11 Average val loss: -1.4912\n",
            "Min loss -1.49\n",
            "====> Epoch: 12 Average train loss: -1.5168\n",
            "====> Epoch: 12 Average val loss: -1.4878\n",
            "====> Epoch: 13 Average train loss: -1.4595\n",
            "====> Epoch: 13 Average val loss: -1.4857\n",
            "====> Epoch: 14 Average train loss: -1.5004\n",
            "====> Epoch: 14 Average val loss: -1.4592\n",
            "====> Epoch: 15 Average train loss: -1.5155\n",
            "====> Epoch: 15 Average val loss: -1.5033\n",
            "Min loss -1.50\n",
            "====> Epoch: 16 Average train loss: -1.5366\n",
            "====> Epoch: 16 Average val loss: -1.5189\n",
            "Min loss -1.52\n",
            "====> Epoch: 17 Average train loss: -1.5259\n",
            "====> Epoch: 17 Average val loss: -1.5639\n",
            "Min loss -1.56\n",
            "====> Epoch: 18 Average train loss: -1.5633\n",
            "====> Epoch: 18 Average val loss: -1.5713\n",
            "Min loss -1.57\n",
            "====> Epoch: 19 Average train loss: -1.5472\n",
            "====> Epoch: 19 Average val loss: -1.5529\n",
            "====> Epoch: 20 Average train loss: -1.5157\n",
            "====> Epoch: 20 Average val loss: -1.5737\n",
            "Min loss -1.57\n",
            "====> Epoch: 21 Average train loss: -1.5755\n",
            "====> Epoch: 21 Average val loss: -1.5520\n",
            "====> Epoch: 22 Average train loss: -1.5724\n",
            "====> Epoch: 22 Average val loss: -1.5494\n",
            "====> Epoch: 23 Average train loss: -1.5707\n",
            "====> Epoch: 23 Average val loss: -1.5853\n",
            "Min loss -1.59\n",
            "====> Epoch: 24 Average train loss: -1.5916\n",
            "====> Epoch: 24 Average val loss: -1.5696\n",
            "====> Epoch: 25 Average train loss: -1.5691\n",
            "====> Epoch: 25 Average val loss: -1.6075\n",
            "Min loss -1.61\n",
            "====> Epoch: 26 Average train loss: -1.5940\n",
            "====> Epoch: 26 Average val loss: -1.5418\n",
            "====> Epoch: 27 Average train loss: -1.5893\n",
            "====> Epoch: 27 Average val loss: -1.5832\n",
            "====> Epoch: 28 Average train loss: -1.6320\n",
            "====> Epoch: 28 Average val loss: -1.5874\n",
            "====> Epoch: 29 Average train loss: -1.6169\n",
            "====> Epoch: 29 Average val loss: -1.6054\n",
            "====> Epoch: 30 Average train loss: -1.6098\n",
            "====> Epoch: 30 Average val loss: -1.5996\n",
            "====> Epoch: 31 Average train loss: -1.6196\n",
            "====> Epoch: 31 Average val loss: -1.6004\n",
            "====> Epoch: 32 Average train loss: -1.6139\n",
            "====> Epoch: 32 Average val loss: -1.5987\n",
            "====> Epoch: 33 Average train loss: -1.6195\n",
            "====> Epoch: 33 Average val loss: -1.5838\n",
            "====> Epoch: 34 Average train loss: -1.6332\n",
            "====> Epoch: 34 Average val loss: -1.5912\n",
            "====> Epoch: 35 Average train loss: -1.6278\n",
            "====> Epoch: 35 Average val loss: -1.6072\n",
            "====> Epoch: 36 Average train loss: -1.6338\n",
            "====> Epoch: 36 Average val loss: -1.6115\n",
            "Min loss -1.61\n",
            "====> Epoch: 37 Average train loss: -1.6468\n",
            "====> Epoch: 37 Average val loss: -1.6143\n",
            "Min loss -1.61\n",
            "====> Epoch: 38 Average train loss: -1.6635\n",
            "====> Epoch: 38 Average val loss: -1.6346\n",
            "Min loss -1.63\n",
            "====> Epoch: 39 Average train loss: -1.6395\n",
            "====> Epoch: 39 Average val loss: -1.6600\n",
            "Min loss -1.66\n",
            "====> Epoch: 40 Average train loss: -1.6353\n",
            "====> Epoch: 40 Average val loss: -1.6383\n",
            "====> Epoch: 41 Average train loss: -1.6421\n",
            "====> Epoch: 41 Average val loss: -1.6306\n",
            "====> Epoch: 42 Average train loss: -1.6367\n",
            "====> Epoch: 42 Average val loss: -1.6192\n",
            "====> Epoch: 43 Average train loss: -1.6446\n",
            "====> Epoch: 43 Average val loss: -1.6519\n",
            "====> Epoch: 44 Average train loss: -1.6792\n",
            "====> Epoch: 44 Average val loss: -1.6448\n",
            "====> Epoch: 45 Average train loss: -1.6443\n",
            "====> Epoch: 45 Average val loss: -1.5774\n",
            "====> Epoch: 46 Average train loss: -1.6878\n",
            "====> Epoch: 46 Average val loss: -1.5836\n",
            "====> Epoch: 47 Average train loss: -1.6510\n",
            "====> Epoch: 47 Average val loss: -1.6482\n",
            "====> Epoch: 48 Average train loss: -1.6565\n",
            "====> Epoch: 48 Average val loss: -1.6362\n",
            "====> Epoch: 49 Average train loss: -1.6974\n",
            "====> Epoch: 49 Average val loss: -1.6216\n",
            "====> Epoch: 50 Average train loss: -1.6999\n",
            "====> Epoch: 50 Average val loss: -1.6594\n",
            "DMCCA\n",
            "total parameters:  201476\n",
            "====> Epoch: 1 Average train loss: -0.2927\n",
            "====> Epoch: 1 Average val loss: -0.7799\n",
            "Min loss -0.78\n",
            "====> Epoch: 2 Average train loss: -0.7746\n",
            "====> Epoch: 2 Average val loss: -1.0985\n",
            "Min loss -1.10\n",
            "====> Epoch: 3 Average train loss: -1.1404\n",
            "====> Epoch: 3 Average val loss: -1.2724\n",
            "Min loss -1.27\n",
            "====> Epoch: 4 Average train loss: -1.3136\n",
            "====> Epoch: 4 Average val loss: -1.3692\n",
            "Min loss -1.37\n",
            "====> Epoch: 5 Average train loss: -1.3338\n",
            "====> Epoch: 5 Average val loss: -1.4061\n",
            "Min loss -1.41\n",
            "====> Epoch: 6 Average train loss: -1.3803\n",
            "====> Epoch: 6 Average val loss: -1.4445\n",
            "Min loss -1.44\n",
            "====> Epoch: 7 Average train loss: -1.4078\n",
            "====> Epoch: 7 Average val loss: -1.4006\n",
            "====> Epoch: 8 Average train loss: -1.4063\n",
            "====> Epoch: 8 Average val loss: -1.4260\n",
            "====> Epoch: 9 Average train loss: -1.4129\n",
            "====> Epoch: 9 Average val loss: -1.4563\n",
            "Min loss -1.46\n",
            "====> Epoch: 10 Average train loss: -1.4960\n",
            "====> Epoch: 10 Average val loss: -1.4838\n",
            "Min loss -1.48\n",
            "====> Epoch: 11 Average train loss: -1.4648\n",
            "====> Epoch: 11 Average val loss: -1.5065\n",
            "Min loss -1.51\n",
            "====> Epoch: 12 Average train loss: -1.5144\n",
            "====> Epoch: 12 Average val loss: -1.4528\n",
            "====> Epoch: 13 Average train loss: -1.4946\n",
            "====> Epoch: 13 Average val loss: -1.5451\n",
            "Min loss -1.55\n",
            "====> Epoch: 14 Average train loss: -1.5358\n",
            "====> Epoch: 14 Average val loss: -1.4778\n",
            "====> Epoch: 15 Average train loss: -1.5496\n",
            "====> Epoch: 15 Average val loss: -1.5406\n",
            "====> Epoch: 16 Average train loss: -1.5060\n",
            "====> Epoch: 16 Average val loss: -1.4984\n",
            "====> Epoch: 17 Average train loss: -1.5337\n",
            "====> Epoch: 17 Average val loss: -1.5094\n",
            "====> Epoch: 18 Average train loss: -1.5399\n",
            "====> Epoch: 18 Average val loss: -1.5406\n",
            "====> Epoch: 19 Average train loss: -1.5853\n",
            "====> Epoch: 19 Average val loss: -1.4972\n",
            "====> Epoch: 20 Average train loss: -1.5458\n",
            "====> Epoch: 20 Average val loss: -1.5708\n",
            "Min loss -1.57\n",
            "====> Epoch: 21 Average train loss: -1.5783\n",
            "====> Epoch: 21 Average val loss: -1.5354\n",
            "====> Epoch: 22 Average train loss: -1.5590\n",
            "====> Epoch: 22 Average val loss: -1.5659\n",
            "====> Epoch: 23 Average train loss: -1.6197\n",
            "====> Epoch: 23 Average val loss: -1.5673\n",
            "====> Epoch: 24 Average train loss: -1.5873\n",
            "====> Epoch: 24 Average val loss: -1.5749\n",
            "Min loss -1.57\n",
            "====> Epoch: 25 Average train loss: -1.5706\n",
            "====> Epoch: 25 Average val loss: -1.5813\n",
            "Min loss -1.58\n",
            "====> Epoch: 26 Average train loss: -1.6327\n",
            "====> Epoch: 26 Average val loss: -1.6062\n",
            "Min loss -1.61\n",
            "====> Epoch: 27 Average train loss: -1.5993\n",
            "====> Epoch: 27 Average val loss: -1.5687\n",
            "====> Epoch: 28 Average train loss: -1.6279\n",
            "====> Epoch: 28 Average val loss: -1.5712\n",
            "====> Epoch: 29 Average train loss: -1.6272\n",
            "====> Epoch: 29 Average val loss: -1.5801\n",
            "====> Epoch: 30 Average train loss: -1.6302\n",
            "====> Epoch: 30 Average val loss: -1.5957\n",
            "====> Epoch: 31 Average train loss: -1.6442\n",
            "====> Epoch: 31 Average val loss: -1.5708\n",
            "====> Epoch: 32 Average train loss: -1.6221\n",
            "====> Epoch: 32 Average val loss: -1.6372\n",
            "Min loss -1.64\n",
            "====> Epoch: 33 Average train loss: -1.6396\n",
            "====> Epoch: 33 Average val loss: -1.6266\n",
            "====> Epoch: 34 Average train loss: -1.6154\n",
            "====> Epoch: 34 Average val loss: -1.6369\n",
            "====> Epoch: 35 Average train loss: -1.6566\n",
            "====> Epoch: 35 Average val loss: -1.6015\n",
            "====> Epoch: 36 Average train loss: -1.6217\n",
            "====> Epoch: 36 Average val loss: -1.6111\n",
            "====> Epoch: 37 Average train loss: -1.6765\n",
            "====> Epoch: 37 Average val loss: -1.6390\n",
            "Min loss -1.64\n",
            "====> Epoch: 38 Average train loss: -1.6502\n",
            "====> Epoch: 38 Average val loss: -1.5961\n",
            "====> Epoch: 39 Average train loss: -1.6470\n",
            "====> Epoch: 39 Average val loss: -1.6071\n",
            "====> Epoch: 40 Average train loss: -1.6799\n",
            "====> Epoch: 40 Average val loss: -1.5924\n",
            "====> Epoch: 41 Average train loss: -1.6204\n",
            "====> Epoch: 41 Average val loss: -1.6246\n",
            "====> Epoch: 42 Average train loss: -1.6594\n",
            "====> Epoch: 42 Average val loss: -1.6324\n",
            "====> Epoch: 43 Average train loss: -1.6837\n",
            "====> Epoch: 43 Average val loss: -1.6509\n",
            "Min loss -1.65\n",
            "====> Epoch: 44 Average train loss: -1.6702\n",
            "====> Epoch: 44 Average val loss: -1.6187\n",
            "====> Epoch: 45 Average train loss: -1.6361\n",
            "====> Epoch: 45 Average val loss: -1.6216\n",
            "====> Epoch: 46 Average train loss: -1.6882\n",
            "====> Epoch: 46 Average val loss: -1.6368\n",
            "====> Epoch: 47 Average train loss: -1.6584\n",
            "====> Epoch: 47 Average val loss: -1.6530\n",
            "Min loss -1.65\n",
            "====> Epoch: 48 Average train loss: -1.6783\n",
            "====> Epoch: 48 Average val loss: -1.6372\n",
            "====> Epoch: 49 Average train loss: -1.7157\n",
            "====> Epoch: 49 Average val loss: -1.6323\n",
            "====> Epoch: 50 Average train loss: -1.7114\n",
            "====> Epoch: 50 Average val loss: -1.6162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ym0WfC6uOA-8"
      },
      "source": [
        "# Deep Canonically Correlated Autoencoders\r\n",
        "We need to add decoders in order to model deep canonically correlated autoencoders and we also use the DCCAE class which inherits from DCCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwiNJf-MOBOg",
        "outputId": "e779f36e-f5fd-4a71-e94e-72755de74232"
      },
      "source": [
        "from cca_zoo import dccae\r\n",
        "\r\n",
        "# DCCAE\r\n",
        "print('DCCAE')\r\n",
        "encoder_1 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\r\n",
        "encoder_2 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\r\n",
        "decoder_1 = deep_models.Decoder(latent_dims=latent_dims, feature_size=784)\r\n",
        "decoder_2 = deep_models.Decoder(latent_dims=latent_dims, feature_size=784)\r\n",
        "dccae_model = dccae.DCCAE(latent_dims=latent_dims, encoders=[encoder_1, encoder_2], decoders=[decoder_1, decoder_2])\r\n",
        "\r\n",
        "dccae_model = deepwrapper.DeepWrapper(dccae_model)\r\n",
        "\r\n",
        "dccae_model.fit(train_view_1, train_view_2, epochs=epochs)\r\n",
        "\r\n",
        "dccae_results = np.stack(\r\n",
        "    (dccae_model.train_correlations[0, 1], dccae_model.predict_corr(test_view_1, test_view_2)[0, 1]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DCCAE\n",
            "total parameters:  404516\n",
            "====> Epoch: 1 Average train loss: 32907.5391\n",
            "====> Epoch: 1 Average val loss: 27802.5078\n",
            "Min loss 27802.51\n",
            "====> Epoch: 2 Average train loss: 27708.0488\n",
            "====> Epoch: 2 Average val loss: 24035.3594\n",
            "Min loss 24035.36\n",
            "====> Epoch: 3 Average train loss: 23930.0234\n",
            "====> Epoch: 3 Average val loss: 21451.0508\n",
            "Min loss 21451.05\n",
            "====> Epoch: 4 Average train loss: 21329.8359\n",
            "====> Epoch: 4 Average val loss: 19741.1660\n",
            "Min loss 19741.17\n",
            "====> Epoch: 5 Average train loss: 19601.3438\n",
            "====> Epoch: 5 Average val loss: 18645.6992\n",
            "Min loss 18645.70\n",
            "====> Epoch: 6 Average train loss: 18487.0000\n",
            "====> Epoch: 6 Average val loss: 17987.4961\n",
            "Min loss 17987.50\n",
            "====> Epoch: 7 Average train loss: 17812.5781\n",
            "====> Epoch: 7 Average val loss: 17634.9453\n",
            "Min loss 17634.95\n",
            "====> Epoch: 8 Average train loss: 17448.5371\n",
            "====> Epoch: 8 Average val loss: 17476.7012\n",
            "Min loss 17476.70\n",
            "====> Epoch: 9 Average train loss: 17284.5312\n",
            "====> Epoch: 9 Average val loss: 17419.5684\n",
            "Min loss 17419.57\n",
            "====> Epoch: 10 Average train loss: 17227.1582\n",
            "====> Epoch: 10 Average val loss: 17399.9941\n",
            "Min loss 17399.99\n",
            "====> Epoch: 11 Average train loss: 17211.6211\n",
            "====> Epoch: 11 Average val loss: 17383.3379\n",
            "Min loss 17383.34\n",
            "====> Epoch: 12 Average train loss: 17201.7480\n",
            "====> Epoch: 12 Average val loss: 17352.1777\n",
            "Min loss 17352.18\n",
            "====> Epoch: 13 Average train loss: 17178.7539\n",
            "====> Epoch: 13 Average val loss: 17296.9785\n",
            "Min loss 17296.98\n",
            "====> Epoch: 14 Average train loss: 17132.0254\n",
            "====> Epoch: 14 Average val loss: 17213.6895\n",
            "Min loss 17213.69\n",
            "====> Epoch: 15 Average train loss: 17056.7441\n",
            "====> Epoch: 15 Average val loss: 17104.7363\n",
            "Min loss 17104.74\n",
            "====> Epoch: 16 Average train loss: 16955.0117\n",
            "====> Epoch: 16 Average val loss: 16978.0098\n",
            "Min loss 16978.01\n",
            "====> Epoch: 17 Average train loss: 16834.7461\n",
            "====> Epoch: 17 Average val loss: 16842.9961\n",
            "Min loss 16843.00\n",
            "====> Epoch: 18 Average train loss: 16705.6582\n",
            "====> Epoch: 18 Average val loss: 16707.0684\n",
            "Min loss 16707.07\n",
            "====> Epoch: 19 Average train loss: 16575.4336\n",
            "====> Epoch: 19 Average val loss: 16574.2520\n",
            "Min loss 16574.25\n",
            "====> Epoch: 20 Average train loss: 16448.2852\n",
            "====> Epoch: 20 Average val loss: 16445.9375\n",
            "Min loss 16445.94\n",
            "====> Epoch: 21 Average train loss: 16325.5527\n",
            "====> Epoch: 21 Average val loss: 16321.9297\n",
            "Min loss 16321.93\n",
            "====> Epoch: 22 Average train loss: 16206.7852\n",
            "====> Epoch: 22 Average val loss: 16201.0020\n",
            "Min loss 16201.00\n",
            "====> Epoch: 23 Average train loss: 16090.5830\n",
            "====> Epoch: 23 Average val loss: 16081.3066\n",
            "Min loss 16081.31\n",
            "====> Epoch: 24 Average train loss: 15975.0674\n",
            "====> Epoch: 24 Average val loss: 15960.7822\n",
            "Min loss 15960.78\n",
            "====> Epoch: 25 Average train loss: 15858.3691\n",
            "====> Epoch: 25 Average val loss: 15837.7715\n",
            "Min loss 15837.77\n",
            "====> Epoch: 26 Average train loss: 15739.1191\n",
            "====> Epoch: 26 Average val loss: 15711.5420\n",
            "Min loss 15711.54\n",
            "====> Epoch: 27 Average train loss: 15616.8477\n",
            "====> Epoch: 27 Average val loss: 15582.4805\n",
            "Min loss 15582.48\n",
            "====> Epoch: 28 Average train loss: 15492.0820\n",
            "====> Epoch: 28 Average val loss: 15451.7559\n",
            "Min loss 15451.76\n",
            "====> Epoch: 29 Average train loss: 15365.9531\n",
            "====> Epoch: 29 Average val loss: 15320.6553\n",
            "Min loss 15320.66\n",
            "====> Epoch: 30 Average train loss: 15239.6025\n",
            "====> Epoch: 30 Average val loss: 15190.2041\n",
            "Min loss 15190.20\n",
            "====> Epoch: 31 Average train loss: 15113.8398\n",
            "====> Epoch: 31 Average val loss: 15060.9980\n",
            "Min loss 15061.00\n",
            "====> Epoch: 32 Average train loss: 14989.1250\n",
            "====> Epoch: 32 Average val loss: 14933.2480\n",
            "Min loss 14933.25\n",
            "====> Epoch: 33 Average train loss: 14865.6787\n",
            "====> Epoch: 33 Average val loss: 14806.9229\n",
            "Min loss 14806.92\n",
            "====> Epoch: 34 Average train loss: 14743.6318\n",
            "====> Epoch: 34 Average val loss: 14681.8945\n",
            "Min loss 14681.89\n",
            "====> Epoch: 35 Average train loss: 14623.0498\n",
            "====> Epoch: 35 Average val loss: 14558.0195\n",
            "Min loss 14558.02\n",
            "====> Epoch: 36 Average train loss: 14503.8564\n",
            "====> Epoch: 36 Average val loss: 14435.2793\n",
            "Min loss 14435.28\n",
            "====> Epoch: 37 Average train loss: 14385.9023\n",
            "====> Epoch: 37 Average val loss: 14313.8828\n",
            "Min loss 14313.88\n",
            "====> Epoch: 38 Average train loss: 14269.1055\n",
            "====> Epoch: 38 Average val loss: 14194.2188\n",
            "Min loss 14194.22\n",
            "====> Epoch: 39 Average train loss: 14153.5303\n",
            "====> Epoch: 39 Average val loss: 14076.7461\n",
            "Min loss 14076.75\n",
            "====> Epoch: 40 Average train loss: 14039.3535\n",
            "====> Epoch: 40 Average val loss: 13961.8428\n",
            "Min loss 13961.84\n",
            "====> Epoch: 41 Average train loss: 13926.7910\n",
            "====> Epoch: 41 Average val loss: 13849.8682\n",
            "Min loss 13849.87\n",
            "====> Epoch: 42 Average train loss: 13816.1836\n",
            "====> Epoch: 42 Average val loss: 13741.2129\n",
            "Min loss 13741.21\n",
            "====> Epoch: 43 Average train loss: 13707.9561\n",
            "====> Epoch: 43 Average val loss: 13636.2676\n",
            "Min loss 13636.27\n",
            "====> Epoch: 44 Average train loss: 13602.4639\n",
            "====> Epoch: 44 Average val loss: 13535.4541\n",
            "Min loss 13535.45\n",
            "====> Epoch: 45 Average train loss: 13500.0967\n",
            "====> Epoch: 45 Average val loss: 13439.0791\n",
            "Min loss 13439.08\n",
            "====> Epoch: 46 Average train loss: 13401.3447\n",
            "====> Epoch: 46 Average val loss: 13347.1924\n",
            "Min loss 13347.19\n",
            "====> Epoch: 47 Average train loss: 13306.5498\n",
            "====> Epoch: 47 Average val loss: 13259.6953\n",
            "Min loss 13259.70\n",
            "====> Epoch: 48 Average train loss: 13215.9121\n",
            "====> Epoch: 48 Average val loss: 13176.6025\n",
            "Min loss 13176.60\n",
            "====> Epoch: 49 Average train loss: 13129.6270\n",
            "====> Epoch: 49 Average val loss: 13097.9678\n",
            "Min loss 13097.97\n",
            "====> Epoch: 50 Average train loss: 13047.8174\n",
            "====> Epoch: 50 Average val loss: 13023.6982\n",
            "Min loss 13023.70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwOTBYZ0O9SP"
      },
      "source": [
        "# Deep Variational CCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SogqelCuO9rm",
        "outputId": "dbc2c828-d821-4380-8854-49918aef963e"
      },
      "source": [
        "\"\"\"\r\n",
        "### Deep Variational Learning\r\n",
        "Finally we have Deep Variational CCA methods.\r\n",
        "- Deep Variational CCA (DVCCA)\r\n",
        "- Deep Variational CCA - private (DVVCA_p)\r\n",
        "\r\n",
        "These are both implemented by the DVCCA class with private=True/False and both_encoders=True/False. If both_encoders,\r\n",
        "the encoder to the shared information Q(z_shared|x) is modelled for both x_1 and x_2 whereas if both_encoders is false\r\n",
        "it is modelled for x_1 as in the paper\r\n",
        "\"\"\"\r\n",
        "from cca_zoo import dvcca\r\n",
        "\r\n",
        "# %%\r\n",
        "# DVCCA (technically bi-DVCCA)\r\n",
        "print('DVCCA')\r\n",
        "encoder_1 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\r\n",
        "encoder_2 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\r\n",
        "decoder_1 = deep_models.Decoder(latent_dims=latent_dims, feature_size=784, norm_output=True)\r\n",
        "decoder_2 = deep_models.Decoder(latent_dims=latent_dims, feature_size=784, norm_output=True)\r\n",
        "dvcca_model = dvcca.DVCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2], decoders=[decoder_1, decoder_2],\r\n",
        "                          private=False)\r\n",
        "\r\n",
        "dvcca_model = deepwrapper.DeepWrapper(dvcca_model)\r\n",
        "\r\n",
        "dvcca_model.fit(train_dataset, val_dataset, epochs=epochs)\r\n",
        "\r\n",
        "dvcca_model_results = np.stack(\r\n",
        "    (dvcca_model.train_correlations[0, 1], dvcca_model.predict_corr(test_view_1, test_view_2)[0, 1]))\r\n",
        "\r\n",
        "# DVCCA_private (technically bi-DVCCA_private)\r\n",
        "print('DVCCA_private')\r\n",
        "encoder_1 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\r\n",
        "encoder_2 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\r\n",
        "private_encoder_1 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\r\n",
        "private_encoder_2 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\r\n",
        "decoder_1 = deep_models.Decoder(latent_dims=latent_dims * 2, feature_size=784, norm_output=True)\r\n",
        "decoder_2 = deep_models.Decoder(latent_dims=latent_dims * 2, feature_size=784, norm_output=True)\r\n",
        "dvccap_model = dvcca.DVCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2], decoders=[decoder_1, decoder_2],\r\n",
        "                           private_encoders=[private_encoder_1, private_encoder_2], private=True)\r\n",
        "\r\n",
        "dvccap_model = deepwrapper.DeepWrapper(dvccap_model)\r\n",
        "\r\n",
        "dvccap_model.fit(train_dataset, val_dataset, epochs=epochs)\r\n",
        "\r\n",
        "dvccap_model_results = np.stack(\r\n",
        "    (dvccap_model.train_correlations[0, 1], dvccap_model.predict_corr(test_view_1, test_view_2)[0, 1]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DVCCA\n",
            "total parameters:  405032\n",
            "====> Epoch: 1 Average train loss: 1110.1912\n",
            "====> Epoch: 1 Average val loss: 1088.3569\n",
            "Min loss 1088.36\n",
            "====> Epoch: 2 Average train loss: 1088.2148\n",
            "====> Epoch: 2 Average val loss: 1067.7648\n",
            "Min loss 1067.76\n",
            "====> Epoch: 3 Average train loss: 1067.6774\n",
            "====> Epoch: 3 Average val loss: 1049.3245\n",
            "Min loss 1049.32\n",
            "====> Epoch: 4 Average train loss: 1049.3337\n",
            "====> Epoch: 4 Average val loss: 1031.4686\n",
            "Min loss 1031.47\n",
            "====> Epoch: 5 Average train loss: 1031.2385\n",
            "====> Epoch: 5 Average val loss: 1016.6136\n",
            "Min loss 1016.61\n",
            "====> Epoch: 6 Average train loss: 1014.9791\n",
            "====> Epoch: 6 Average val loss: 1001.1571\n",
            "Min loss 1001.16\n",
            "====> Epoch: 7 Average train loss: 1001.0985\n",
            "====> Epoch: 7 Average val loss: 988.1716\n",
            "Min loss 988.17\n",
            "====> Epoch: 8 Average train loss: 988.9889\n",
            "====> Epoch: 8 Average val loss: 976.9553\n",
            "Min loss 976.96\n",
            "====> Epoch: 9 Average train loss: 974.0115\n",
            "====> Epoch: 9 Average val loss: 965.7035\n",
            "Min loss 965.70\n",
            "====> Epoch: 10 Average train loss: 964.5316\n",
            "====> Epoch: 10 Average val loss: 956.2521\n",
            "Min loss 956.25\n",
            "====> Epoch: 11 Average train loss: 953.6492\n",
            "====> Epoch: 11 Average val loss: 946.6265\n",
            "Min loss 946.63\n",
            "====> Epoch: 12 Average train loss: 945.6373\n",
            "====> Epoch: 12 Average val loss: 935.9091\n",
            "Min loss 935.91\n",
            "====> Epoch: 13 Average train loss: 935.4236\n",
            "====> Epoch: 13 Average val loss: 929.9589\n",
            "Min loss 929.96\n",
            "====> Epoch: 14 Average train loss: 929.8121\n",
            "====> Epoch: 14 Average val loss: 924.9833\n",
            "Min loss 924.98\n",
            "====> Epoch: 15 Average train loss: 923.5316\n",
            "====> Epoch: 15 Average val loss: 918.4387\n",
            "Min loss 918.44\n",
            "====> Epoch: 16 Average train loss: 915.8567\n",
            "====> Epoch: 16 Average val loss: 912.1971\n",
            "Min loss 912.20\n",
            "====> Epoch: 17 Average train loss: 909.1552\n",
            "====> Epoch: 17 Average val loss: 904.9290\n",
            "Min loss 904.93\n",
            "====> Epoch: 18 Average train loss: 907.3363\n",
            "====> Epoch: 18 Average val loss: 895.9294\n",
            "Min loss 895.93\n",
            "====> Epoch: 19 Average train loss: 899.3442\n",
            "====> Epoch: 19 Average val loss: 896.8703\n",
            "====> Epoch: 20 Average train loss: 894.7240\n",
            "====> Epoch: 20 Average val loss: 892.1349\n",
            "Min loss 892.13\n",
            "====> Epoch: 21 Average train loss: 888.0685\n",
            "====> Epoch: 21 Average val loss: 887.0359\n",
            "Min loss 887.04\n",
            "====> Epoch: 22 Average train loss: 889.4491\n",
            "====> Epoch: 22 Average val loss: 885.6465\n",
            "Min loss 885.65\n",
            "====> Epoch: 23 Average train loss: 888.2942\n",
            "====> Epoch: 23 Average val loss: 886.7324\n",
            "====> Epoch: 24 Average train loss: 882.5817\n",
            "====> Epoch: 24 Average val loss: 881.2905\n",
            "Min loss 881.29\n",
            "====> Epoch: 25 Average train loss: 879.8373\n",
            "====> Epoch: 25 Average val loss: 877.3138\n",
            "Min loss 877.31\n",
            "====> Epoch: 26 Average train loss: 875.5851\n",
            "====> Epoch: 26 Average val loss: 871.8550\n",
            "Min loss 871.86\n",
            "====> Epoch: 27 Average train loss: 871.4105\n",
            "====> Epoch: 27 Average val loss: 873.2587\n",
            "====> Epoch: 28 Average train loss: 869.2275\n",
            "====> Epoch: 28 Average val loss: 871.5426\n",
            "Min loss 871.54\n",
            "====> Epoch: 29 Average train loss: 870.8988\n",
            "====> Epoch: 29 Average val loss: 869.4576\n",
            "Min loss 869.46\n",
            "====> Epoch: 30 Average train loss: 867.4475\n",
            "====> Epoch: 30 Average val loss: 867.4768\n",
            "Min loss 867.48\n",
            "====> Epoch: 31 Average train loss: 864.9745\n",
            "====> Epoch: 31 Average val loss: 866.7017\n",
            "Min loss 866.70\n",
            "====> Epoch: 32 Average train loss: 864.4260\n",
            "====> Epoch: 32 Average val loss: 865.1659\n",
            "Min loss 865.17\n",
            "====> Epoch: 33 Average train loss: 861.1597\n",
            "====> Epoch: 33 Average val loss: 859.8821\n",
            "Min loss 859.88\n",
            "====> Epoch: 34 Average train loss: 856.4635\n",
            "====> Epoch: 34 Average val loss: 857.9600\n",
            "Min loss 857.96\n",
            "====> Epoch: 35 Average train loss: 859.3276\n",
            "====> Epoch: 35 Average val loss: 858.4520\n",
            "====> Epoch: 36 Average train loss: 852.9229\n",
            "====> Epoch: 36 Average val loss: 858.6609\n",
            "====> Epoch: 37 Average train loss: 855.0237\n",
            "====> Epoch: 37 Average val loss: 855.1924\n",
            "Min loss 855.19\n",
            "====> Epoch: 38 Average train loss: 851.4760\n",
            "====> Epoch: 38 Average val loss: 851.5594\n",
            "Min loss 851.56\n",
            "====> Epoch: 39 Average train loss: 849.9170\n",
            "====> Epoch: 39 Average val loss: 850.4242\n",
            "Min loss 850.42\n",
            "====> Epoch: 40 Average train loss: 848.8440\n",
            "====> Epoch: 40 Average val loss: 848.8376\n",
            "Min loss 848.84\n",
            "====> Epoch: 41 Average train loss: 843.5593\n",
            "====> Epoch: 41 Average val loss: 849.3358\n",
            "====> Epoch: 42 Average train loss: 846.1602\n",
            "====> Epoch: 42 Average val loss: 847.4199\n",
            "Min loss 847.42\n",
            "====> Epoch: 43 Average train loss: 846.8466\n",
            "====> Epoch: 43 Average val loss: 845.1311\n",
            "Min loss 845.13\n",
            "====> Epoch: 44 Average train loss: 848.1917\n",
            "====> Epoch: 44 Average val loss: 844.7574\n",
            "Min loss 844.76\n",
            "====> Epoch: 45 Average train loss: 843.7889\n",
            "====> Epoch: 45 Average val loss: 846.4813\n",
            "====> Epoch: 46 Average train loss: 845.3593\n",
            "====> Epoch: 46 Average val loss: 841.5366\n",
            "Min loss 841.54\n",
            "====> Epoch: 47 Average train loss: 840.9749\n",
            "====> Epoch: 47 Average val loss: 841.2169\n",
            "Min loss 841.22\n",
            "====> Epoch: 48 Average train loss: 840.4537\n",
            "====> Epoch: 48 Average val loss: 842.5902\n",
            "====> Epoch: 49 Average train loss: 839.2661\n",
            "====> Epoch: 49 Average val loss: 838.5351\n",
            "Min loss 838.54\n",
            "====> Epoch: 50 Average train loss: 838.9827\n",
            "====> Epoch: 50 Average val loss: 832.7213\n",
            "Min loss 832.72\n",
            "DVCCA_private\n",
            "total parameters:  607536\n",
            "====> Epoch: 1 Average train loss: 1107.3865\n",
            "====> Epoch: 1 Average val loss: 1085.4265\n",
            "Min loss 1085.43\n",
            "====> Epoch: 2 Average train loss: 1085.6337\n",
            "====> Epoch: 2 Average val loss: 1065.2286\n",
            "Min loss 1065.23\n",
            "====> Epoch: 3 Average train loss: 1065.3132\n",
            "====> Epoch: 3 Average val loss: 1046.3669\n",
            "Min loss 1046.37\n",
            "====> Epoch: 4 Average train loss: 1046.5200\n",
            "====> Epoch: 4 Average val loss: 1029.9766\n",
            "Min loss 1029.98\n",
            "====> Epoch: 5 Average train loss: 1029.3950\n",
            "====> Epoch: 5 Average val loss: 1013.3016\n",
            "Min loss 1013.30\n",
            "====> Epoch: 6 Average train loss: 1014.1763\n",
            "====> Epoch: 6 Average val loss: 999.5905\n",
            "Min loss 999.59\n",
            "====> Epoch: 7 Average train loss: 998.4175\n",
            "====> Epoch: 7 Average val loss: 985.7924\n",
            "Min loss 985.79\n",
            "====> Epoch: 8 Average train loss: 985.4335\n",
            "====> Epoch: 8 Average val loss: 974.6035\n",
            "Min loss 974.60\n",
            "====> Epoch: 9 Average train loss: 973.2162\n",
            "====> Epoch: 9 Average val loss: 962.4003\n",
            "Min loss 962.40\n",
            "====> Epoch: 10 Average train loss: 961.1428\n",
            "====> Epoch: 10 Average val loss: 951.9128\n",
            "Min loss 951.91\n",
            "====> Epoch: 11 Average train loss: 950.9050\n",
            "====> Epoch: 11 Average val loss: 942.0867\n",
            "Min loss 942.09\n",
            "====> Epoch: 12 Average train loss: 942.1488\n",
            "====> Epoch: 12 Average val loss: 932.0648\n",
            "Min loss 932.06\n",
            "====> Epoch: 13 Average train loss: 935.9381\n",
            "====> Epoch: 13 Average val loss: 927.1044\n",
            "Min loss 927.10\n",
            "====> Epoch: 14 Average train loss: 926.0721\n",
            "====> Epoch: 14 Average val loss: 920.7079\n",
            "Min loss 920.71\n",
            "====> Epoch: 15 Average train loss: 919.6794\n",
            "====> Epoch: 15 Average val loss: 916.0655\n",
            "Min loss 916.07\n",
            "====> Epoch: 16 Average train loss: 911.7233\n",
            "====> Epoch: 16 Average val loss: 909.2602\n",
            "Min loss 909.26\n",
            "====> Epoch: 17 Average train loss: 909.6561\n",
            "====> Epoch: 17 Average val loss: 902.0276\n",
            "Min loss 902.03\n",
            "====> Epoch: 18 Average train loss: 901.6588\n",
            "====> Epoch: 18 Average val loss: 897.7151\n",
            "Min loss 897.72\n",
            "====> Epoch: 19 Average train loss: 895.8136\n",
            "====> Epoch: 19 Average val loss: 896.1954\n",
            "Min loss 896.20\n",
            "====> Epoch: 20 Average train loss: 889.6052\n",
            "====> Epoch: 20 Average val loss: 891.8663\n",
            "Min loss 891.87\n",
            "====> Epoch: 21 Average train loss: 892.3069\n",
            "====> Epoch: 21 Average val loss: 887.1937\n",
            "Min loss 887.19\n",
            "====> Epoch: 22 Average train loss: 884.6244\n",
            "====> Epoch: 22 Average val loss: 884.6281\n",
            "Min loss 884.63\n",
            "====> Epoch: 23 Average train loss: 878.5243\n",
            "====> Epoch: 23 Average val loss: 879.8505\n",
            "Min loss 879.85\n",
            "====> Epoch: 24 Average train loss: 882.2972\n",
            "====> Epoch: 24 Average val loss: 878.3494\n",
            "Min loss 878.35\n",
            "====> Epoch: 25 Average train loss: 880.3298\n",
            "====> Epoch: 25 Average val loss: 878.1654\n",
            "Min loss 878.17\n",
            "====> Epoch: 26 Average train loss: 875.1782\n",
            "====> Epoch: 26 Average val loss: 873.3229\n",
            "Min loss 873.32\n",
            "====> Epoch: 27 Average train loss: 869.8702\n",
            "====> Epoch: 27 Average val loss: 871.6789\n",
            "Min loss 871.68\n",
            "====> Epoch: 28 Average train loss: 869.3588\n",
            "====> Epoch: 28 Average val loss: 870.0730\n",
            "Min loss 870.07\n",
            "====> Epoch: 29 Average train loss: 870.1843\n",
            "====> Epoch: 29 Average val loss: 868.4824\n",
            "Min loss 868.48\n",
            "====> Epoch: 30 Average train loss: 870.1272\n",
            "====> Epoch: 30 Average val loss: 867.7911\n",
            "Min loss 867.79\n",
            "====> Epoch: 31 Average train loss: 866.5523\n",
            "====> Epoch: 31 Average val loss: 866.8175\n",
            "Min loss 866.82\n",
            "====> Epoch: 32 Average train loss: 864.8517\n",
            "====> Epoch: 32 Average val loss: 859.6826\n",
            "Min loss 859.68\n",
            "====> Epoch: 33 Average train loss: 862.2565\n",
            "====> Epoch: 33 Average val loss: 862.9545\n",
            "====> Epoch: 34 Average train loss: 859.1375\n",
            "====> Epoch: 34 Average val loss: 863.4701\n",
            "====> Epoch: 35 Average train loss: 859.1638\n",
            "====> Epoch: 35 Average val loss: 853.9283\n",
            "Min loss 853.93\n",
            "====> Epoch: 36 Average train loss: 860.2810\n",
            "====> Epoch: 36 Average val loss: 865.6420\n",
            "====> Epoch: 37 Average train loss: 857.3210\n",
            "====> Epoch: 37 Average val loss: 855.6506\n",
            "====> Epoch: 38 Average train loss: 856.6342\n",
            "====> Epoch: 38 Average val loss: 851.6082\n",
            "Min loss 851.61\n",
            "====> Epoch: 39 Average train loss: 861.5029\n",
            "====> Epoch: 39 Average val loss: 857.6553\n",
            "====> Epoch: 40 Average train loss: 853.2531\n",
            "====> Epoch: 40 Average val loss: 856.8270\n",
            "====> Epoch: 41 Average train loss: 852.0042\n",
            "====> Epoch: 41 Average val loss: 850.2716\n",
            "Min loss 850.27\n",
            "====> Epoch: 42 Average train loss: 854.0242\n",
            "====> Epoch: 42 Average val loss: 851.6593\n",
            "====> Epoch: 43 Average train loss: 854.0540\n",
            "====> Epoch: 43 Average val loss: 851.9764\n",
            "====> Epoch: 44 Average train loss: 850.8811\n",
            "====> Epoch: 44 Average val loss: 850.5092\n",
            "====> Epoch: 45 Average train loss: 846.4337\n",
            "====> Epoch: 45 Average val loss: 849.0243\n",
            "Min loss 849.02\n",
            "====> Epoch: 46 Average train loss: 850.2129\n",
            "====> Epoch: 46 Average val loss: 849.5294\n",
            "====> Epoch: 47 Average train loss: 846.9133\n",
            "====> Epoch: 47 Average val loss: 846.9513\n",
            "Min loss 846.95\n",
            "====> Epoch: 48 Average train loss: 843.5503\n",
            "====> Epoch: 48 Average val loss: 847.5908\n",
            "====> Epoch: 49 Average train loss: 844.6978\n",
            "====> Epoch: 49 Average val loss: 842.6495\n",
            "Min loss 842.65\n",
            "====> Epoch: 50 Average train loss: 839.9466\n",
            "====> Epoch: 50 Average val loss: 843.2615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCMeGlxJkp93"
      },
      "source": [
        "# Convolutional Deep CCA (and using other architectures)\r\n",
        "We provide a standard CNN encoder and decoder but users can build their own encoders and decoders by inheriting BaseEncoder and BaseDecoder for seamless integration with the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9TEto00kpn2",
        "outputId": "903d8bc8-97a0-4757-c288-b8a747102f21"
      },
      "source": [
        "print('Convolutional DCCA')\r\n",
        "encoder_1 = deep_models.CNNEncoder(latent_dims=latent_dims, channels=[3, 3])\r\n",
        "encoder_2 = deep_models.CNNEncoder(latent_dims=latent_dims, channels=[3, 3])\r\n",
        "dcca_conv_model = dcca.DCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2])\r\n",
        "\r\n",
        "dcca_conv_model = deepwrapper.DeepWrapper(dcca_conv_model)\r\n",
        "\r\n",
        "# to change the models used change the cfg.encoder_models. We implement a CNN_Encoder and CNN_decoder as well\r\n",
        "# as some based on brainnet architecture in cca_zoo.deep_models. Equally you could pass your own encoder/decoder models\r\n",
        "\r\n",
        "dcca_conv_model.fit(train_view_1.reshape((-1, 1, 28, 28)), train_view_2.reshape((-1, 1, 28, 28)), epochs=epochs)\r\n",
        "\r\n",
        "dcca_conv_results = np.stack(\r\n",
        "    (dcca_conv_model.train_correlations[0, 1], dcca_conv_model.predict_corr(test_view_1.reshape((-1, 1, 28, 28)),\r\n",
        "                                                                            test_view_2.reshape(\r\n",
        "                                                                                (-1, 1, 28, 28)))[0, 1]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Convolutional DCCA\n",
            "total parameters:  9568\n",
            "====> Epoch: 1 Average train loss: -0.1122\n",
            "====> Epoch: 1 Average val loss: -0.6000\n",
            "Min loss -0.60\n",
            "====> Epoch: 2 Average train loss: -0.6667\n",
            "====> Epoch: 2 Average val loss: -0.8313\n",
            "Min loss -0.83\n",
            "====> Epoch: 3 Average train loss: -1.0002\n",
            "====> Epoch: 3 Average val loss: -0.9811\n",
            "Min loss -0.98\n",
            "====> Epoch: 4 Average train loss: -1.2072\n",
            "====> Epoch: 4 Average val loss: -1.0786\n",
            "Min loss -1.08\n",
            "====> Epoch: 5 Average train loss: -1.3414\n",
            "====> Epoch: 5 Average val loss: -1.1450\n",
            "Min loss -1.14\n",
            "====> Epoch: 6 Average train loss: -1.4371\n",
            "====> Epoch: 6 Average val loss: -1.1919\n",
            "Min loss -1.19\n",
            "====> Epoch: 7 Average train loss: -1.5117\n",
            "====> Epoch: 7 Average val loss: -1.2256\n",
            "Min loss -1.23\n",
            "====> Epoch: 8 Average train loss: -1.5730\n",
            "====> Epoch: 8 Average val loss: -1.2490\n",
            "Min loss -1.25\n",
            "====> Epoch: 9 Average train loss: -1.6245\n",
            "====> Epoch: 9 Average val loss: -1.2644\n",
            "Min loss -1.26\n",
            "====> Epoch: 10 Average train loss: -1.6675\n",
            "====> Epoch: 10 Average val loss: -1.2740\n",
            "Min loss -1.27\n",
            "====> Epoch: 11 Average train loss: -1.7030\n",
            "====> Epoch: 11 Average val loss: -1.2811\n",
            "Min loss -1.28\n",
            "====> Epoch: 12 Average train loss: -1.7330\n",
            "====> Epoch: 12 Average val loss: -1.2885\n",
            "Min loss -1.29\n",
            "====> Epoch: 13 Average train loss: -1.7601\n",
            "====> Epoch: 13 Average val loss: -1.2968\n",
            "Min loss -1.30\n",
            "====> Epoch: 14 Average train loss: -1.7846\n",
            "====> Epoch: 14 Average val loss: -1.3045\n",
            "Min loss -1.30\n",
            "====> Epoch: 15 Average train loss: -1.8058\n",
            "====> Epoch: 15 Average val loss: -1.3108\n",
            "Min loss -1.31\n",
            "====> Epoch: 16 Average train loss: -1.8235\n",
            "====> Epoch: 16 Average val loss: -1.3157\n",
            "Min loss -1.32\n",
            "====> Epoch: 17 Average train loss: -1.8385\n",
            "====> Epoch: 17 Average val loss: -1.3194\n",
            "Min loss -1.32\n",
            "====> Epoch: 18 Average train loss: -1.8517\n",
            "====> Epoch: 18 Average val loss: -1.3220\n",
            "Min loss -1.32\n",
            "====> Epoch: 19 Average train loss: -1.8636\n",
            "====> Epoch: 19 Average val loss: -1.3238\n",
            "Min loss -1.32\n",
            "====> Epoch: 20 Average train loss: -1.8744\n",
            "====> Epoch: 20 Average val loss: -1.3248\n",
            "Min loss -1.32\n",
            "====> Epoch: 21 Average train loss: -1.8841\n",
            "====> Epoch: 21 Average val loss: -1.3250\n",
            "Min loss -1.33\n",
            "====> Epoch: 22 Average train loss: -1.8926\n",
            "====> Epoch: 22 Average val loss: -1.3250\n",
            "====> Epoch: 23 Average train loss: -1.8999\n",
            "====> Epoch: 23 Average val loss: -1.3251\n",
            "Min loss -1.33\n",
            "====> Epoch: 24 Average train loss: -1.9063\n",
            "====> Epoch: 24 Average val loss: -1.3259\n",
            "Min loss -1.33\n",
            "====> Epoch: 25 Average train loss: -1.9120\n",
            "====> Epoch: 25 Average val loss: -1.3276\n",
            "Min loss -1.33\n",
            "====> Epoch: 26 Average train loss: -1.9175\n",
            "====> Epoch: 26 Average val loss: -1.3303\n",
            "Min loss -1.33\n",
            "====> Epoch: 27 Average train loss: -1.9227\n",
            "====> Epoch: 27 Average val loss: -1.3335\n",
            "Min loss -1.33\n",
            "====> Epoch: 28 Average train loss: -1.9276\n",
            "====> Epoch: 28 Average val loss: -1.3368\n",
            "Min loss -1.34\n",
            "====> Epoch: 29 Average train loss: -1.9321\n",
            "====> Epoch: 29 Average val loss: -1.3398\n",
            "Min loss -1.34\n",
            "====> Epoch: 30 Average train loss: -1.9362\n",
            "====> Epoch: 30 Average val loss: -1.3422\n",
            "Min loss -1.34\n",
            "====> Epoch: 31 Average train loss: -1.9398\n",
            "====> Epoch: 31 Average val loss: -1.3440\n",
            "Min loss -1.34\n",
            "====> Epoch: 32 Average train loss: -1.9430\n",
            "====> Epoch: 32 Average val loss: -1.3451\n",
            "Min loss -1.35\n",
            "====> Epoch: 33 Average train loss: -1.9459\n",
            "====> Epoch: 33 Average val loss: -1.3454\n",
            "Min loss -1.35\n",
            "====> Epoch: 34 Average train loss: -1.9485\n",
            "====> Epoch: 34 Average val loss: -1.3451\n",
            "====> Epoch: 35 Average train loss: -1.9508\n",
            "====> Epoch: 35 Average val loss: -1.3444\n",
            "====> Epoch: 36 Average train loss: -1.9529\n",
            "====> Epoch: 36 Average val loss: -1.3433\n",
            "====> Epoch: 37 Average train loss: -1.9547\n",
            "====> Epoch: 37 Average val loss: -1.3422\n",
            "====> Epoch: 38 Average train loss: -1.9563\n",
            "====> Epoch: 38 Average val loss: -1.3413\n",
            "====> Epoch: 39 Average train loss: -1.9578\n",
            "====> Epoch: 39 Average val loss: -1.3407\n",
            "====> Epoch: 40 Average train loss: -1.9593\n",
            "====> Epoch: 40 Average val loss: -1.3405\n",
            "====> Epoch: 41 Average train loss: -1.9607\n",
            "====> Epoch: 41 Average val loss: -1.3408\n",
            "====> Epoch: 42 Average train loss: -1.9621\n",
            "====> Epoch: 42 Average val loss: -1.3413\n",
            "====> Epoch: 43 Average train loss: -1.9634\n",
            "====> Epoch: 43 Average val loss: -1.3419\n",
            "====> Epoch: 44 Average train loss: -1.9646\n",
            "====> Epoch: 44 Average val loss: -1.3425\n",
            "====> Epoch: 45 Average train loss: -1.9656\n",
            "====> Epoch: 45 Average val loss: -1.3431\n",
            "====> Epoch: 46 Average train loss: -1.9666\n",
            "====> Epoch: 46 Average val loss: -1.3434\n",
            "====> Epoch: 47 Average train loss: -1.9675\n",
            "====> Epoch: 47 Average val loss: -1.3436\n",
            "====> Epoch: 48 Average train loss: -1.9684\n",
            "====> Epoch: 48 Average val loss: -1.3436\n",
            "====> Epoch: 49 Average train loss: -1.9692\n",
            "====> Epoch: 49 Average val loss: -1.3436\n",
            "====> Epoch: 50 Average train loss: -1.9700\n",
            "====> Epoch: 50 Average val loss: -1.3436\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhYAL8vxkiAh"
      },
      "source": [
        "# Generate Some Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNeUaqjwhcj7"
      },
      "source": [
        "\"\"\"\r\n",
        "### Make results plot to compare methods\r\n",
        "\"\"\"\r\n",
        "# %%\r\n",
        "\r\n",
        "all_results = np.stack(\r\n",
        "    [linear_cca_results, gcca_results, mcca_results, pls_results, pmd_results, elastic_results,\r\n",
        "     scca_results, kernel_reg_results, kernel_poly_results,\r\n",
        "     kernel_gaussian_results, dcca_results, dgcca_results, dmcca_results, dvcca_model_results,\r\n",
        "     dcca_conv_results],\r\n",
        "    axis=0)\r\n",
        "all_labels = ['linear', 'gcca', 'mcca', 'pls', 'pmd', 'elastic', 'scca', 'linear kernel', 'polynomial kernel',\r\n",
        "              'gaussian kernel', 'deep CCA', 'deep generalized CCA', 'deep multiset CCA', 'deep VCCA',\r\n",
        "              'deep convolutional cca']\r\n",
        "\r\n",
        "from cca_zoo import plot_utils\r\n",
        "\r\n",
        "plot_utils.plot_results(all_results, all_labels)\r\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wgDHziqYJZX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}