{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cca-zoo-tutorial.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMCqTZE/0bfiWgRlQy8J9OX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jameschapman19/cca_zoo/blob/master/cca_zoo_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFVm_oT3cmZH",
        "outputId": "0aa3cc24-300c-4ef5-cb77-1fddc3f39c76"
      },
      "source": [
        "!pip install cca-zoo --upgrade\n",
        "!pip install scipy --upgrade"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: cca-zoo in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from cca-zoo) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: seaborn in /usr/local/lib/python3.7/dist-packages (from cca-zoo) (0.11.1)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from cca-zoo) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.7/dist-packages (from cca-zoo) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from cca-zoo) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=1.5 in /usr/local/lib/python3.7/dist-packages (from cca-zoo) (1.6.2)\n",
            "Requirement already satisfied, skipping upgrade: Pillow in /usr/local/lib/python3.7/dist-packages (from cca-zoo) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->cca-zoo) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->cca-zoo) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->cca-zoo) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cca-zoo) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cca-zoo) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cca-zoo) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->cca-zoo) (1.15.0)\n",
            "Requirement already up-to-date: scipy in /usr/local/lib/python3.7/dist-packages (1.6.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFsRNCJ0crH8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00e8b144-21e1-4611-e95f-467a054e5a3e"
      },
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "from cca_zoo import wrappers\n",
        "from cca_zoo import data\n",
        "import itertools\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Subset\n",
        "from torch import optim\n",
        "\n",
        "# Load MNIST Data\n",
        "os.chdir('..')\n",
        "N = 500\n",
        "dataset = data.Noisy_MNIST_Dataset(mnist_type='FashionMNIST', train=True)\n",
        "ids = np.arange(min(2 * N, len(dataset)))\n",
        "np.random.shuffle(ids)\n",
        "train_ids, val_ids = np.array_split(ids, 2)\n",
        "val_dataset = Subset(dataset, val_ids)\n",
        "train_dataset = Subset(dataset, train_ids)\n",
        "test_dataset = data.Noisy_MNIST_Dataset(mnist_type='FashionMNIST', train=False)\n",
        "test_ids = np.arange(min(N, len(test_dataset)))\n",
        "np.random.shuffle(test_ids)\n",
        "test_dataset = Subset(test_dataset, test_ids)\n",
        "train_view_1, train_view_2, train_rotations, train_OH_labels, train_labels = train_dataset.dataset.to_numpy(\n",
        "    train_dataset.indices)\n",
        "val_view_1, val_view_2, val_rotations, val_OH_labels, val_labels = val_dataset.dataset.to_numpy(val_dataset.indices)\n",
        "test_view_1, test_view_2, test_rotations, test_OH_labels, test_labels = test_dataset.dataset.to_numpy(\n",
        "    test_dataset.indices)\n",
        "\n",
        "# Settings\n",
        "\n",
        "# The number of latent dimensions across models\n",
        "latent_dims = 2\n",
        "# The number of folds used for cross-validation/hyperparameter tuning\n",
        "cv_folds = 5\n",
        "# For running hyperparameter tuning in parallel (0 if not)\n",
        "jobs = 2\n",
        "# Number of iterations for iterative algorithms\n",
        "max_iter = 2\n",
        "# number of epochs for deep models\n",
        "epochs = 50"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:936: UserWarning: Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\n",
            "  \"Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOryUM6ShmQf"
      },
      "source": [
        "# Canonical Correlation Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSGgSD7vgh1b"
      },
      "source": [
        "\"\"\"\n",
        "### Linear CCA by eigendecomposition\n",
        "\"\"\"\n",
        "linear_cca = wrappers.CCA(latent_dims=latent_dims)\n",
        "\n",
        "linear_cca.fit(train_view_1, train_view_2)\n",
        "\n",
        "linear_cca_results = np.stack(\n",
        "    (linear_cca.train_correlations[0, 1], linear_cca.predict_corr(test_view_1, test_view_2)[0, 1]))\n",
        "\n",
        "\"\"\"\n",
        "### Linear CCA by alternating least squares (can pass more than 2 views)\n",
        "\"\"\"\n",
        "\n",
        "linear_cca_als = wrappers.CCA_ALS(latent_dims=latent_dims)\n",
        "\n",
        "linear_cca_als.fit(train_view_1, train_view_2)\n",
        "\n",
        "linear_cca_als_results = np.stack(\n",
        "    (linear_cca_als.train_correlations[0, 1], linear_cca_als.predict_corr(test_view_1, test_view_2)[0, 1]))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZtZUfZ3huKE"
      },
      "source": [
        "# Partial Least Squares\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei3rASx3ghtJ"
      },
      "source": [
        "\"\"\"\n",
        "### PLS with scikit-learn (only permits 2 views)\n",
        "\"\"\"\n",
        "pls = wrappers.PLS(latent_dims=latent_dims)\n",
        "\n",
        "pls.fit(train_view_1, train_view_2)\n",
        "\n",
        "pls_results = np.stack(\n",
        "    (pls.train_correlations[0, 1], pls.predict_corr(test_view_1, test_view_2)[0, 1]))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88vAaUxIi1H7"
      },
      "source": [
        "# Extension to multiple views\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Fx0dj8GghbD"
      },
      "source": [
        "\"\"\"\n",
        "### (Regularized) Generalized CCA(can pass more than 2 views)\n",
        "\"\"\"\n",
        "# small ammount of regularisation added since data is not full rank\n",
        "c=[0.5,0.5,0.5]\n",
        "\n",
        "gcca = wrappers.GCCA(latent_dims=latent_dims,c=c)\n",
        "\n",
        "gcca.fit(train_view_1, train_view_2,train_view_1)\n",
        "\n",
        "gcca_results = np.stack((gcca.train_correlations[0, 1], gcca.predict_corr(test_view_1, test_view_2)[0, 1]))\n",
        "\n",
        "\"\"\"\n",
        "### (Regularized) Multiset CCA(can pass more than 2 views)\n",
        "\"\"\"\n",
        "\n",
        "mcca = wrappers.MCCA(latent_dims=latent_dims, c=c)\n",
        "\n",
        "mcca.fit(train_view_1, train_view_2,train_view_1)\n",
        "\n",
        "mcca_results = np.stack((mcca.train_correlations[0, 1], mcca.predict_corr(test_view_1, test_view_2)[0, 1]))\n",
        "\n",
        "\"\"\"\n",
        "### Multiset CCA by alternating least squares\n",
        "\"\"\"\n",
        "mcca_als = wrappers.CCA_ALS(latent_dims=latent_dims, max_iter=max_iter)\n",
        "\n",
        "mcca_als.fit(train_view_1, train_view_2,train_view_1)\n",
        "\n",
        "mcca_als_results = np.stack(\n",
        "    (mcca_als.train_correlations[0, 1], mcca_als.predict_corr(test_view_1, test_view_2)[0, 1]))\n",
        "\n",
        "\"\"\"\n",
        "### Multiset PLS by alternating least squares\n",
        "\"\"\"\n",
        "mcca_pls = wrappers.PLS(latent_dims=latent_dims, max_iter=max_iter)\n",
        "\n",
        "mcca_pls.fit(train_view_1, train_view_2,train_view_1)\n",
        "\n",
        "mcca_pls_results = np.stack(\n",
        "    (mcca_als.train_correlations[0, 1], mcca_pls.predict_corr(test_view_1, test_view_2)[0, 1]))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-J9QturUVUE"
      },
      "source": [
        "# Weighted GCCA/Missing Observation GCCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58A4v1p_UVio"
      },
      "source": [
        "#observation_matrix\n",
        "K = np.ones((3, N))\n",
        "K[0, 200:] = 0\n",
        "K[1, :100] = 0\n",
        "\n",
        "#view weights\n",
        "view_weights=[1,2,1.2]\n",
        "\n",
        "c=[0.5,0.5,0.5]\n",
        "\n",
        "gcca = wrappers.GCCA(latent_dims=latent_dims,c=c,view_weights=view_weights)\n",
        "\n",
        "gcca.fit(train_view_1, train_view_2,train_view_1,K=K)\n",
        "\n",
        "gcca_results = np.stack((gcca.train_correlations[0, 1], gcca.predict_corr(test_view_1, test_view_2)[0, 1]))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9847WJ3liT6v"
      },
      "source": [
        "# Rgularised CCA solutions based on alternating minimisation/alternating least squares\n",
        "\n",
        "We implement Witten's penalized matrix decomposition form of sparse CCA using 'pmd'\n",
        "\n",
        "We implement Waaijenborg's penalized CCA using elastic net using 'elastic'\n",
        "\n",
        "We implement Mai's sparse CCA using 'scca'\n",
        "\n",
        "Furthermore, any of these methods can be extended to multiple views. Witten describes this method explicitly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts_yQvzdhDQe",
        "outputId": "83a4e227-da6b-4ac5-b68f-02c4fcb447e5"
      },
      "source": [
        "\"\"\"\n",
        "### Ridge CCA (can pass more than 2 views)\n",
        "\"\"\"\n",
        "c1 = [0.1, 0.3, 0.7, 0.9]\n",
        "c2 = [0.1, 0.3, 0.7, 0.9]\n",
        "param_candidates = {'c': list(itertools.product(c1, c2))}\n",
        "\n",
        "ridge = wrappers.rCCA(latent_dims=latent_dims).gridsearch_fit(\n",
        "    train_view_1,\n",
        "    train_view_2,\n",
        "    param_candidates=param_candidates,\n",
        "    folds=cv_folds,\n",
        "    verbose=True, jobs=jobs,\n",
        "    plot=True)\n",
        "\n",
        "ridge_results = np.stack((ridge.train_correlations[0, 1, :], ridge.predict_corr(test_view_1, test_view_2)[0, 1, :]))\n",
        "\n",
        "\"\"\"\n",
        "### Sparse CCA (Penalized Matrix Decomposition) (can pass more than 2 views)\n",
        "\"\"\"\n",
        "\n",
        "# PMD\n",
        "c1 = [1, 3, 7, 9]\n",
        "c2 = [1, 3, 7, 9]\n",
        "param_candidates = {'c': list(itertools.product(c1, c2))}\n",
        "\n",
        "pmd = wrappers.PMD(latent_dims=latent_dims, max_iter=max_iter).gridsearch_fit(\n",
        "    train_view_1,\n",
        "    train_view_2,\n",
        "    param_candidates=param_candidates,\n",
        "    folds=cv_folds,\n",
        "    verbose=True, jobs=jobs,\n",
        "    plot=True)\n",
        "\n",
        "pmd_results = np.stack((pmd.train_correlations[0, 1, :], pmd.predict_corr(test_view_1, test_view_2)[0, 1, :]))\n",
        "\n",
        "\"\"\"\n",
        "### Sparse CCA (can pass more than 2 views)\n",
        "\"\"\"\n",
        "\n",
        "# Sparse CCA\n",
        "c1 = [0.00001, 0.0001]\n",
        "c2 = [0.00001, 0.0001]\n",
        "param_candidates = {'c': list(itertools.product(c1, c2))}\n",
        "\n",
        "scca = wrappers.SCCA(latent_dims=latent_dims, max_iter=max_iter).gridsearch_fit(\n",
        "    train_view_1,\n",
        "    train_view_2,\n",
        "    param_candidates=param_candidates,\n",
        "    folds=cv_folds,\n",
        "    verbose=True,\n",
        "    jobs=jobs, plot=True)\n",
        "\n",
        "scca_results = np.stack(\n",
        "    (scca.train_correlations[0, 1, :], scca.predict_corr(test_view_1, test_view_2)[0, 1, :]))\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "### Elastic CCA (can pass more than 2 views)\n",
        "\"\"\"\n",
        "\n",
        "# Elastic CCA\n",
        "c1 = [0.001, 0.0001]\n",
        "c2 = [0.001, 0.0001]\n",
        "l1_1 = [0.01, 0.1]\n",
        "l1_2 = [0.01, 0.1]\n",
        "param_candidates = {'c': list(itertools.product(c1, c2)), 'l1_ratio': list(itertools.product(l1_1, l1_2))}\n",
        "\n",
        "elastic = wrappers.ElasticCCA(latent_dims=latent_dims,\n",
        "                              max_iter=max_iter).gridsearch_fit(train_view_1,\n",
        "                                                                train_view_2,\n",
        "                                                                param_candidates=param_candidates,\n",
        "                                                                folds=cv_folds,\n",
        "                                                                verbose=True,\n",
        "                                                                jobs=jobs,\n",
        "                                                                plot=True)\n",
        "\n",
        "elastic_results = np.stack(\n",
        "    (elastic.train_correlations[0, 1, :], elastic.predict_corr(test_view_1, test_view_2)[0, 1, :]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cross validation\n",
            "number of folds:  5\n",
            "Best score :  1.1580229366975092\n",
            "Standard deviation :  0.0744296519833356\n",
            "{'c': (0.9, 0.9)}\n",
            "cross validation\n",
            "number of folds:  5\n",
            "Best score :  1.2096107222263128\n",
            "Standard deviation :  0.07042732486816454\n",
            "{'c': (9, 9)}\n",
            "cross validation\n",
            "number of folds:  5\n",
            "Best score :  0.7671002196854806\n",
            "Standard deviation :  0.11205946080012376\n",
            "{'c': (0.0001, 1e-05)}\n",
            "cross validation\n",
            "number of folds:  5\n",
            "Best score :  0.8174683020077215\n",
            "Standard deviation :  0.027509691263146254\n",
            "{'c': (0.001, 0.001), 'l1_ratio': (0.1, 0.01)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaHqF5CljrCb"
      },
      "source": [
        "# Kernel CCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtH38KO8hLFL",
        "outputId": "8cf1afc0-292e-49c7-ebb4-483c4fb3f072"
      },
      "source": [
        "\"\"\"\n",
        "### Kernel CCA\n",
        "\n",
        "Similarly, we can use kernel CCA methods with [method='kernel']\n",
        "\n",
        "We can use different kernels and their associated parameters in a similar manner to before\n",
        "- regularized linear kernel CCA: parameters :  'kernel'='linear', 0<'c'<1\n",
        "- polynomial kernel CCA: parameters : 'kernel'='poly', 'degree', 0<'c'<1\n",
        "- gaussian rbf kernel CCA: parameters : 'kernel'='gaussian', 'sigma', 0<'c'<1\n",
        "\"\"\"\n",
        "# %%\n",
        "# r-kernel cca\n",
        "c1 = [0.9, 0.99]\n",
        "c2 = [0.9, 0.99]\n",
        "\n",
        "param_candidates = {'kernel': ['linear'], 'c': list(itertools.product(c1, c2))}\n",
        "\n",
        "kernel_reg = wrappers.KCCA(latent_dims=latent_dims).gridsearch_fit(train_view_1, train_view_2,\n",
        "                                                                   folds=cv_folds,\n",
        "                                                                   param_candidates=param_candidates,\n",
        "                                                                   verbose=True, jobs=jobs,\n",
        "                                                                   plot=True)\n",
        "kernel_reg_results = np.stack((\n",
        "    kernel_reg.train_correlations[0, 1, :],\n",
        "    kernel_reg.predict_corr(test_view_1, test_view_2)[0, 1, :]))\n",
        "\n",
        "# kernel cca (poly)\n",
        "param_candidates = {'kernel': ['poly'], 'degree': [2, 3], 'c': list(itertools.product(c1, c2))}\n",
        "\n",
        "kernel_poly = wrappers.KCCA(latent_dims=latent_dims).gridsearch_fit(train_view_1, train_view_2,\n",
        "                                                                    folds=cv_folds,\n",
        "                                                                    param_candidates=param_candidates,\n",
        "                                                                    verbose=True, jobs=jobs,\n",
        "                                                                    plot=True)\n",
        "\n",
        "kernel_poly_results = np.stack((\n",
        "    kernel_poly.train_correlations[0, 1, :],\n",
        "    kernel_poly.predict_corr(test_view_1, test_view_2)[0, 1, :]))\n",
        "\n",
        "# kernel cca (gaussian)\n",
        "param_candidates = {'kernel': ['rbf'], 'sigma': [1e+1, 1e+2, 1e+3], 'c': list(itertools.product(c1, c2))}\n",
        "\n",
        "kernel_gaussian = wrappers.KCCA(latent_dims=latent_dims).gridsearch_fit(train_view_1, train_view_2,\n",
        "                                                                        folds=cv_folds,\n",
        "                                                                        param_candidates=param_candidates,\n",
        "                                                                        verbose=True, jobs=jobs,\n",
        "                                                                        plot=True)\n",
        "\n",
        "kernel_gaussian_results = np.stack((\n",
        "    kernel_gaussian.train_correlations[0, 1, :],\n",
        "    kernel_gaussian.predict_corr(test_view_1, test_view_2)[0, 1, :]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cross validation\n",
            "number of folds:  5\n",
            "Best score :  1.4173160345413034\n",
            "Standard deviation :  0.07843160389828484\n",
            "{'kernel': 'linear', 'c': (0.99, 0.99)}\n",
            "cross validation\n",
            "number of folds:  5\n",
            "Best score :  1.0184435578673425\n",
            "Standard deviation :  0.1203279634354833\n",
            "{'kernel': 'poly', 'degree': 3, 'c': (0.9, 0.9)}\n",
            "cross validation\n",
            "number of folds:  5\n",
            "Best score :  1.157831396516231\n",
            "Standard deviation :  0.11527570837893727\n",
            "{'kernel': 'rbf', 'sigma': 100.0, 'c': (0.99, 0.9)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44ltKrtIkICK"
      },
      "source": [
        "# Deep CCA\n",
        "\n",
        "DCCA can be optimized using Andrew's original tracenorm objective or Wang's DCCA by nonlinear orthogonal iterations using the argument als=True."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0nTlPSEhVeP",
        "outputId": "1b071c09-86c7-442c-e75f-b5c4c9cf714a"
      },
      "source": [
        "\"\"\"\n",
        "### Deep Learning\n",
        "\n",
        "We also have deep CCA methods (and autoencoder variants)\n",
        "- Deep CCA (DCCA)\n",
        "- Deep Canonically Correlated Autoencoders (DCCAE)\n",
        "\n",
        "We introduce a Config class from configuration.py. This contains a number of default settings for running DCCA.\n",
        "\n",
        "\"\"\"\n",
        "from cca_zoo import deepwrapper, objectives, dcca, deep_models\n",
        "\n",
        "# %%\n",
        "# DCCA\n",
        "print('DCCA')\n",
        "encoder_1 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\n",
        "encoder_2 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\n",
        "dcca_model = dcca.DCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2])\n",
        "\n",
        "dcca_model = deepwrapper.DeepWrapper(dcca_model)\n",
        "\n",
        "dcca_model.fit(train_dataset, val_dataset=val_dataset, epochs=epochs)\n",
        "\n",
        "dcca_results = np.stack((dcca_model.train_correlations[0, 1], dcca_model.predict_corr(test_dataset)[0, 1]))\n",
        "\n",
        "\n",
        "# DCCA_NOI\n",
        "# Note that als=True\n",
        "print('DCCA by non-linear orthogonal iterations')\n",
        "encoder_1 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\n",
        "encoder_2 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\n",
        "dcca_noi_model = dcca.DCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2], als=True)\n",
        "\n",
        "dcca_noi_model = deepwrapper.DeepWrapper(dcca_noi_model)\n",
        "\n",
        "dcca_noi_model.fit(train_dataset, val_dataset=val_dataset, epochs=epochs)\n",
        "\n",
        "dcca_noi_results = np.stack(\n",
        "    (dcca_noi_model.train_correlations[0, 1], dcca_noi_model.predict_corr(test_dataset)[0, 1]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DCCA\n",
            "total parameters:  201476\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:936: UserWarning: Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\n",
            "  \"Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "====> Epoch: 1 Average train loss: -0.2773\n",
            "====> Epoch: 1 Average val loss: -0.8487\n",
            "Min loss -0.85\n",
            "====> Epoch: 2 Average train loss: -0.6858\n",
            "====> Epoch: 2 Average val loss: -1.1395\n",
            "Min loss -1.14\n",
            "====> Epoch: 3 Average train loss: -1.0905\n",
            "====> Epoch: 3 Average val loss: -1.2920\n",
            "Min loss -1.29\n",
            "====> Epoch: 4 Average train loss: -1.1826\n",
            "====> Epoch: 4 Average val loss: -1.2559\n",
            "====> Epoch: 5 Average train loss: -1.3236\n",
            "====> Epoch: 5 Average val loss: -1.3220\n",
            "Min loss -1.32\n",
            "====> Epoch: 6 Average train loss: -1.2880\n",
            "====> Epoch: 6 Average val loss: -1.3762\n",
            "Min loss -1.38\n",
            "====> Epoch: 7 Average train loss: -1.2604\n",
            "====> Epoch: 7 Average val loss: -1.3424\n",
            "====> Epoch: 8 Average train loss: -1.3732\n",
            "====> Epoch: 8 Average val loss: -1.3888\n",
            "Min loss -1.39\n",
            "====> Epoch: 9 Average train loss: -1.3910\n",
            "====> Epoch: 9 Average val loss: -1.4136\n",
            "Min loss -1.41\n",
            "====> Epoch: 10 Average train loss: -1.3582\n",
            "====> Epoch: 10 Average val loss: -1.4313\n",
            "Min loss -1.43\n",
            "====> Epoch: 11 Average train loss: -1.3802\n",
            "====> Epoch: 11 Average val loss: -1.4669\n",
            "Min loss -1.47\n",
            "====> Epoch: 12 Average train loss: -1.3518\n",
            "====> Epoch: 12 Average val loss: -1.4688\n",
            "Min loss -1.47\n",
            "====> Epoch: 13 Average train loss: -1.4321\n",
            "====> Epoch: 13 Average val loss: -1.4310\n",
            "====> Epoch: 14 Average train loss: -1.3888\n",
            "====> Epoch: 14 Average val loss: -1.4720\n",
            "Min loss -1.47\n",
            "====> Epoch: 15 Average train loss: -1.4195\n",
            "====> Epoch: 15 Average val loss: -1.4679\n",
            "====> Epoch: 16 Average train loss: -1.4546\n",
            "====> Epoch: 16 Average val loss: -1.4924\n",
            "Min loss -1.49\n",
            "====> Epoch: 17 Average train loss: -1.4619\n",
            "====> Epoch: 17 Average val loss: -1.5217\n",
            "Min loss -1.52\n",
            "====> Epoch: 18 Average train loss: -1.4586\n",
            "====> Epoch: 18 Average val loss: -1.5630\n",
            "Min loss -1.56\n",
            "====> Epoch: 19 Average train loss: -1.4653\n",
            "====> Epoch: 19 Average val loss: -1.5150\n",
            "====> Epoch: 20 Average train loss: -1.4264\n",
            "====> Epoch: 20 Average val loss: -1.5335\n",
            "====> Epoch: 21 Average train loss: -1.5161\n",
            "====> Epoch: 21 Average val loss: -1.5344\n",
            "====> Epoch: 22 Average train loss: -1.4940\n",
            "====> Epoch: 22 Average val loss: -1.5259\n",
            "====> Epoch: 23 Average train loss: -1.4923\n",
            "====> Epoch: 23 Average val loss: -1.5499\n",
            "====> Epoch: 24 Average train loss: -1.5149\n",
            "====> Epoch: 24 Average val loss: -1.5648\n",
            "Min loss -1.56\n",
            "====> Epoch: 25 Average train loss: -1.5150\n",
            "====> Epoch: 25 Average val loss: -1.5361\n",
            "====> Epoch: 26 Average train loss: -1.4827\n",
            "====> Epoch: 26 Average val loss: -1.5410\n",
            "====> Epoch: 27 Average train loss: -1.5311\n",
            "====> Epoch: 27 Average val loss: -1.5671\n",
            "Min loss -1.57\n",
            "====> Epoch: 28 Average train loss: -1.5312\n",
            "====> Epoch: 28 Average val loss: -1.6496\n",
            "Min loss -1.65\n",
            "====> Epoch: 29 Average train loss: -1.5205\n",
            "====> Epoch: 29 Average val loss: -1.5859\n",
            "====> Epoch: 30 Average train loss: -1.5608\n",
            "====> Epoch: 30 Average val loss: -1.6023\n",
            "====> Epoch: 31 Average train loss: -1.5408\n",
            "====> Epoch: 31 Average val loss: -1.5680\n",
            "====> Epoch: 32 Average train loss: -1.5728\n",
            "====> Epoch: 32 Average val loss: -1.5834\n",
            "====> Epoch: 33 Average train loss: -1.5693\n",
            "====> Epoch: 33 Average val loss: -1.6329\n",
            "====> Epoch: 34 Average train loss: -1.5843\n",
            "====> Epoch: 34 Average val loss: -1.6298\n",
            "====> Epoch: 35 Average train loss: -1.5697\n",
            "====> Epoch: 35 Average val loss: -1.5912\n",
            "====> Epoch: 36 Average train loss: -1.5933\n",
            "====> Epoch: 36 Average val loss: -1.6292\n",
            "====> Epoch: 37 Average train loss: -1.5982\n",
            "====> Epoch: 37 Average val loss: -1.6682\n",
            "Min loss -1.67\n",
            "====> Epoch: 38 Average train loss: -1.5995\n",
            "====> Epoch: 38 Average val loss: -1.6186\n",
            "====> Epoch: 39 Average train loss: -1.6332\n",
            "====> Epoch: 39 Average val loss: -1.6424\n",
            "====> Epoch: 40 Average train loss: -1.5745\n",
            "====> Epoch: 40 Average val loss: -1.6360\n",
            "====> Epoch: 41 Average train loss: -1.6106\n",
            "====> Epoch: 41 Average val loss: -1.6277\n",
            "====> Epoch: 42 Average train loss: -1.6300\n",
            "====> Epoch: 42 Average val loss: -1.5900\n",
            "====> Epoch: 43 Average train loss: -1.6535\n",
            "====> Epoch: 43 Average val loss: -1.6464\n",
            "====> Epoch: 44 Average train loss: -1.6048\n",
            "====> Epoch: 44 Average val loss: -1.6448\n",
            "====> Epoch: 45 Average train loss: -1.6170\n",
            "====> Epoch: 45 Average val loss: -1.6460\n",
            "====> Epoch: 46 Average train loss: -1.6429\n",
            "====> Epoch: 46 Average val loss: -1.6481\n",
            "====> Epoch: 47 Average train loss: -1.6117\n",
            "====> Epoch: 47 Average val loss: -1.6373\n",
            "====> Epoch: 48 Average train loss: -1.6425\n",
            "====> Epoch: 48 Average val loss: -1.6421\n",
            "====> Epoch: 49 Average train loss: -1.6628\n",
            "====> Epoch: 49 Average val loss: -1.6388\n",
            "====> Epoch: 50 Average train loss: -1.6463\n",
            "====> Epoch: 50 Average val loss: -1.6912\n",
            "Min loss -1.69\n",
            "DCCA by non-linear orthogonal iterations\n",
            "total parameters:  201476\n",
            "====> Epoch: 1 Average train loss: -0.1113\n",
            "====> Epoch: 1 Average val loss: -0.4468\n",
            "Min loss -0.45\n",
            "====> Epoch: 2 Average train loss: -0.4779\n",
            "====> Epoch: 2 Average val loss: -0.3813\n",
            "====> Epoch: 3 Average train loss: -0.4686\n",
            "====> Epoch: 3 Average val loss: -0.2168\n",
            "====> Epoch: 4 Average train loss: -0.2471\n",
            "====> Epoch: 4 Average val loss: -0.0825\n",
            "====> Epoch: 5 Average train loss: -0.1115\n",
            "====> Epoch: 5 Average val loss: -0.2531\n",
            "====> Epoch: 6 Average train loss: -0.2459\n",
            "====> Epoch: 6 Average val loss: -0.2110\n",
            "====> Epoch: 7 Average train loss: -0.2670\n",
            "====> Epoch: 7 Average val loss: -0.2862\n",
            "====> Epoch: 8 Average train loss: -0.2228\n",
            "====> Epoch: 8 Average val loss: -0.2636\n",
            "====> Epoch: 9 Average train loss: -0.1782\n",
            "====> Epoch: 9 Average val loss: -0.2343\n",
            "====> Epoch: 10 Average train loss: -0.1905\n",
            "====> Epoch: 10 Average val loss: -0.1462\n",
            "====> Epoch: 11 Average train loss: -0.1741\n",
            "====> Epoch: 11 Average val loss: -0.1610\n",
            "====> Epoch: 12 Average train loss: -0.1497\n",
            "====> Epoch: 12 Average val loss: -0.0655\n",
            "====> Epoch: 13 Average train loss: -0.0550\n",
            "====> Epoch: 13 Average val loss: -0.0677\n",
            "====> Epoch: 14 Average train loss: -0.0561\n",
            "====> Epoch: 14 Average val loss: -0.1347\n",
            "====> Epoch: 15 Average train loss: -0.1565\n",
            "====> Epoch: 15 Average val loss: -0.1245\n",
            "====> Epoch: 16 Average train loss: -0.1349\n",
            "====> Epoch: 16 Average val loss: -0.1443\n",
            "====> Epoch: 17 Average train loss: -0.1566\n",
            "====> Epoch: 17 Average val loss: -0.1020\n",
            "====> Epoch: 18 Average train loss: -0.1452\n",
            "====> Epoch: 18 Average val loss: -0.0426\n",
            "====> Epoch: 19 Average train loss: -0.0716\n",
            "====> Epoch: 19 Average val loss: -0.0336\n",
            "====> Epoch: 20 Average train loss: -0.0312\n",
            "====> Epoch: 20 Average val loss: -0.0506\n",
            "====> Epoch: 21 Average train loss: -0.0231\n",
            "====> Epoch: 21 Average val loss: -0.0314\n",
            "====> Epoch: 22 Average train loss: -0.0344\n",
            "====> Epoch: 22 Average val loss: -0.0267\n",
            "====> Epoch: 23 Average train loss: -0.0150\n",
            "====> Epoch: 23 Average val loss: -0.0243\n",
            "====> Epoch: 24 Average train loss: -0.0294\n",
            "====> Epoch: 24 Average val loss: -0.0283\n",
            "====> Epoch: 25 Average train loss: -0.0386\n",
            "====> Epoch: 25 Average val loss: -0.0062\n",
            "====> Epoch: 26 Average train loss: -0.0283\n",
            "====> Epoch: 26 Average val loss: -0.0487\n",
            "====> Epoch: 27 Average train loss: -0.0163\n",
            "====> Epoch: 27 Average val loss: -0.0500\n",
            "====> Epoch: 28 Average train loss: -0.0272\n",
            "====> Epoch: 28 Average val loss: -0.0434\n",
            "====> Epoch: 29 Average train loss: -0.0405\n",
            "====> Epoch: 29 Average val loss: -0.0515\n",
            "====> Epoch: 30 Average train loss: -0.0436\n",
            "====> Epoch: 30 Average val loss: -0.0595\n",
            "====> Epoch: 31 Average train loss: -0.0486\n",
            "====> Epoch: 31 Average val loss: -0.0338\n",
            "====> Epoch: 32 Average train loss: -0.0450\n",
            "====> Epoch: 32 Average val loss: -0.0760\n",
            "====> Epoch: 33 Average train loss: -0.0707\n",
            "====> Epoch: 33 Average val loss: -0.0604\n",
            "====> Epoch: 34 Average train loss: -0.0506\n",
            "====> Epoch: 34 Average val loss: -0.0523\n",
            "====> Epoch: 35 Average train loss: -0.0695\n",
            "====> Epoch: 35 Average val loss: -0.0769\n",
            "====> Epoch: 36 Average train loss: -0.0893\n",
            "====> Epoch: 36 Average val loss: -0.0918\n",
            "====> Epoch: 37 Average train loss: -0.1154\n",
            "====> Epoch: 37 Average val loss: -0.0941\n",
            "====> Epoch: 38 Average train loss: -0.1112\n",
            "====> Epoch: 38 Average val loss: -0.0718\n",
            "====> Epoch: 39 Average train loss: -0.1001\n",
            "====> Epoch: 39 Average val loss: -0.1003\n",
            "====> Epoch: 40 Average train loss: -0.0588\n",
            "====> Epoch: 40 Average val loss: -0.0870\n",
            "====> Epoch: 41 Average train loss: -0.1069\n",
            "====> Epoch: 41 Average val loss: -0.0863\n",
            "====> Epoch: 42 Average train loss: -0.1067\n",
            "====> Epoch: 42 Average val loss: -0.0908\n",
            "====> Epoch: 43 Average train loss: -0.1116\n",
            "====> Epoch: 43 Average val loss: -0.1084\n",
            "====> Epoch: 44 Average train loss: -0.1001\n",
            "====> Epoch: 44 Average val loss: -0.0738\n",
            "====> Epoch: 45 Average train loss: -0.1074\n",
            "====> Epoch: 45 Average val loss: -0.1070\n",
            "====> Epoch: 46 Average train loss: -0.1053\n",
            "====> Epoch: 46 Average val loss: -0.1073\n",
            "====> Epoch: 47 Average train loss: -0.1009\n",
            "====> Epoch: 47 Average val loss: -0.0790\n",
            "====> Epoch: 48 Average train loss: -0.0975\n",
            "====> Epoch: 48 Average val loss: -0.1155\n",
            "====> Epoch: 49 Average train loss: -0.0901\n",
            "====> Epoch: 49 Average val loss: -0.1223\n",
            "====> Epoch: 50 Average train loss: -0.1099\n",
            "====> Epoch: 50 Average val loss: -0.0978\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1_ce5uMJUJ8"
      },
      "source": [
        "# DCCA with custom optimizers and schedulers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGC3HS2YJUk1",
        "outputId": "2c26f745-ba51-444c-b380-cd14c388f2f5"
      },
      "source": [
        "# DCCA\n",
        "optimizers = [optim.Adam(encoder_1.parameters(), lr=1e-4), optim.Adam(encoder_2.parameters(), lr=1e-4)]\n",
        "schedulers = [optim.lr_scheduler.CosineAnnealingLR(optimizers[0], 1),\n",
        "              optim.lr_scheduler.ReduceLROnPlateau(optimizers[1])]\n",
        "dcca_model = dcca.DCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2],\n",
        "                                objective=objectives.CCA, optimizers=optimizers, schedulers=schedulers)\n",
        "# hidden_layer_sizes are shown explicitly but these are also the defaults\n",
        "dcca_model = deepwrapper.DeepWrapper(dcca_model)\n",
        "dcca_model.fit(train_dataset, val_dataset=val_dataset,epochs=20)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:936: UserWarning: Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\n",
            "  \"Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "total parameters:  201476\n",
            "====> Epoch: 1 Average train loss: -0.0976\n",
            "====> Epoch: 1 Average val loss: -0.1331\n",
            "Min loss -0.13\n",
            "====> Epoch: 2 Average train loss: -0.1345\n",
            "====> Epoch: 2 Average val loss: -0.1524\n",
            "Min loss -0.15\n",
            "====> Epoch: 3 Average train loss: -0.1413\n",
            "====> Epoch: 3 Average val loss: -0.1598\n",
            "Min loss -0.16\n",
            "====> Epoch: 4 Average train loss: -0.1507\n",
            "====> Epoch: 4 Average val loss: -0.1572\n",
            "====> Epoch: 5 Average train loss: -0.1610\n",
            "====> Epoch: 5 Average val loss: -0.2026\n",
            "Min loss -0.20\n",
            "====> Epoch: 6 Average train loss: -0.1699\n",
            "====> Epoch: 6 Average val loss: -0.2012\n",
            "====> Epoch: 7 Average train loss: -0.2136\n",
            "====> Epoch: 7 Average val loss: -0.2427\n",
            "Min loss -0.24\n",
            "====> Epoch: 8 Average train loss: -0.2145\n",
            "====> Epoch: 8 Average val loss: -0.2604\n",
            "Min loss -0.26\n",
            "====> Epoch: 9 Average train loss: -0.2642\n",
            "====> Epoch: 9 Average val loss: -0.2720\n",
            "Min loss -0.27\n",
            "====> Epoch: 10 Average train loss: -0.2478\n",
            "====> Epoch: 10 Average val loss: -0.2952\n",
            "Min loss -0.30\n",
            "====> Epoch: 11 Average train loss: -0.2624\n",
            "====> Epoch: 11 Average val loss: -0.2992\n",
            "Min loss -0.30\n",
            "====> Epoch: 12 Average train loss: -0.2718\n",
            "====> Epoch: 12 Average val loss: -0.3170\n",
            "Min loss -0.32\n",
            "====> Epoch: 13 Average train loss: -0.2960\n",
            "====> Epoch: 13 Average val loss: -0.3336\n",
            "Min loss -0.33\n",
            "====> Epoch: 14 Average train loss: -0.3629\n",
            "====> Epoch: 14 Average val loss: -0.3500\n",
            "Min loss -0.35\n",
            "====> Epoch: 15 Average train loss: -0.3579\n",
            "====> Epoch: 15 Average val loss: -0.3606\n",
            "Min loss -0.36\n",
            "====> Epoch: 16 Average train loss: -0.3333\n",
            "====> Epoch: 16 Average val loss: -0.3863\n",
            "Min loss -0.39\n",
            "====> Epoch: 17 Average train loss: -0.3549\n",
            "====> Epoch: 17 Average val loss: -0.4115\n",
            "Min loss -0.41\n",
            "====> Epoch: 18 Average train loss: -0.4104\n",
            "====> Epoch: 18 Average val loss: -0.4401\n",
            "Min loss -0.44\n",
            "====> Epoch: 19 Average train loss: -0.3733\n",
            "====> Epoch: 19 Average val loss: -0.4593\n",
            "Min loss -0.46\n",
            "====> Epoch: 20 Average train loss: -0.4447\n",
            "====> Epoch: 20 Average val loss: -0.4677\n",
            "Min loss -0.47\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeepWrapper(device='cpu',\n",
              "            model=DCCA(\n",
              "  (encoders): ModuleList(\n",
              "    (0): Encoder(\n",
              "      (layers): Sequential(\n",
              "        (0): Sequential(\n",
              "          (0): Linear(in_features=784, out_features=128, bias=True)\n",
              "          (1): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (fc): Linear(in_features=128, out_features=2, bias=True)\n",
              "    )\n",
              "    (1): Encoder(\n",
              "      (layers): Sequential(\n",
              "        (0): Sequential(\n",
              "          (0): Linear(in_features=784, out_features=128, bias=True)\n",
              "          (1): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (fc): Linear(in_features=128, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "),\n",
              "            tensorboard=False, tensorboard_tag=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NZ5ZB9cNx-o"
      },
      "source": [
        "# DGCCA and DMCCA for more than 2 views\n",
        "\n",
        "The only change we need to make is to the objective argument to perform DGCCA and DMCCA."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAClfNMYNxq4",
        "outputId": "e512af6c-6268-486a-eb96-4ab12a79d9f6"
      },
      "source": [
        "# DGCCA\n",
        "print('DGCCA')\n",
        "encoder_1 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\n",
        "encoder_2 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\n",
        "dgcca_model = dcca.DCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2], objective=objectives.GCCA)\n",
        "\n",
        "dgcca_model = deepwrapper.DeepWrapper(dgcca_model)\n",
        "\n",
        "dgcca_model.fit(train_dataset, val_dataset=val_dataset, epochs=epochs)\n",
        "\n",
        "dgcca_results = np.stack(\n",
        "    (dgcca_model.train_correlations[0, 1], dgcca_model.predict_corr(test_dataset)[0, 1]))\n",
        "\n",
        "# DMCCA\n",
        "print('DMCCA')\n",
        "encoder_1 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\n",
        "encoder_2 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\n",
        "dmcca_model = dcca.DCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2], objective=objectives.MCCA)\n",
        "\n",
        "dmcca_model = deepwrapper.DeepWrapper(dmcca_model)\n",
        "\n",
        "dmcca_model.fit(train_dataset, val_dataset=val_dataset, epochs=epochs)\n",
        "\n",
        "dmcca_results = np.stack(\n",
        "    (dmcca_model.train_correlations[0, 1], dmcca_model.predict_corr(test_dataset)[0, 1]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:936: UserWarning: Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\n",
            "  \"Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DGCCA\n",
            "total parameters:  201476\n",
            "====> Epoch: 1 Average train loss: -0.2276\n",
            "====> Epoch: 1 Average val loss: -1.0637\n",
            "Min loss -1.06\n",
            "====> Epoch: 2 Average train loss: -0.9894\n",
            "====> Epoch: 2 Average val loss: -1.2232\n",
            "Min loss -1.22\n",
            "====> Epoch: 3 Average train loss: -1.2018\n",
            "====> Epoch: 3 Average val loss: -1.3136\n",
            "Min loss -1.31\n",
            "====> Epoch: 4 Average train loss: -1.2822\n",
            "====> Epoch: 4 Average val loss: -1.4474\n",
            "Min loss -1.45\n",
            "====> Epoch: 5 Average train loss: -1.3327\n",
            "====> Epoch: 5 Average val loss: -1.4549\n",
            "Min loss -1.45\n",
            "====> Epoch: 6 Average train loss: -1.4326\n",
            "====> Epoch: 6 Average val loss: -1.4645\n",
            "Min loss -1.46\n",
            "====> Epoch: 7 Average train loss: -1.4150\n",
            "====> Epoch: 7 Average val loss: -1.4986\n",
            "Min loss -1.50\n",
            "====> Epoch: 8 Average train loss: -1.4307\n",
            "====> Epoch: 8 Average val loss: -1.5470\n",
            "Min loss -1.55\n",
            "====> Epoch: 9 Average train loss: -1.4586\n",
            "====> Epoch: 9 Average val loss: -1.5280\n",
            "====> Epoch: 10 Average train loss: -1.5138\n",
            "====> Epoch: 10 Average val loss: -1.5065\n",
            "====> Epoch: 11 Average train loss: -1.4927\n",
            "====> Epoch: 11 Average val loss: -1.5319\n",
            "====> Epoch: 12 Average train loss: -1.4931\n",
            "====> Epoch: 12 Average val loss: -1.5507\n",
            "Min loss -1.55\n",
            "====> Epoch: 13 Average train loss: -1.5418\n",
            "====> Epoch: 13 Average val loss: -1.5720\n",
            "Min loss -1.57\n",
            "====> Epoch: 14 Average train loss: -1.5456\n",
            "====> Epoch: 14 Average val loss: -1.5783\n",
            "Min loss -1.58\n",
            "====> Epoch: 15 Average train loss: -1.5243\n",
            "====> Epoch: 15 Average val loss: -1.5975\n",
            "Min loss -1.60\n",
            "====> Epoch: 16 Average train loss: -1.5456\n",
            "====> Epoch: 16 Average val loss: -1.5441\n",
            "====> Epoch: 17 Average train loss: -1.5706\n",
            "====> Epoch: 17 Average val loss: -1.5664\n",
            "====> Epoch: 18 Average train loss: -1.5388\n",
            "====> Epoch: 18 Average val loss: -1.5760\n",
            "====> Epoch: 19 Average train loss: -1.5828\n",
            "====> Epoch: 19 Average val loss: -1.6239\n",
            "Min loss -1.62\n",
            "====> Epoch: 20 Average train loss: -1.5787\n",
            "====> Epoch: 20 Average val loss: -1.6048\n",
            "====> Epoch: 21 Average train loss: -1.5670\n",
            "====> Epoch: 21 Average val loss: -1.6275\n",
            "Min loss -1.63\n",
            "====> Epoch: 22 Average train loss: -1.5900\n",
            "====> Epoch: 22 Average val loss: -1.5597\n",
            "====> Epoch: 23 Average train loss: -1.5910\n",
            "====> Epoch: 23 Average val loss: -1.6336\n",
            "Min loss -1.63\n",
            "====> Epoch: 24 Average train loss: -1.6014\n",
            "====> Epoch: 24 Average val loss: -1.6289\n",
            "====> Epoch: 25 Average train loss: -1.5823\n",
            "====> Epoch: 25 Average val loss: -1.6316\n",
            "====> Epoch: 26 Average train loss: -1.5793\n",
            "====> Epoch: 26 Average val loss: -1.6436\n",
            "Min loss -1.64\n",
            "====> Epoch: 27 Average train loss: -1.6130\n",
            "====> Epoch: 27 Average val loss: -1.6139\n",
            "====> Epoch: 28 Average train loss: -1.5811\n",
            "====> Epoch: 28 Average val loss: -1.6459\n",
            "Min loss -1.65\n",
            "====> Epoch: 29 Average train loss: -1.5849\n",
            "====> Epoch: 29 Average val loss: -1.6738\n",
            "Min loss -1.67\n",
            "====> Epoch: 30 Average train loss: -1.5986\n",
            "====> Epoch: 30 Average val loss: -1.6001\n",
            "====> Epoch: 31 Average train loss: -1.6041\n",
            "====> Epoch: 31 Average val loss: -1.6497\n",
            "====> Epoch: 32 Average train loss: -1.6423\n",
            "====> Epoch: 32 Average val loss: -1.6490\n",
            "====> Epoch: 33 Average train loss: -1.5998\n",
            "====> Epoch: 33 Average val loss: -1.6384\n",
            "====> Epoch: 34 Average train loss: -1.6202\n",
            "====> Epoch: 34 Average val loss: -1.6527\n",
            "====> Epoch: 35 Average train loss: -1.6143\n",
            "====> Epoch: 35 Average val loss: -1.6541\n",
            "====> Epoch: 36 Average train loss: -1.5900\n",
            "====> Epoch: 36 Average val loss: -1.6137\n",
            "====> Epoch: 37 Average train loss: -1.6059\n",
            "====> Epoch: 37 Average val loss: -1.6672\n",
            "====> Epoch: 38 Average train loss: -1.6532\n",
            "====> Epoch: 38 Average val loss: -1.6393\n",
            "====> Epoch: 39 Average train loss: -1.6464\n",
            "====> Epoch: 39 Average val loss: -1.6408\n",
            "====> Epoch: 40 Average train loss: -1.6433\n",
            "====> Epoch: 40 Average val loss: -1.7158\n",
            "Min loss -1.72\n",
            "====> Epoch: 41 Average train loss: -1.6660\n",
            "====> Epoch: 41 Average val loss: -1.6948\n",
            "====> Epoch: 42 Average train loss: -1.6498\n",
            "====> Epoch: 42 Average val loss: -1.6920\n",
            "====> Epoch: 43 Average train loss: -1.6606\n",
            "====> Epoch: 43 Average val loss: -1.6743\n",
            "====> Epoch: 44 Average train loss: -1.6646\n",
            "====> Epoch: 44 Average val loss: -1.6028\n",
            "====> Epoch: 45 Average train loss: -1.6649\n",
            "====> Epoch: 45 Average val loss: -1.6632\n",
            "====> Epoch: 46 Average train loss: -1.6637\n",
            "====> Epoch: 46 Average val loss: -1.6550\n",
            "====> Epoch: 47 Average train loss: -1.6512\n",
            "====> Epoch: 47 Average val loss: -1.6549\n",
            "====> Epoch: 48 Average train loss: -1.6232\n",
            "====> Epoch: 48 Average val loss: -1.6906\n",
            "====> Epoch: 49 Average train loss: -1.6633\n",
            "====> Epoch: 49 Average val loss: -1.6452\n",
            "====> Epoch: 50 Average train loss: -1.6653\n",
            "====> Epoch: 50 Average val loss: -1.6956\n",
            "DMCCA\n",
            "total parameters:  201476\n",
            "====> Epoch: 1 Average train loss: -0.1297\n",
            "====> Epoch: 1 Average val loss: -0.7257\n",
            "Min loss -0.73\n",
            "====> Epoch: 2 Average train loss: -0.6360\n",
            "====> Epoch: 2 Average val loss: -0.9946\n",
            "Min loss -0.99\n",
            "====> Epoch: 3 Average train loss: -0.9970\n",
            "====> Epoch: 3 Average val loss: -1.2440\n",
            "Min loss -1.24\n",
            "====> Epoch: 4 Average train loss: -1.1718\n",
            "====> Epoch: 4 Average val loss: -1.2937\n",
            "Min loss -1.29\n",
            "====> Epoch: 5 Average train loss: -1.2456\n",
            "====> Epoch: 5 Average val loss: -1.3816\n",
            "Min loss -1.38\n",
            "====> Epoch: 6 Average train loss: -1.3125\n",
            "====> Epoch: 6 Average val loss: -1.4026\n",
            "Min loss -1.40\n",
            "====> Epoch: 7 Average train loss: -1.3508\n",
            "====> Epoch: 7 Average val loss: -1.3855\n",
            "====> Epoch: 8 Average train loss: -1.3883\n",
            "====> Epoch: 8 Average val loss: -1.4513\n",
            "Min loss -1.45\n",
            "====> Epoch: 9 Average train loss: -1.4029\n",
            "====> Epoch: 9 Average val loss: -1.4760\n",
            "Min loss -1.48\n",
            "====> Epoch: 10 Average train loss: -1.4037\n",
            "====> Epoch: 10 Average val loss: -1.4769\n",
            "Min loss -1.48\n",
            "====> Epoch: 11 Average train loss: -1.4757\n",
            "====> Epoch: 11 Average val loss: -1.5046\n",
            "Min loss -1.50\n",
            "====> Epoch: 12 Average train loss: -1.4857\n",
            "====> Epoch: 12 Average val loss: -1.4966\n",
            "====> Epoch: 13 Average train loss: -1.4699\n",
            "====> Epoch: 13 Average val loss: -1.4900\n",
            "====> Epoch: 14 Average train loss: -1.4739\n",
            "====> Epoch: 14 Average val loss: -1.5291\n",
            "Min loss -1.53\n",
            "====> Epoch: 15 Average train loss: -1.5525\n",
            "====> Epoch: 15 Average val loss: -1.5506\n",
            "Min loss -1.55\n",
            "====> Epoch: 16 Average train loss: -1.4984\n",
            "====> Epoch: 16 Average val loss: -1.5331\n",
            "====> Epoch: 17 Average train loss: -1.5123\n",
            "====> Epoch: 17 Average val loss: -1.5530\n",
            "Min loss -1.55\n",
            "====> Epoch: 18 Average train loss: -1.5169\n",
            "====> Epoch: 18 Average val loss: -1.5362\n",
            "====> Epoch: 19 Average train loss: -1.5619\n",
            "====> Epoch: 19 Average val loss: -1.5700\n",
            "Min loss -1.57\n",
            "====> Epoch: 20 Average train loss: -1.5286\n",
            "====> Epoch: 20 Average val loss: -1.6017\n",
            "Min loss -1.60\n",
            "====> Epoch: 21 Average train loss: -1.5498\n",
            "====> Epoch: 21 Average val loss: -1.5454\n",
            "====> Epoch: 22 Average train loss: -1.5254\n",
            "====> Epoch: 22 Average val loss: -1.6010\n",
            "====> Epoch: 23 Average train loss: -1.5292\n",
            "====> Epoch: 23 Average val loss: -1.5620\n",
            "====> Epoch: 24 Average train loss: -1.5650\n",
            "====> Epoch: 24 Average val loss: -1.6234\n",
            "Min loss -1.62\n",
            "====> Epoch: 25 Average train loss: -1.5740\n",
            "====> Epoch: 25 Average val loss: -1.5834\n",
            "====> Epoch: 26 Average train loss: -1.5470\n",
            "====> Epoch: 26 Average val loss: -1.6088\n",
            "====> Epoch: 27 Average train loss: -1.5657\n",
            "====> Epoch: 27 Average val loss: -1.5781\n",
            "====> Epoch: 28 Average train loss: -1.5905\n",
            "====> Epoch: 28 Average val loss: -1.6244\n",
            "Min loss -1.62\n",
            "====> Epoch: 29 Average train loss: -1.5501\n",
            "====> Epoch: 29 Average val loss: -1.6335\n",
            "Min loss -1.63\n",
            "====> Epoch: 30 Average train loss: -1.5725\n",
            "====> Epoch: 30 Average val loss: -1.6224\n",
            "====> Epoch: 31 Average train loss: -1.6150\n",
            "====> Epoch: 31 Average val loss: -1.6336\n",
            "Min loss -1.63\n",
            "====> Epoch: 32 Average train loss: -1.5443\n",
            "====> Epoch: 32 Average val loss: -1.6265\n",
            "====> Epoch: 33 Average train loss: -1.6369\n",
            "====> Epoch: 33 Average val loss: -1.6323\n",
            "====> Epoch: 34 Average train loss: -1.5683\n",
            "====> Epoch: 34 Average val loss: -1.6780\n",
            "Min loss -1.68\n",
            "====> Epoch: 35 Average train loss: -1.6086\n",
            "====> Epoch: 35 Average val loss: -1.6408\n",
            "====> Epoch: 36 Average train loss: -1.6010\n",
            "====> Epoch: 36 Average val loss: -1.6206\n",
            "====> Epoch: 37 Average train loss: -1.6422\n",
            "====> Epoch: 37 Average val loss: -1.6396\n",
            "====> Epoch: 38 Average train loss: -1.6712\n",
            "====> Epoch: 38 Average val loss: -1.6362\n",
            "====> Epoch: 39 Average train loss: -1.6106\n",
            "====> Epoch: 39 Average val loss: -1.6506\n",
            "====> Epoch: 40 Average train loss: -1.6122\n",
            "====> Epoch: 40 Average val loss: -1.6659\n",
            "====> Epoch: 41 Average train loss: -1.6194\n",
            "====> Epoch: 41 Average val loss: -1.6281\n",
            "====> Epoch: 42 Average train loss: -1.6490\n",
            "====> Epoch: 42 Average val loss: -1.6391\n",
            "====> Epoch: 43 Average train loss: -1.6640\n",
            "====> Epoch: 43 Average val loss: -1.6524\n",
            "====> Epoch: 44 Average train loss: -1.6149\n",
            "====> Epoch: 44 Average val loss: -1.6543\n",
            "====> Epoch: 45 Average train loss: -1.6389\n",
            "====> Epoch: 45 Average val loss: -1.6778\n",
            "====> Epoch: 46 Average train loss: -1.6462\n",
            "====> Epoch: 46 Average val loss: -1.6605\n",
            "====> Epoch: 47 Average train loss: -1.6502\n",
            "====> Epoch: 47 Average val loss: -1.6512\n",
            "====> Epoch: 48 Average train loss: -1.6641\n",
            "====> Epoch: 48 Average val loss: -1.6514\n",
            "====> Epoch: 49 Average train loss: -1.6554\n",
            "====> Epoch: 49 Average val loss: -1.6474\n",
            "====> Epoch: 50 Average train loss: -1.6783\n",
            "====> Epoch: 50 Average val loss: -1.6906\n",
            "Min loss -1.69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ym0WfC6uOA-8"
      },
      "source": [
        "# Deep Canonically Correlated Autoencoders\n",
        "We need to add decoders in order to model deep canonically correlated autoencoders and we also use the DCCAE class which inherits from DCCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwiNJf-MOBOg",
        "outputId": "49591883-13dd-430f-8314-03ec6d0cd794"
      },
      "source": [
        "from cca_zoo import dccae\n",
        "\n",
        "# DCCAE\n",
        "print('DCCAE')\n",
        "encoder_1 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\n",
        "encoder_2 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\n",
        "decoder_1 = deep_models.Decoder(latent_dims=latent_dims, feature_size=784)\n",
        "decoder_2 = deep_models.Decoder(latent_dims=latent_dims, feature_size=784)\n",
        "dccae_model = dccae.DCCAE(latent_dims=latent_dims, encoders=[encoder_1, encoder_2], decoders=[decoder_1, decoder_2])\n",
        "\n",
        "dccae_model = deepwrapper.DeepWrapper(dccae_model)\n",
        "\n",
        "#can also pass a tuple of numpy arrays\n",
        "dccae_model.fit((train_view_1, train_view_2), epochs=epochs)\n",
        "\n",
        "dccae_results = np.stack(\n",
        "    (dccae_model.train_correlations[0, 1], dccae_model.predict_corr(test_dataset)[0, 1]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DCCAE\n",
            "total parameters:  404516\n",
            "====> Epoch: 1 Average train loss: 55446.6602\n",
            "====> Epoch: 1 Average val loss: 11446.3047\n",
            "Min loss 11446.30\n",
            "====> Epoch: 2 Average train loss: 46537.3086\n",
            "====> Epoch: 2 Average val loss: 9816.6934\n",
            "Min loss 9816.69\n",
            "====> Epoch: 3 Average train loss: 39998.5781\n",
            "====> Epoch: 3 Average val loss: 8677.6221\n",
            "Min loss 8677.62\n",
            "====> Epoch: 4 Average train loss: 35431.3008\n",
            "====> Epoch: 4 Average val loss: 7906.2661\n",
            "Min loss 7906.27\n",
            "====> Epoch: 5 Average train loss: 32344.1191\n",
            "====> Epoch: 5 Average val loss: 7400.0356\n",
            "Min loss 7400.04\n",
            "====> Epoch: 6 Average train loss: 30322.6309\n",
            "====> Epoch: 6 Average val loss: 7086.2070\n",
            "Min loss 7086.21\n",
            "====> Epoch: 7 Average train loss: 29072.0000\n",
            "====> Epoch: 7 Average val loss: 6908.5840\n",
            "Min loss 6908.58\n",
            "====> Epoch: 8 Average train loss: 28364.0977\n",
            "====> Epoch: 8 Average val loss: 6820.3354\n",
            "Min loss 6820.34\n",
            "====> Epoch: 9 Average train loss: 28009.3301\n",
            "====> Epoch: 9 Average val loss: 6783.6299\n",
            "Min loss 6783.63\n",
            "====> Epoch: 10 Average train loss: 27855.6055\n",
            "====> Epoch: 10 Average val loss: 6772.0283\n",
            "Min loss 6772.03\n",
            "====> Epoch: 11 Average train loss: 27797.9805\n",
            "====> Epoch: 11 Average val loss: 6769.5444\n",
            "Min loss 6769.54\n",
            "====> Epoch: 12 Average train loss: 27774.1562\n",
            "====> Epoch: 12 Average val loss: 6766.9990\n",
            "Min loss 6767.00\n",
            "====> Epoch: 13 Average train loss: 27749.3633\n",
            "====> Epoch: 13 Average val loss: 6758.8237\n",
            "Min loss 6758.82\n",
            "====> Epoch: 14 Average train loss: 27703.0605\n",
            "====> Epoch: 14 Average val loss: 6741.5796\n",
            "Min loss 6741.58\n",
            "====> Epoch: 15 Average train loss: 27622.7910\n",
            "====> Epoch: 15 Average val loss: 6714.0381\n",
            "Min loss 6714.04\n",
            "====> Epoch: 16 Average train loss: 27504.2832\n",
            "====> Epoch: 16 Average val loss: 6677.0259\n",
            "Min loss 6677.03\n",
            "====> Epoch: 17 Average train loss: 27350.8320\n",
            "====> Epoch: 17 Average val loss: 6632.4233\n",
            "Min loss 6632.42\n",
            "====> Epoch: 18 Average train loss: 27169.3691\n",
            "====> Epoch: 18 Average val loss: 6582.0923\n",
            "Min loss 6582.09\n",
            "====> Epoch: 19 Average train loss: 26966.4277\n",
            "====> Epoch: 19 Average val loss: 6527.5532\n",
            "Min loss 6527.55\n",
            "====> Epoch: 20 Average train loss: 26747.2227\n",
            "====> Epoch: 20 Average val loss: 6470.2720\n",
            "Min loss 6470.27\n",
            "====> Epoch: 21 Average train loss: 26516.8516\n",
            "====> Epoch: 21 Average val loss: 6411.7827\n",
            "Min loss 6411.78\n",
            "====> Epoch: 22 Average train loss: 26280.9805\n",
            "====> Epoch: 22 Average val loss: 6353.4609\n",
            "Min loss 6353.46\n",
            "====> Epoch: 23 Average train loss: 26044.8809\n",
            "====> Epoch: 23 Average val loss: 6296.1294\n",
            "Min loss 6296.13\n",
            "====> Epoch: 24 Average train loss: 25811.9941\n",
            "====> Epoch: 24 Average val loss: 6240.0332\n",
            "Min loss 6240.03\n",
            "====> Epoch: 25 Average train loss: 25583.5254\n",
            "====> Epoch: 25 Average val loss: 6185.0645\n",
            "Min loss 6185.06\n",
            "====> Epoch: 26 Average train loss: 25359.3418\n",
            "====> Epoch: 26 Average val loss: 6130.9585\n",
            "Min loss 6130.96\n",
            "====> Epoch: 27 Average train loss: 25138.7422\n",
            "====> Epoch: 27 Average val loss: 6077.3711\n",
            "Min loss 6077.37\n",
            "====> Epoch: 28 Average train loss: 24920.6230\n",
            "====> Epoch: 28 Average val loss: 6023.9043\n",
            "Min loss 6023.90\n",
            "====> Epoch: 29 Average train loss: 24703.6230\n",
            "====> Epoch: 29 Average val loss: 5970.2773\n",
            "Min loss 5970.28\n",
            "====> Epoch: 30 Average train loss: 24486.8281\n",
            "====> Epoch: 30 Average val loss: 5916.4199\n",
            "Min loss 5916.42\n",
            "====> Epoch: 31 Average train loss: 24270.0742\n",
            "====> Epoch: 31 Average val loss: 5862.3779\n",
            "Min loss 5862.38\n",
            "====> Epoch: 32 Average train loss: 24053.5840\n",
            "====> Epoch: 32 Average val loss: 5808.2466\n",
            "Min loss 5808.25\n",
            "====> Epoch: 33 Average train loss: 23837.5898\n",
            "====> Epoch: 33 Average val loss: 5754.2114\n",
            "Min loss 5754.21\n",
            "====> Epoch: 34 Average train loss: 23622.5625\n",
            "====> Epoch: 34 Average val loss: 5700.5767\n",
            "Min loss 5700.58\n",
            "====> Epoch: 35 Average train loss: 23409.3730\n",
            "====> Epoch: 35 Average val loss: 5647.6919\n",
            "Min loss 5647.69\n",
            "====> Epoch: 36 Average train loss: 23199.0684\n",
            "====> Epoch: 36 Average val loss: 5595.8691\n",
            "Min loss 5595.87\n",
            "====> Epoch: 37 Average train loss: 22992.6270\n",
            "====> Epoch: 37 Average val loss: 5545.3955\n",
            "Min loss 5545.40\n",
            "====> Epoch: 38 Average train loss: 22791.0527\n",
            "====> Epoch: 38 Average val loss: 5496.5127\n",
            "Min loss 5496.51\n",
            "====> Epoch: 39 Average train loss: 22595.1543\n",
            "====> Epoch: 39 Average val loss: 5449.3477\n",
            "Min loss 5449.35\n",
            "====> Epoch: 40 Average train loss: 22405.4766\n",
            "====> Epoch: 40 Average val loss: 5403.9585\n",
            "Min loss 5403.96\n",
            "====> Epoch: 41 Average train loss: 22222.3691\n",
            "====> Epoch: 41 Average val loss: 5360.3452\n",
            "Min loss 5360.35\n",
            "====> Epoch: 42 Average train loss: 22046.1348\n",
            "====> Epoch: 42 Average val loss: 5318.4761\n",
            "Min loss 5318.48\n",
            "====> Epoch: 43 Average train loss: 21876.9336\n",
            "====> Epoch: 43 Average val loss: 5278.2935\n",
            "Min loss 5278.29\n",
            "====> Epoch: 44 Average train loss: 21714.7676\n",
            "====> Epoch: 44 Average val loss: 5239.7847\n",
            "Min loss 5239.78\n",
            "====> Epoch: 45 Average train loss: 21559.6074\n",
            "====> Epoch: 45 Average val loss: 5202.9609\n",
            "Min loss 5202.96\n",
            "====> Epoch: 46 Average train loss: 21411.3379\n",
            "====> Epoch: 46 Average val loss: 5167.7793\n",
            "Min loss 5167.78\n",
            "====> Epoch: 47 Average train loss: 21269.5586\n",
            "====> Epoch: 47 Average val loss: 5134.1533\n",
            "Min loss 5134.15\n",
            "====> Epoch: 48 Average train loss: 21133.6387\n",
            "====> Epoch: 48 Average val loss: 5101.9971\n",
            "Min loss 5102.00\n",
            "====> Epoch: 49 Average train loss: 21003.0078\n",
            "====> Epoch: 49 Average val loss: 5071.2407\n",
            "Min loss 5071.24\n",
            "====> Epoch: 50 Average train loss: 20877.2715\n",
            "====> Epoch: 50 Average val loss: 5041.8330\n",
            "Min loss 5041.83\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:936: UserWarning: Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\n",
            "  \"Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwOTBYZ0O9SP"
      },
      "source": [
        "# Deep Variational CCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SogqelCuO9rm",
        "outputId": "5a46586a-aec1-4e64-e91b-9d3fb4b16c05"
      },
      "source": [
        "\"\"\"\n",
        "### Deep Variational Learning\n",
        "Finally we have Deep Variational CCA methods.\n",
        "- Deep Variational CCA (DVCCA)\n",
        "- Deep Variational CCA - private (DVVCA_p)\n",
        "\n",
        "These are both implemented by the DVCCA class with private=True/False and both_encoders=True/False. If both_encoders,\n",
        "the encoder to the shared information Q(z_shared|x) is modelled for both x_1 and x_2 whereas if both_encoders is false\n",
        "it is modelled for x_1 as in the paper\n",
        "\"\"\"\n",
        "from cca_zoo import dvcca\n",
        "\n",
        "# %%\n",
        "# DVCCA (technically bi-DVCCA)\n",
        "print('DVCCA')\n",
        "encoder_1 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\n",
        "encoder_2 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\n",
        "decoder_1 = deep_models.Decoder(latent_dims=latent_dims, feature_size=784, norm_output=True)\n",
        "decoder_2 = deep_models.Decoder(latent_dims=latent_dims, feature_size=784, norm_output=True)\n",
        "dvcca_model = dvcca.DVCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2], decoders=[decoder_1, decoder_2],\n",
        "                          private=False)\n",
        "\n",
        "dvcca_model = deepwrapper.DeepWrapper(dvcca_model)\n",
        "\n",
        "dvcca_model.fit(train_dataset, val_dataset=val_dataset, epochs=epochs)\n",
        "\n",
        "dvcca_model_results = np.stack(\n",
        "    (dvcca_model.train_correlations[0, 1], dvcca_model.predict_corr(test_dataset)[0, 1]))\n",
        "\n",
        "# DVCCA_private (technically bi-DVCCA_private)\n",
        "print('DVCCA_private')\n",
        "encoder_1 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\n",
        "encoder_2 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\n",
        "private_encoder_1 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\n",
        "private_encoder_2 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\n",
        "decoder_1 = deep_models.Decoder(latent_dims=latent_dims * 2, feature_size=784, norm_output=True)\n",
        "decoder_2 = deep_models.Decoder(latent_dims=latent_dims * 2, feature_size=784, norm_output=True)\n",
        "dvccap_model = dvcca.DVCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2], decoders=[decoder_1, decoder_2],\n",
        "                           private_encoders=[private_encoder_1, private_encoder_2], private=True)\n",
        "\n",
        "dvccap_model = deepwrapper.DeepWrapper(dvccap_model)\n",
        "\n",
        "dvccap_model.fit(train_dataset, val_dataset=val_dataset, epochs=epochs)\n",
        "\n",
        "dvccap_model_results = np.stack(\n",
        "    (dvccap_model.train_correlations[0, 1], dvccap_model.predict_corr(test_dataset)[0, 1]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DVCCA\n",
            "total parameters:  405032\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:936: UserWarning: Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\n",
            "  \"Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "====> Epoch: 1 Average train loss: 1102.7065\n",
            "====> Epoch: 1 Average val loss: 1080.3849\n",
            "Min loss 1080.38\n",
            "====> Epoch: 2 Average train loss: 1081.1470\n",
            "====> Epoch: 2 Average val loss: 1060.3260\n",
            "Min loss 1060.33\n",
            "====> Epoch: 3 Average train loss: 1060.9924\n",
            "====> Epoch: 3 Average val loss: 1041.2097\n",
            "Min loss 1041.21\n",
            "====> Epoch: 4 Average train loss: 1042.2260\n",
            "====> Epoch: 4 Average val loss: 1024.2603\n",
            "Min loss 1024.26\n",
            "====> Epoch: 5 Average train loss: 1026.2439\n",
            "====> Epoch: 5 Average val loss: 1009.3326\n",
            "Min loss 1009.33\n",
            "====> Epoch: 6 Average train loss: 1009.9720\n",
            "====> Epoch: 6 Average val loss: 994.4794\n",
            "Min loss 994.48\n",
            "====> Epoch: 7 Average train loss: 994.9193\n",
            "====> Epoch: 7 Average val loss: 981.2676\n",
            "Min loss 981.27\n",
            "====> Epoch: 8 Average train loss: 982.4504\n",
            "====> Epoch: 8 Average val loss: 969.2190\n",
            "Min loss 969.22\n",
            "====> Epoch: 9 Average train loss: 972.2469\n",
            "====> Epoch: 9 Average val loss: 956.1982\n",
            "Min loss 956.20\n",
            "====> Epoch: 10 Average train loss: 958.7764\n",
            "====> Epoch: 10 Average val loss: 948.2333\n",
            "Min loss 948.23\n",
            "====> Epoch: 11 Average train loss: 950.9177\n",
            "====> Epoch: 11 Average val loss: 937.9540\n",
            "Min loss 937.95\n",
            "====> Epoch: 12 Average train loss: 940.1158\n",
            "====> Epoch: 12 Average val loss: 931.9788\n",
            "Min loss 931.98\n",
            "====> Epoch: 13 Average train loss: 934.0157\n",
            "====> Epoch: 13 Average val loss: 921.1811\n",
            "Min loss 921.18\n",
            "====> Epoch: 14 Average train loss: 925.8224\n",
            "====> Epoch: 14 Average val loss: 914.1489\n",
            "Min loss 914.15\n",
            "====> Epoch: 15 Average train loss: 918.0220\n",
            "====> Epoch: 15 Average val loss: 911.0702\n",
            "Min loss 911.07\n",
            "====> Epoch: 16 Average train loss: 910.7281\n",
            "====> Epoch: 16 Average val loss: 903.4702\n",
            "Min loss 903.47\n",
            "====> Epoch: 17 Average train loss: 908.9481\n",
            "====> Epoch: 17 Average val loss: 899.6514\n",
            "Min loss 899.65\n",
            "====> Epoch: 18 Average train loss: 901.2672\n",
            "====> Epoch: 18 Average val loss: 895.3617\n",
            "Min loss 895.36\n",
            "====> Epoch: 19 Average train loss: 897.2910\n",
            "====> Epoch: 19 Average val loss: 891.6063\n",
            "Min loss 891.61\n",
            "====> Epoch: 20 Average train loss: 895.9845\n",
            "====> Epoch: 20 Average val loss: 887.9302\n",
            "Min loss 887.93\n",
            "====> Epoch: 21 Average train loss: 888.9901\n",
            "====> Epoch: 21 Average val loss: 886.1252\n",
            "Min loss 886.13\n",
            "====> Epoch: 22 Average train loss: 884.9470\n",
            "====> Epoch: 22 Average val loss: 884.4580\n",
            "Min loss 884.46\n",
            "====> Epoch: 23 Average train loss: 884.3988\n",
            "====> Epoch: 23 Average val loss: 881.0940\n",
            "Min loss 881.09\n",
            "====> Epoch: 24 Average train loss: 881.7715\n",
            "====> Epoch: 24 Average val loss: 878.6251\n",
            "Min loss 878.63\n",
            "====> Epoch: 25 Average train loss: 882.0291\n",
            "====> Epoch: 25 Average val loss: 875.0663\n",
            "Min loss 875.07\n",
            "====> Epoch: 26 Average train loss: 877.8679\n",
            "====> Epoch: 26 Average val loss: 870.3438\n",
            "Min loss 870.34\n",
            "====> Epoch: 27 Average train loss: 871.5981\n",
            "====> Epoch: 27 Average val loss: 867.3391\n",
            "Min loss 867.34\n",
            "====> Epoch: 28 Average train loss: 874.4896\n",
            "====> Epoch: 28 Average val loss: 867.1175\n",
            "Min loss 867.12\n",
            "====> Epoch: 29 Average train loss: 875.0657\n",
            "====> Epoch: 29 Average val loss: 863.8233\n",
            "Min loss 863.82\n",
            "====> Epoch: 30 Average train loss: 870.3301\n",
            "====> Epoch: 30 Average val loss: 864.8604\n",
            "====> Epoch: 31 Average train loss: 867.2036\n",
            "====> Epoch: 31 Average val loss: 866.9258\n",
            "====> Epoch: 32 Average train loss: 868.3900\n",
            "====> Epoch: 32 Average val loss: 864.2268\n",
            "====> Epoch: 33 Average train loss: 865.9951\n",
            "====> Epoch: 33 Average val loss: 861.2958\n",
            "Min loss 861.30\n",
            "====> Epoch: 34 Average train loss: 866.6112\n",
            "====> Epoch: 34 Average val loss: 859.7886\n",
            "Min loss 859.79\n",
            "====> Epoch: 35 Average train loss: 865.7145\n",
            "====> Epoch: 35 Average val loss: 860.1636\n",
            "====> Epoch: 36 Average train loss: 864.8945\n",
            "====> Epoch: 36 Average val loss: 857.4254\n",
            "Min loss 857.43\n",
            "====> Epoch: 37 Average train loss: 864.0295\n",
            "====> Epoch: 37 Average val loss: 858.5137\n",
            "====> Epoch: 38 Average train loss: 860.7103\n",
            "====> Epoch: 38 Average val loss: 854.6040\n",
            "Min loss 854.60\n",
            "====> Epoch: 39 Average train loss: 857.5059\n",
            "====> Epoch: 39 Average val loss: 851.7207\n",
            "Min loss 851.72\n",
            "====> Epoch: 40 Average train loss: 862.1215\n",
            "====> Epoch: 40 Average val loss: 856.2379\n",
            "====> Epoch: 41 Average train loss: 857.7980\n",
            "====> Epoch: 41 Average val loss: 853.8787\n",
            "====> Epoch: 42 Average train loss: 861.4253\n",
            "====> Epoch: 42 Average val loss: 852.4431\n",
            "====> Epoch: 43 Average train loss: 855.2185\n",
            "====> Epoch: 43 Average val loss: 852.4231\n",
            "====> Epoch: 44 Average train loss: 853.4487\n",
            "====> Epoch: 44 Average val loss: 848.9587\n",
            "Min loss 848.96\n",
            "====> Epoch: 45 Average train loss: 857.1940\n",
            "====> Epoch: 45 Average val loss: 848.1650\n",
            "Min loss 848.17\n",
            "====> Epoch: 46 Average train loss: 853.4266\n",
            "====> Epoch: 46 Average val loss: 849.4829\n",
            "====> Epoch: 47 Average train loss: 855.3391\n",
            "====> Epoch: 47 Average val loss: 845.8026\n",
            "Min loss 845.80\n",
            "====> Epoch: 48 Average train loss: 858.9372\n",
            "====> Epoch: 48 Average val loss: 846.2657\n",
            "====> Epoch: 49 Average train loss: 853.2695\n",
            "====> Epoch: 49 Average val loss: 842.6397\n",
            "Min loss 842.64\n",
            "====> Epoch: 50 Average train loss: 852.3524\n",
            "====> Epoch: 50 Average val loss: 841.5566\n",
            "Min loss 841.56\n",
            "DVCCA_private\n",
            "total parameters:  607536\n",
            "====> Epoch: 1 Average train loss: 1104.0334\n",
            "====> Epoch: 1 Average val loss: 1083.7609\n",
            "Min loss 1083.76\n",
            "====> Epoch: 2 Average train loss: 1083.6753\n",
            "====> Epoch: 2 Average val loss: 1062.0581\n",
            "Min loss 1062.06\n",
            "====> Epoch: 3 Average train loss: 1062.3572\n",
            "====> Epoch: 3 Average val loss: 1043.0598\n",
            "Min loss 1043.06\n",
            "====> Epoch: 4 Average train loss: 1043.4106\n",
            "====> Epoch: 4 Average val loss: 1026.6152\n",
            "Min loss 1026.62\n",
            "====> Epoch: 5 Average train loss: 1026.6479\n",
            "====> Epoch: 5 Average val loss: 1009.7847\n",
            "Min loss 1009.78\n",
            "====> Epoch: 6 Average train loss: 1011.2947\n",
            "====> Epoch: 6 Average val loss: 994.6940\n",
            "Min loss 994.69\n",
            "====> Epoch: 7 Average train loss: 997.5922\n",
            "====> Epoch: 7 Average val loss: 981.1531\n",
            "Min loss 981.15\n",
            "====> Epoch: 8 Average train loss: 983.9420\n",
            "====> Epoch: 8 Average val loss: 968.0625\n",
            "Min loss 968.06\n",
            "====> Epoch: 9 Average train loss: 969.9508\n",
            "====> Epoch: 9 Average val loss: 957.2662\n",
            "Min loss 957.27\n",
            "====> Epoch: 10 Average train loss: 960.0817\n",
            "====> Epoch: 10 Average val loss: 948.5443\n",
            "Min loss 948.54\n",
            "====> Epoch: 11 Average train loss: 948.7662\n",
            "====> Epoch: 11 Average val loss: 938.2024\n",
            "Min loss 938.20\n",
            "====> Epoch: 12 Average train loss: 941.5322\n",
            "====> Epoch: 12 Average val loss: 930.8552\n",
            "Min loss 930.86\n",
            "====> Epoch: 13 Average train loss: 933.0962\n",
            "====> Epoch: 13 Average val loss: 923.1169\n",
            "Min loss 923.12\n",
            "====> Epoch: 14 Average train loss: 924.2042\n",
            "====> Epoch: 14 Average val loss: 914.8483\n",
            "Min loss 914.85\n",
            "====> Epoch: 15 Average train loss: 920.6029\n",
            "====> Epoch: 15 Average val loss: 909.7762\n",
            "Min loss 909.78\n",
            "====> Epoch: 16 Average train loss: 910.5583\n",
            "====> Epoch: 16 Average val loss: 902.4301\n",
            "Min loss 902.43\n",
            "====> Epoch: 17 Average train loss: 909.2017\n",
            "====> Epoch: 17 Average val loss: 901.9604\n",
            "Min loss 901.96\n",
            "====> Epoch: 18 Average train loss: 903.2141\n",
            "====> Epoch: 18 Average val loss: 894.0276\n",
            "Min loss 894.03\n",
            "====> Epoch: 19 Average train loss: 896.7037\n",
            "====> Epoch: 19 Average val loss: 888.7763\n",
            "Min loss 888.78\n",
            "====> Epoch: 20 Average train loss: 893.9832\n",
            "====> Epoch: 20 Average val loss: 886.9514\n",
            "Min loss 886.95\n",
            "====> Epoch: 21 Average train loss: 891.2222\n",
            "====> Epoch: 21 Average val loss: 882.6333\n",
            "Min loss 882.63\n",
            "====> Epoch: 22 Average train loss: 885.8899\n",
            "====> Epoch: 22 Average val loss: 878.1973\n",
            "Min loss 878.20\n",
            "====> Epoch: 23 Average train loss: 883.0952\n",
            "====> Epoch: 23 Average val loss: 878.9097\n",
            "====> Epoch: 24 Average train loss: 881.7171\n",
            "====> Epoch: 24 Average val loss: 873.8475\n",
            "Min loss 873.85\n",
            "====> Epoch: 25 Average train loss: 883.2040\n",
            "====> Epoch: 25 Average val loss: 873.4288\n",
            "Min loss 873.43\n",
            "====> Epoch: 26 Average train loss: 874.1611\n",
            "====> Epoch: 26 Average val loss: 871.6837\n",
            "Min loss 871.68\n",
            "====> Epoch: 27 Average train loss: 874.6606\n",
            "====> Epoch: 27 Average val loss: 869.2620\n",
            "Min loss 869.26\n",
            "====> Epoch: 28 Average train loss: 875.2936\n",
            "====> Epoch: 28 Average val loss: 865.4209\n",
            "Min loss 865.42\n",
            "====> Epoch: 29 Average train loss: 870.4238\n",
            "====> Epoch: 29 Average val loss: 867.2591\n",
            "====> Epoch: 30 Average train loss: 869.1692\n",
            "====> Epoch: 30 Average val loss: 864.5493\n",
            "Min loss 864.55\n",
            "====> Epoch: 31 Average train loss: 868.9342\n",
            "====> Epoch: 31 Average val loss: 867.1650\n",
            "====> Epoch: 32 Average train loss: 866.5616\n",
            "====> Epoch: 32 Average val loss: 856.5948\n",
            "Min loss 856.59\n",
            "====> Epoch: 33 Average train loss: 863.8691\n",
            "====> Epoch: 33 Average val loss: 861.3411\n",
            "====> Epoch: 34 Average train loss: 861.0127\n",
            "====> Epoch: 34 Average val loss: 858.4871\n",
            "====> Epoch: 35 Average train loss: 861.1184\n",
            "====> Epoch: 35 Average val loss: 856.6475\n",
            "====> Epoch: 36 Average train loss: 863.9402\n",
            "====> Epoch: 36 Average val loss: 859.0483\n",
            "====> Epoch: 37 Average train loss: 867.1481\n",
            "====> Epoch: 37 Average val loss: 856.0947\n",
            "Min loss 856.09\n",
            "====> Epoch: 38 Average train loss: 860.8419\n",
            "====> Epoch: 38 Average val loss: 854.1060\n",
            "Min loss 854.11\n",
            "====> Epoch: 39 Average train loss: 859.2229\n",
            "====> Epoch: 39 Average val loss: 852.6639\n",
            "Min loss 852.66\n",
            "====> Epoch: 40 Average train loss: 858.9915\n",
            "====> Epoch: 40 Average val loss: 853.7014\n",
            "====> Epoch: 41 Average train loss: 861.0404\n",
            "====> Epoch: 41 Average val loss: 853.0071\n",
            "====> Epoch: 42 Average train loss: 860.1443\n",
            "====> Epoch: 42 Average val loss: 852.7570\n",
            "====> Epoch: 43 Average train loss: 859.6019\n",
            "====> Epoch: 43 Average val loss: 852.6921\n",
            "====> Epoch: 44 Average train loss: 853.4427\n",
            "====> Epoch: 44 Average val loss: 849.6875\n",
            "Min loss 849.69\n",
            "====> Epoch: 45 Average train loss: 856.2112\n",
            "====> Epoch: 45 Average val loss: 851.7819\n",
            "====> Epoch: 46 Average train loss: 850.3111\n",
            "====> Epoch: 46 Average val loss: 851.2325\n",
            "====> Epoch: 47 Average train loss: 855.8978\n",
            "====> Epoch: 47 Average val loss: 846.1752\n",
            "Min loss 846.18\n",
            "====> Epoch: 48 Average train loss: 851.5730\n",
            "====> Epoch: 48 Average val loss: 844.5673\n",
            "Min loss 844.57\n",
            "====> Epoch: 49 Average train loss: 854.0706\n",
            "====> Epoch: 49 Average val loss: 847.4598\n",
            "====> Epoch: 50 Average train loss: 849.7069\n",
            "====> Epoch: 50 Average val loss: 845.8752\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCMeGlxJkp93"
      },
      "source": [
        "# Convolutional Deep CCA (and using other architectures)\n",
        "We provide a standard CNN encoder and decoder but users can build their own encoders and decoders by inheriting BaseEncoder and BaseDecoder for seamless integration with the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9TEto00kpn2",
        "outputId": "52dde0cb-da42-4ca3-aa5d-e5070f954e3a"
      },
      "source": [
        "print('Convolutional DCCA')\n",
        "encoder_1 = deep_models.CNNEncoder(latent_dims=latent_dims, channels=[3, 3])\n",
        "encoder_2 = deep_models.CNNEncoder(latent_dims=latent_dims, channels=[3, 3])\n",
        "dcca_conv_model = dcca.DCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2])\n",
        "\n",
        "dcca_conv_model = deepwrapper.DeepWrapper(dcca_conv_model)\n",
        "\n",
        "# to change the models used change the cfg.encoder_models. We implement a CNN_Encoder and CNN_decoder as well\n",
        "# as some based on brainnet architecture in cca_zoo.deep_models. Equally you could pass your own encoder/decoder models\n",
        "\n",
        "dcca_conv_model.fit((train_view_1.reshape((-1, 1, 28, 28)), train_view_2.reshape((-1, 1, 28, 28))), epochs=epochs)\n",
        "\n",
        "dcca_conv_results = np.stack(\n",
        "    (dcca_conv_model.train_correlations[0, 1], dcca_conv_model.predict_corr((test_view_1.reshape((-1, 1, 28, 28)),\n",
        "                                                                            test_view_2.reshape(\n",
        "                                                                                (-1, 1, 28, 28))))[0, 1]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Convolutional DCCA\n",
            "total parameters:  9568\n",
            "====> Epoch: 1 Average train loss: -0.0993\n",
            "====> Epoch: 1 Average val loss: -0.2911\n",
            "Min loss -0.29\n",
            "====> Epoch: 2 Average train loss: -0.5038\n",
            "====> Epoch: 2 Average val loss: -0.4841\n",
            "Min loss -0.48\n",
            "====> Epoch: 3 Average train loss: -0.8328\n",
            "====> Epoch: 3 Average val loss: -0.6386\n",
            "Min loss -0.64\n",
            "====> Epoch: 4 Average train loss: -1.0509\n",
            "====> Epoch: 4 Average val loss: -0.7580\n",
            "Min loss -0.76\n",
            "====> Epoch: 5 Average train loss: -1.1914\n",
            "====> Epoch: 5 Average val loss: -0.8454\n",
            "Min loss -0.85\n",
            "====> Epoch: 6 Average train loss: -1.2920\n",
            "====> Epoch: 6 Average val loss: -0.9087\n",
            "Min loss -0.91\n",
            "====> Epoch: 7 Average train loss: -1.3716\n",
            "====> Epoch: 7 Average val loss: -0.9543\n",
            "Min loss -0.95\n",
            "====> Epoch: 8 Average train loss: -1.4388\n",
            "====> Epoch: 8 Average val loss: -0.9866\n",
            "Min loss -0.99\n",
            "====> Epoch: 9 Average train loss: -1.4972\n",
            "====> Epoch: 9 Average val loss: -1.0081\n",
            "Min loss -1.01\n",
            "====> Epoch: 10 Average train loss: -1.5481\n",
            "====> Epoch: 10 Average val loss: -1.0210\n",
            "Min loss -1.02\n",
            "====> Epoch: 11 Average train loss: -1.5917\n",
            "====> Epoch: 11 Average val loss: -1.0281\n",
            "Min loss -1.03\n",
            "====> Epoch: 12 Average train loss: -1.6282\n",
            "====> Epoch: 12 Average val loss: -1.0328\n",
            "Min loss -1.03\n",
            "====> Epoch: 13 Average train loss: -1.6590\n",
            "====> Epoch: 13 Average val loss: -1.0388\n",
            "Min loss -1.04\n",
            "====> Epoch: 14 Average train loss: -1.6865\n",
            "====> Epoch: 14 Average val loss: -1.0480\n",
            "Min loss -1.05\n",
            "====> Epoch: 15 Average train loss: -1.7125\n",
            "====> Epoch: 15 Average val loss: -1.0603\n",
            "Min loss -1.06\n",
            "====> Epoch: 16 Average train loss: -1.7371\n",
            "====> Epoch: 16 Average val loss: -1.0745\n",
            "Min loss -1.07\n",
            "====> Epoch: 17 Average train loss: -1.7597\n",
            "====> Epoch: 17 Average val loss: -1.0889\n",
            "Min loss -1.09\n",
            "====> Epoch: 18 Average train loss: -1.7798\n",
            "====> Epoch: 18 Average val loss: -1.1022\n",
            "Min loss -1.10\n",
            "====> Epoch: 19 Average train loss: -1.7972\n",
            "====> Epoch: 19 Average val loss: -1.1135\n",
            "Min loss -1.11\n",
            "====> Epoch: 20 Average train loss: -1.8122\n",
            "====> Epoch: 20 Average val loss: -1.1225\n",
            "Min loss -1.12\n",
            "====> Epoch: 21 Average train loss: -1.8251\n",
            "====> Epoch: 21 Average val loss: -1.1291\n",
            "Min loss -1.13\n",
            "====> Epoch: 22 Average train loss: -1.8364\n",
            "====> Epoch: 22 Average val loss: -1.1334\n",
            "Min loss -1.13\n",
            "====> Epoch: 23 Average train loss: -1.8464\n",
            "====> Epoch: 23 Average val loss: -1.1361\n",
            "Min loss -1.14\n",
            "====> Epoch: 24 Average train loss: -1.8556\n",
            "====> Epoch: 24 Average val loss: -1.1377\n",
            "Min loss -1.14\n",
            "====> Epoch: 25 Average train loss: -1.8640\n",
            "====> Epoch: 25 Average val loss: -1.1388\n",
            "Min loss -1.14\n",
            "====> Epoch: 26 Average train loss: -1.8717\n",
            "====> Epoch: 26 Average val loss: -1.1399\n",
            "Min loss -1.14\n",
            "====> Epoch: 27 Average train loss: -1.8791\n",
            "====> Epoch: 27 Average val loss: -1.1417\n",
            "Min loss -1.14\n",
            "====> Epoch: 28 Average train loss: -1.8860\n",
            "====> Epoch: 28 Average val loss: -1.1440\n",
            "Min loss -1.14\n",
            "====> Epoch: 29 Average train loss: -1.8925\n",
            "====> Epoch: 29 Average val loss: -1.1471\n",
            "Min loss -1.15\n",
            "====> Epoch: 30 Average train loss: -1.8986\n",
            "====> Epoch: 30 Average val loss: -1.1505\n",
            "Min loss -1.15\n",
            "====> Epoch: 31 Average train loss: -1.9042\n",
            "====> Epoch: 31 Average val loss: -1.1540\n",
            "Min loss -1.15\n",
            "====> Epoch: 32 Average train loss: -1.9094\n",
            "====> Epoch: 32 Average val loss: -1.1574\n",
            "Min loss -1.16\n",
            "====> Epoch: 33 Average train loss: -1.9141\n",
            "====> Epoch: 33 Average val loss: -1.1605\n",
            "Min loss -1.16\n",
            "====> Epoch: 34 Average train loss: -1.9184\n",
            "====> Epoch: 34 Average val loss: -1.1630\n",
            "Min loss -1.16\n",
            "====> Epoch: 35 Average train loss: -1.9224\n",
            "====> Epoch: 35 Average val loss: -1.1650\n",
            "Min loss -1.17\n",
            "====> Epoch: 36 Average train loss: -1.9262\n",
            "====> Epoch: 36 Average val loss: -1.1664\n",
            "Min loss -1.17\n",
            "====> Epoch: 37 Average train loss: -1.9296\n",
            "====> Epoch: 37 Average val loss: -1.1672\n",
            "Min loss -1.17\n",
            "====> Epoch: 38 Average train loss: -1.9329\n",
            "====> Epoch: 38 Average val loss: -1.1675\n",
            "Min loss -1.17\n",
            "====> Epoch: 39 Average train loss: -1.9359\n",
            "====> Epoch: 39 Average val loss: -1.1676\n",
            "Min loss -1.17\n",
            "====> Epoch: 40 Average train loss: -1.9386\n",
            "====> Epoch: 40 Average val loss: -1.1676\n",
            "====> Epoch: 41 Average train loss: -1.9411\n",
            "====> Epoch: 41 Average val loss: -1.1676\n",
            "====> Epoch: 42 Average train loss: -1.9435\n",
            "====> Epoch: 42 Average val loss: -1.1678\n",
            "Min loss -1.17\n",
            "====> Epoch: 43 Average train loss: -1.9456\n",
            "====> Epoch: 43 Average val loss: -1.1683\n",
            "Min loss -1.17\n",
            "====> Epoch: 44 Average train loss: -1.9476\n",
            "====> Epoch: 44 Average val loss: -1.1689\n",
            "Min loss -1.17\n",
            "====> Epoch: 45 Average train loss: -1.9495\n",
            "====> Epoch: 45 Average val loss: -1.1697\n",
            "Min loss -1.17\n",
            "====> Epoch: 46 Average train loss: -1.9513\n",
            "====> Epoch: 46 Average val loss: -1.1705\n",
            "Min loss -1.17\n",
            "====> Epoch: 47 Average train loss: -1.9529\n",
            "====> Epoch: 47 Average val loss: -1.1712\n",
            "Min loss -1.17\n",
            "====> Epoch: 48 Average train loss: -1.9544\n",
            "====> Epoch: 48 Average val loss: -1.1717\n",
            "Min loss -1.17\n",
            "====> Epoch: 49 Average train loss: -1.9558\n",
            "====> Epoch: 49 Average val loss: -1.1721\n",
            "Min loss -1.17\n",
            "====> Epoch: 50 Average train loss: -1.9572\n",
            "====> Epoch: 50 Average val loss: -1.1722\n",
            "Min loss -1.17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhYAL8vxkiAh"
      },
      "source": [
        "# Generate Some Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNeUaqjwhcj7"
      },
      "source": [
        "\"\"\"\n",
        "### Make results plot to compare methods\n",
        "\"\"\"\n",
        "# %%\n",
        "\n",
        "all_results = np.stack(\n",
        "    [linear_cca_results, gcca_results, mcca_results, pls_results, pmd_results, elastic_results,\n",
        "     scca_results, kernel_reg_results, kernel_poly_results,\n",
        "     kernel_gaussian_results, dcca_results, dgcca_results, dmcca_results, dvcca_model_results,\n",
        "     dcca_conv_results],\n",
        "    axis=0)\n",
        "all_labels = ['linear', 'gcca', 'mcca', 'pls', 'pmd', 'elastic', 'scca', 'linear kernel', 'polynomial kernel',\n",
        "              'gaussian kernel', 'deep CCA', 'deep generalized CCA', 'deep multiset CCA', 'deep VCCA',\n",
        "              'deep convolutional cca']\n",
        "\n",
        "from cca_zoo import plot_utils\n",
        "\n",
        "plot_utils.plot_results(all_results, all_labels)\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wgDHziqYJZX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}