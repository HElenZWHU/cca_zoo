{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cca-zoo-tutorial.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPFk+Wc6clDBqs6ApkScHSq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jameschapman19/cca_zoo/blob/master/cca_zoo_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFVm_oT3cmZH",
        "outputId": "544c1c59-59ed-48f9-b085-d4bd56d5933f"
      },
      "source": [
        "!pip install cca-zoo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: cca-zoo in /usr/local/lib/python3.6/dist-packages (1.1.8)\n",
            "Requirement already satisfied, skipping upgrade: torchvision in /usr/local/lib/python3.6/dist-packages (from cca-zoo) (0.8.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: mvlearn in /usr/local/lib/python3.6/dist-packages (from cca-zoo) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from cca-zoo) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from cca-zoo) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: seaborn in /usr/local/lib/python3.6/dist-packages (from cca-zoo) (0.11.0)\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.6/dist-packages (from cca-zoo) (1.7.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: Pillow in /usr/local/lib/python3.6/dist-packages (from cca-zoo) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from cca-zoo) (1.19.4)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from cca-zoo) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from cca-zoo) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from mvlearn->cca-zoo) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cca-zoo) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cca-zoo) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cca-zoo) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cca-zoo) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->cca-zoo) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->cca-zoo) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch->cca-zoo) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->cca-zoo) (0.8)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->cca-zoo) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKgX47gILXS-"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFsRNCJ0crH8"
      },
      "source": [
        "# Imports\r\n",
        "import numpy as np\r\n",
        "from cca_zoo import wrappers\r\n",
        "from cca_zoo import data\r\n",
        "import itertools\r\n",
        "import os\r\n",
        "from cca_zoo.configuration import Config\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from torch.utils.data import Subset\r\n",
        "\r\n",
        "# Load MNIST Data\r\n",
        "os.chdir('..')\r\n",
        "N = 1000\r\n",
        "dataset = data.Noisy_MNIST_Dataset(mnist_type='FashionMNIST', train=True)\r\n",
        "ids = np.arange(min(2 * N, len(dataset)))\r\n",
        "np.random.shuffle(ids)\r\n",
        "train_ids, val_ids = np.array_split(ids, 2)\r\n",
        "val_dataset = Subset(dataset, val_ids)\r\n",
        "train_dataset = Subset(dataset, train_ids)\r\n",
        "test_dataset = data.Noisy_MNIST_Dataset(mnist_type='FashionMNIST', train=False)\r\n",
        "test_ids = np.arange(min(N, len(test_dataset)))\r\n",
        "np.random.shuffle(test_ids)\r\n",
        "test_dataset = Subset(test_dataset, test_ids)\r\n",
        "train_view_1, train_view_2, train_rotations, train_OH_labels, train_labels = train_dataset.dataset.to_numpy(\r\n",
        "    train_dataset.indices)\r\n",
        "val_view_1, val_view_2, val_rotations, val_OH_labels, val_labels = val_dataset.dataset.to_numpy(val_dataset.indices)\r\n",
        "test_view_1, test_view_2, test_rotations, test_OH_labels, test_labels = test_dataset.dataset.to_numpy(\r\n",
        "    test_dataset.indices)\r\n",
        "\r\n",
        "# Settings\r\n",
        "\r\n",
        "# The number of latent dimensions across models\r\n",
        "latent_dims = 2\r\n",
        "# The number of folds used for cross-validation/hyperparameter tuning\r\n",
        "cv_folds = 5\r\n",
        "# For running hyperparameter tuning in parallel (0 if not)\r\n",
        "jobs = 2\r\n",
        "# Number of iterations for iterative algorithms\r\n",
        "max_iter = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOryUM6ShmQf"
      },
      "source": [
        "# Canonical Correlation Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSGgSD7vgh1b"
      },
      "source": [
        "\"\"\"\r\n",
        "### Linear CCA via alternating least squares (can pass more than 2 views)\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "# %%\r\n",
        "linear_cca = wrappers.CCA_ALS(latent_dims=latent_dims)\r\n",
        "\r\n",
        "linear_cca.fit(train_view_1, train_view_2)\r\n",
        "\r\n",
        "linear_cca_results = np.stack(\r\n",
        "    (linear_cca.train_correlations[0, 1], linear_cca.predict_corr(test_view_1, test_view_2)[0, 1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZtZUfZ3huKE"
      },
      "source": [
        "# Canonical Correlation Analysis and Partial Least Squares using scikit-learn implementations\r\n",
        "\r\n",
        "These will likely be deprecated since our alternating least squares algorithm is very similar to the NIPALS algorithm used there. For the moment we keep to help test simple 2-view unregularized examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei3rASx3ghtJ"
      },
      "source": [
        "\"\"\"\r\n",
        "### Linear CCA with scikit-learn (only permits 2 views)\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "scikit_cca = wrappers.CCA_scikit(latent_dims=latent_dims)\r\n",
        "\r\n",
        "scikit_cca.fit(train_view_1, train_view_2)\r\n",
        "\r\n",
        "scikit_cca_results = np.stack(\r\n",
        "    (scikit_cca.train_correlations[0, 1], scikit_cca.predict_corr(test_view_1, test_view_2)[0, 1]))\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "### PLS with scikit-learn (only permits 2 views)\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "# %%\r\n",
        "pls = wrappers.PLS_scikit(latent_dims=latent_dims)\r\n",
        "\r\n",
        "pls.fit(train_view_1, train_view_2)\r\n",
        "\r\n",
        "pls_results = np.stack(\r\n",
        "    (pls.train_correlations[0, 1], pls.predict_corr(test_view_1, test_view_2)[0, 1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88vAaUxIi1H7"
      },
      "source": [
        "# Extension to multiple views\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Fx0dj8GghbD"
      },
      "source": [
        "\"\"\"\r\n",
        "### (Regularized) Generalized CCA(can pass more than 2 views)\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "gcca = wrappers.GCCA(latent_dims=latent_dims)\r\n",
        "# small ammount of regularisation added since data is not full rank\r\n",
        "params = {'c': [1, 1]}\r\n",
        "\r\n",
        "gcca.fit(train_view_1, train_view_2, params=params) #Just pass more views to .fit()\r\n",
        "\r\n",
        "gcca_results = np.stack((gcca.train_correlations[0, 1], gcca.predict_corr(test_view_1, test_view_2)[0, 1]))\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "### (Regularized) Multiset CCA(can pass more than 2 views)\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "mcca = wrappers.MCCA(latent_dims=latent_dims)\r\n",
        "# small ammount of regularisation added since data is not full rank\r\n",
        "params = {'c': [0.5, 0.5]}\r\n",
        "\r\n",
        "mcca.fit(train_view_1, train_view_2, params=params) #Just pass more views to .fit()\r\n",
        "\r\n",
        "mcca_results = np.stack((mcca.train_correlations[0, 1], mcca.predict_corr(test_view_1, test_view_2)[0, 1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9847WJ3liT6v"
      },
      "source": [
        "# Rgularised CCA solutions based on alternating minimisation/alternating least squares\r\n",
        "\r\n",
        "We implement Witten's penalized matrix decomposition form of sparse CCA using 'pmd'\r\n",
        "\r\n",
        "We implement Waaijenborg's penalized CCA using elastic net using 'elastic'\r\n",
        "\r\n",
        "We implement Mai's sparse CCA using 'scca'\r\n",
        "\r\n",
        "Furthermore, any of these methods can be extended to multiple views. Witten describes this method explicitly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts_yQvzdhDQe",
        "outputId": "abe0e3ed-046f-4489-f285-f3fafd149ea6"
      },
      "source": [
        "\"\"\"\r\n",
        "### Sparse CCA (Penalized Matrix Decomposition) (can pass more than 2 views)\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "# PMD\r\n",
        "c1 = [1, 3, 7, 9]\r\n",
        "c2 = [1, 3, 7, 9]\r\n",
        "param_candidates = {'c': list(itertools.product(c1, c2))}\r\n",
        "\r\n",
        "pmd = wrappers.CCA_ALS(latent_dims=latent_dims, method='pmd', tol=1e-5, max_iter=max_iter).gridsearch_fit(\r\n",
        "    train_view_1,\r\n",
        "    train_view_2,\r\n",
        "    param_candidates=param_candidates,\r\n",
        "    folds=cv_folds,\r\n",
        "    verbose=True, jobs=jobs,\r\n",
        "    plot=True)\r\n",
        "\r\n",
        "pmd_results = np.stack((pmd.train_correlations[0, 1, :], pmd.predict_corr(test_view_1, test_view_2)[0, 1, :]))\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "### Elastic CCA (can pass more than 2 views)\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "# Elastic CCA\r\n",
        "c1 = [0.0001, 0.001]\r\n",
        "c2 = [0.0001, 0.001]\r\n",
        "l1_1 = [0.01, 0.1]\r\n",
        "l1_2 = [0.01, 0.1]\r\n",
        "param_candidates = {'c': list(itertools.product(c1, c2)), 'l1_ratio': list(itertools.product(l1_1, l1_2))}\r\n",
        "\r\n",
        "elastic = wrappers.CCA_ALS(latent_dims=latent_dims, method='elastic',\r\n",
        "                                   max_iter=max_iter).gridsearch_fit(train_view_1,\r\n",
        "                                                                    train_view_2,\r\n",
        "                                                                    param_candidates=param_candidates,\r\n",
        "                                                                    folds=cv_folds,\r\n",
        "                                                                    verbose=True,\r\n",
        "                                                                    jobs=jobs,\r\n",
        "                                                                    plot=True)\r\n",
        "\r\n",
        "elastic_results = np.stack(\r\n",
        "    (elastic.train_correlations[0, 1, :], elastic.predict_corr(test_view_1, test_view_2)[0, 1, :]))\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "### Sparse CCA (can pass more than 2 views)\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "# Sparse CCA\r\n",
        "c1 = [0.0001, 0.001]\r\n",
        "c2 = [0.0001, 0.001]\r\n",
        "param_candidates = {'c': list(itertools.product(c1, c2))}\r\n",
        "\r\n",
        "scca = wrappers.CCA_ALS(latent_dims=latent_dims, method='scca', max_iter=max_iter).gridsearch_fit(\r\n",
        "    train_view_1,\r\n",
        "    train_view_2,\r\n",
        "    param_candidates=param_candidates,\r\n",
        "    folds=cv_folds,\r\n",
        "    verbose=True,\r\n",
        "    jobs=jobs, plot=True)\r\n",
        "\r\n",
        "scca_results = np.stack(\r\n",
        "    (scca.train_correlations[0, 1, :], scca.predict_corr(test_view_1, test_view_2)[0, 1, :]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cross validation\n",
            "number of folds:  5\n",
            "Best score :  1.263031777484701\n",
            "{'c': (9, 9)}\n",
            "cross validation\n",
            "number of folds:  5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best score :  1.1217213066451142\n",
            "{'c': (0.001, 0.001), 'l1_ratio': (0.1, 0.1)}\n",
            "cross validation\n",
            "number of folds:  5\n",
            "Best score :  1.3778632445701178\n",
            "{'c': (0.001, 0.0001)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaHqF5CljrCb"
      },
      "source": [
        "# Kernel CCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FtH38KO8hLFL",
        "outputId": "aee19288-fab6-4690-9dee-6b37cae7a745"
      },
      "source": [
        "\"\"\"\r\n",
        "### Kernel CCA\r\n",
        "\r\n",
        "Similarly, we can use kernel CCA methods with [method='kernel']\r\n",
        "\r\n",
        "We can use different kernels and their associated parameters in a similar manner to before\r\n",
        "- regularized linear kernel CCA: parameters :  'kernel'='linear', 0<'c'<1\r\n",
        "- polynomial kernel CCA: parameters : 'kernel'='poly', 'degree', 0<'c'<1\r\n",
        "- gaussian rbf kernel CCA: parameters : 'kernel'='gaussian', 'sigma', 0<'c'<1\r\n",
        "\"\"\"\r\n",
        "# %%\r\n",
        "# r-kernel cca\r\n",
        "c1 = [0.9, 0.99]\r\n",
        "c2 = [0.9, 0.99]\r\n",
        "\r\n",
        "param_candidates = {'kernel': ['linear'], 'c': list(itertools.product(c1, c2))}\r\n",
        "\r\n",
        "kernel_reg = wrappers.KCCA(latent_dims=latent_dims).gridsearch_fit(train_view_1, train_view_2,\r\n",
        "                                                                           folds=cv_folds,\r\n",
        "                                                                           param_candidates=param_candidates,\r\n",
        "                                                                           verbose=True, jobs=jobs,\r\n",
        "                                                                           plot=True)\r\n",
        "kernel_reg_results = np.stack((\r\n",
        "    kernel_reg.train_correlations[0, 1, :],\r\n",
        "    kernel_reg.predict_corr(test_view_1, test_view_2)[0, 1, :]))\r\n",
        "\r\n",
        "# kernel cca (poly)\r\n",
        "param_candidates = {'kernel': ['poly'], 'degree': [2, 3], 'c': list(itertools.product(c1, c2))}\r\n",
        "\r\n",
        "kernel_poly = wrappers.KCCA(latent_dims=latent_dims).gridsearch_fit(train_view_1, train_view_2,\r\n",
        "                                                                            folds=cv_folds,\r\n",
        "                                                                            param_candidates=param_candidates,\r\n",
        "                                                                            verbose=True, jobs=jobs,\r\n",
        "                                                                            plot=True)\r\n",
        "\r\n",
        "kernel_poly_results = np.stack((\r\n",
        "    kernel_poly.train_correlations[0, 1, :],\r\n",
        "    kernel_poly.predict_corr(test_view_1, test_view_2)[0, 1, :]))\r\n",
        "\r\n",
        "# kernel cca (gaussian)\r\n",
        "param_candidates = {'kernel': ['rbf'], 'sigma': [1e+1, 1e+2, 1e+3], 'c': list(itertools.product(c1, c2))}\r\n",
        "\r\n",
        "kernel_gaussian = wrappers.KCCA(latent_dims=latent_dims).gridsearch_fit(train_view_1, train_view_2,\r\n",
        "                                                                                folds=cv_folds,\r\n",
        "                                                                                param_candidates=param_candidates,\r\n",
        "                                                                                verbose=True, jobs=jobs,\r\n",
        "                                                                                plot=True)\r\n",
        "\r\n",
        "kernel_gaussian_results = np.stack((\r\n",
        "    kernel_gaussian.train_correlations[0, 1, :],\r\n",
        "    kernel_gaussian.predict_corr(test_view_1, test_view_2)[0, 1, :]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cross validation\n",
            "number of folds:  5\n",
            "Best score :  1.4950788066772576\n",
            "{'kernel': 'linear', 'c': (0.99, 0.99)}\n",
            "cross validation\n",
            "number of folds:  5\n",
            "Best score :  1.269053452297602\n",
            "{'kernel': 'poly', 'degree': 3, 'c': (0.9, 0.9)}\n",
            "cross validation\n",
            "number of folds:  5\n",
            "Best score :  1.1206782413713658\n",
            "{'kernel': 'rbf', 'sigma': 1000.0, 'c': (0.9, 0.9)}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/cca_zoo/plot_utils.py:49: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig, axs = plt.subplots(1, n_uniques[-1], subplot_kw={'projection': '3d'})\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44ltKrtIkICK"
      },
      "source": [
        "# Deep CCA, Deep Generalized CCA & Deep Multiset CCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "z0nTlPSEhVeP",
        "outputId": "85f7f318-0037-47df-f3e5-91dfd7c6a66d"
      },
      "source": [
        "\"\"\"\r\n",
        "### Deep Learning\r\n",
        "\r\n",
        "We also have deep CCA methods (and autoencoder variants)\r\n",
        "- Deep CCA (DCCA)\r\n",
        "- Deep Canonically Correlated Autoencoders (DCCAE)\r\n",
        "\r\n",
        "We introduce a Config class from configuration.py. This contains a number of default settings for running DCCA.\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "from cca_zoo import deepwrapper,objectives\r\n",
        "# %%\r\n",
        "# DCCA\r\n",
        "cfg = Config()\r\n",
        "cfg.epoch_num = 100\r\n",
        "\r\n",
        "# hidden_layer_sizes are shown explicitly but these are also the defaults\r\n",
        "dcca = deepwrapper.DeepWrapper(cfg)\r\n",
        "\r\n",
        "dcca.fit(train_view_1, train_view_2)\r\n",
        "\r\n",
        "dcca_results = np.stack((dcca.train_correlations, dcca.predict_corr(test_view_1, test_view_2)))\r\n",
        "\r\n",
        "# DGCCA\r\n",
        "cfg.loss_type = objectives.GCCA\r\n",
        "\r\n",
        "# Note the different loss function\r\n",
        "dgcca = deepwrapper.DeepWrapper(cfg)\r\n",
        "\r\n",
        "dgcca.fit(train_view_1, train_view_2)\r\n",
        "\r\n",
        "dgcca_results = np.stack((dgcca.train_correlations, dgcca.predict_corr(test_view_1, test_view_2)))\r\n",
        "\r\n",
        "# DMCCA\r\n",
        "cfg.loss_type = objectives.MCCA\r\n",
        "\r\n",
        "# Note the different loss function\r\n",
        "dmcca = deepwrapper.DeepWrapper(cfg)\r\n",
        "\r\n",
        "dmcca.fit(train_view_1, train_view_2)\r\n",
        "\r\n",
        "dmcca_results = np.stack((dmcca.train_correlations, dmcca.predict_corr(test_view_1, test_view_2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total parameters:  402948\n",
            "====> Epoch: 1 Average train loss: -0.1573\n",
            "====> Epoch: 1 Average val loss: -0.6672\n",
            "Min loss -0.67\n",
            "====> Epoch: 2 Average train loss: -0.8956\n",
            "====> Epoch: 2 Average val loss: -1.1338\n",
            "Min loss -1.13\n",
            "====> Epoch: 3 Average train loss: -1.3275\n",
            "====> Epoch: 3 Average val loss: -1.2245\n",
            "Min loss -1.22\n",
            "====> Epoch: 4 Average train loss: -1.4298\n",
            "====> Epoch: 4 Average val loss: -1.2658\n",
            "Min loss -1.27\n",
            "====> Epoch: 5 Average train loss: -1.5004\n",
            "====> Epoch: 5 Average val loss: -1.2973\n",
            "Min loss -1.30\n",
            "====> Epoch: 6 Average train loss: -1.5585\n",
            "====> Epoch: 6 Average val loss: -1.3205\n",
            "Min loss -1.32\n",
            "====> Epoch: 7 Average train loss: -1.6067\n",
            "====> Epoch: 7 Average val loss: -1.3305\n",
            "Min loss -1.33\n",
            "====> Epoch: 8 Average train loss: -1.6449\n",
            "====> Epoch: 8 Average val loss: -1.3334\n",
            "Min loss -1.33\n",
            "====> Epoch: 9 Average train loss: -1.6779\n",
            "====> Epoch: 9 Average val loss: -1.3323\n",
            "====> Epoch: 10 Average train loss: -1.7053\n",
            "====> Epoch: 10 Average val loss: -1.3362\n",
            "Min loss -1.34\n",
            "====> Epoch: 11 Average train loss: -1.7306\n",
            "====> Epoch: 11 Average val loss: -1.3468\n",
            "Min loss -1.35\n",
            "====> Epoch: 12 Average train loss: -1.7558\n",
            "====> Epoch: 12 Average val loss: -1.3573\n",
            "Min loss -1.36\n",
            "====> Epoch: 13 Average train loss: -1.7768\n",
            "====> Epoch: 13 Average val loss: -1.3624\n",
            "Min loss -1.36\n",
            "====> Epoch: 14 Average train loss: -1.7933\n",
            "====> Epoch: 14 Average val loss: -1.3623\n",
            "====> Epoch: 15 Average train loss: -1.8066\n",
            "====> Epoch: 15 Average val loss: -1.3593\n",
            "====> Epoch: 16 Average train loss: -1.8181\n",
            "====> Epoch: 16 Average val loss: -1.3560\n",
            "====> Epoch: 17 Average train loss: -1.8290\n",
            "====> Epoch: 17 Average val loss: -1.3551\n",
            "====> Epoch: 18 Average train loss: -1.8399\n",
            "====> Epoch: 18 Average val loss: -1.3574\n",
            "====> Epoch: 19 Average train loss: -1.8508\n",
            "====> Epoch: 19 Average val loss: -1.3630\n",
            "Min loss -1.36\n",
            "====> Epoch: 20 Average train loss: -1.8616\n",
            "====> Epoch: 20 Average val loss: -1.3678\n",
            "Min loss -1.37\n",
            "====> Epoch: 21 Average train loss: -1.8721\n",
            "====> Epoch: 21 Average val loss: -1.3708\n",
            "Min loss -1.37\n",
            "====> Epoch: 22 Average train loss: -1.8812\n",
            "====> Epoch: 22 Average val loss: -1.3731\n",
            "Min loss -1.37\n",
            "====> Epoch: 23 Average train loss: -1.8889\n",
            "====> Epoch: 23 Average val loss: -1.3762\n",
            "Min loss -1.38\n",
            "====> Epoch: 24 Average train loss: -1.8962\n",
            "====> Epoch: 24 Average val loss: -1.3793\n",
            "Min loss -1.38\n",
            "====> Epoch: 25 Average train loss: -1.9029\n",
            "====> Epoch: 25 Average val loss: -1.3797\n",
            "Min loss -1.38\n",
            "====> Epoch: 26 Average train loss: -1.9095\n",
            "====> Epoch: 26 Average val loss: -1.3775\n",
            "====> Epoch: 27 Average train loss: -1.9156\n",
            "====> Epoch: 27 Average val loss: -1.3762\n",
            "====> Epoch: 28 Average train loss: -1.9211\n",
            "====> Epoch: 28 Average val loss: -1.3761\n",
            "====> Epoch: 29 Average train loss: -1.9265\n",
            "====> Epoch: 29 Average val loss: -1.3762\n",
            "====> Epoch: 30 Average train loss: -1.9316\n",
            "====> Epoch: 30 Average val loss: -1.3744\n",
            "====> Epoch: 31 Average train loss: -1.9361\n",
            "====> Epoch: 31 Average val loss: -1.3706\n",
            "====> Epoch: 32 Average train loss: -1.9405\n",
            "====> Epoch: 32 Average val loss: -1.3664\n",
            "====> Epoch: 33 Average train loss: -1.9447\n",
            "====> Epoch: 33 Average val loss: -1.3628\n",
            "====> Epoch: 34 Average train loss: -1.9485\n",
            "====> Epoch: 34 Average val loss: -1.3603\n",
            "====> Epoch: 35 Average train loss: -1.9519\n",
            "====> Epoch: 35 Average val loss: -1.3594\n",
            "====> Epoch: 36 Average train loss: -1.9552\n",
            "====> Epoch: 36 Average val loss: -1.3604\n",
            "====> Epoch: 37 Average train loss: -1.9581\n",
            "====> Epoch: 37 Average val loss: -1.3618\n",
            "====> Epoch: 38 Average train loss: -1.9609\n",
            "====> Epoch: 38 Average val loss: -1.3626\n",
            "====> Epoch: 39 Average train loss: -1.9634\n",
            "====> Epoch: 39 Average val loss: -1.3619\n",
            "====> Epoch: 40 Average train loss: -1.9657\n",
            "====> Epoch: 40 Average val loss: -1.3609\n",
            "====> Epoch: 41 Average train loss: -1.9679\n",
            "====> Epoch: 41 Average val loss: -1.3606\n",
            "====> Epoch: 42 Average train loss: -1.9701\n",
            "====> Epoch: 42 Average val loss: -1.3602\n",
            "====> Epoch: 43 Average train loss: -1.9721\n",
            "====> Epoch: 43 Average val loss: -1.3588\n",
            "====> Epoch: 44 Average train loss: -1.9740\n",
            "====> Epoch: 44 Average val loss: -1.3565\n",
            "====> Epoch: 45 Average train loss: -1.9757\n",
            "====> Epoch: 45 Average val loss: -1.3549\n",
            "====> Epoch: 46 Average train loss: -1.9772\n",
            "====> Epoch: 46 Average val loss: -1.3540\n",
            "====> Epoch: 47 Average train loss: -1.9787\n",
            "====> Epoch: 47 Average val loss: -1.3537\n",
            "====> Epoch: 48 Average train loss: -1.9801\n",
            "====> Epoch: 48 Average val loss: -1.3540\n",
            "====> Epoch: 49 Average train loss: -1.9814\n",
            "====> Epoch: 49 Average val loss: -1.3542\n",
            "====> Epoch: 50 Average train loss: -1.9827\n",
            "====> Epoch: 50 Average val loss: -1.3536\n",
            "====> Epoch: 51 Average train loss: -1.9839\n",
            "====> Epoch: 51 Average val loss: -1.3523\n",
            "====> Epoch: 52 Average train loss: -1.9850\n",
            "====> Epoch: 52 Average val loss: -1.3517\n",
            "====> Epoch: 53 Average train loss: -1.9860\n",
            "====> Epoch: 53 Average val loss: -1.3523\n",
            "====> Epoch: 54 Average train loss: -1.9869\n",
            "====> Epoch: 54 Average val loss: -1.3528\n",
            "====> Epoch: 55 Average train loss: -1.9878\n",
            "====> Epoch: 55 Average val loss: -1.3526\n",
            "====> Epoch: 56 Average train loss: -1.9886\n",
            "====> Epoch: 56 Average val loss: -1.3517\n",
            "====> Epoch: 57 Average train loss: -1.9894\n",
            "====> Epoch: 57 Average val loss: -1.3505\n",
            "====> Epoch: 58 Average train loss: -1.9902\n",
            "====> Epoch: 58 Average val loss: -1.3494\n",
            "====> Epoch: 59 Average train loss: -1.9909\n",
            "====> Epoch: 59 Average val loss: -1.3491\n",
            "====> Epoch: 60 Average train loss: -1.9915\n",
            "====> Epoch: 60 Average val loss: -1.3493\n",
            "====> Epoch: 61 Average train loss: -1.9921\n",
            "====> Epoch: 61 Average val loss: -1.3489\n",
            "====> Epoch: 62 Average train loss: -1.9927\n",
            "====> Epoch: 62 Average val loss: -1.3479\n",
            "====> Epoch: 63 Average train loss: -1.9933\n",
            "====> Epoch: 63 Average val loss: -1.3470\n",
            "====> Epoch: 64 Average train loss: -1.9938\n",
            "====> Epoch: 64 Average val loss: -1.3463\n",
            "====> Epoch: 65 Average train loss: -1.9943\n",
            "====> Epoch: 65 Average val loss: -1.3457\n",
            "====> Epoch: 66 Average train loss: -1.9947\n",
            "====> Epoch: 66 Average val loss: -1.3457\n",
            "====> Epoch: 67 Average train loss: -1.9951\n",
            "====> Epoch: 67 Average val loss: -1.3458\n",
            "====> Epoch: 68 Average train loss: -1.9955\n",
            "====> Epoch: 68 Average val loss: -1.3457\n",
            "====> Epoch: 69 Average train loss: -1.9959\n",
            "====> Epoch: 69 Average val loss: -1.3457\n",
            "====> Epoch: 70 Average train loss: -1.9962\n",
            "====> Epoch: 70 Average val loss: -1.3456\n",
            "====> Epoch: 71 Average train loss: -1.9965\n",
            "====> Epoch: 71 Average val loss: -1.3451\n",
            "====> Epoch: 72 Average train loss: -1.9968\n",
            "====> Epoch: 72 Average val loss: -1.3447\n",
            "====> Epoch: 73 Average train loss: -1.9971\n",
            "====> Epoch: 73 Average val loss: -1.3444\n",
            "====> Epoch: 74 Average train loss: -1.9973\n",
            "====> Epoch: 74 Average val loss: -1.3441\n",
            "====> Epoch: 75 Average train loss: -1.9975\n",
            "====> Epoch: 75 Average val loss: -1.3439\n",
            "====> Epoch: 76 Average train loss: -1.9978\n",
            "====> Epoch: 76 Average val loss: -1.3439\n",
            "====> Epoch: 77 Average train loss: -1.9980\n",
            "====> Epoch: 77 Average val loss: -1.3439\n",
            "====> Epoch: 78 Average train loss: -1.9981\n",
            "====> Epoch: 78 Average val loss: -1.3436\n",
            "====> Epoch: 79 Average train loss: -1.9983\n",
            "====> Epoch: 79 Average val loss: -1.3430\n",
            "====> Epoch: 80 Average train loss: -1.9985\n",
            "====> Epoch: 80 Average val loss: -1.3424\n",
            "====> Epoch: 81 Average train loss: -1.9986\n",
            "====> Epoch: 81 Average val loss: -1.3423\n",
            "====> Epoch: 82 Average train loss: -1.9987\n",
            "====> Epoch: 82 Average val loss: -1.3423\n",
            "====> Epoch: 83 Average train loss: -1.9988\n",
            "====> Epoch: 83 Average val loss: -1.3422\n",
            "====> Epoch: 84 Average train loss: -1.9989\n",
            "====> Epoch: 84 Average val loss: -1.3419\n",
            "====> Epoch: 85 Average train loss: -1.9990\n",
            "====> Epoch: 85 Average val loss: -1.3415\n",
            "====> Epoch: 86 Average train loss: -1.9991\n",
            "====> Epoch: 86 Average val loss: -1.3412\n",
            "====> Epoch: 87 Average train loss: -1.9992\n",
            "====> Epoch: 87 Average val loss: -1.3412\n",
            "====> Epoch: 88 Average train loss: -1.9993\n",
            "====> Epoch: 88 Average val loss: -1.3410\n",
            "====> Epoch: 89 Average train loss: -1.9993\n",
            "====> Epoch: 89 Average val loss: -1.3406\n",
            "====> Epoch: 90 Average train loss: -1.9994\n",
            "====> Epoch: 90 Average val loss: -1.3403\n",
            "====> Epoch: 91 Average train loss: -1.9995\n",
            "====> Epoch: 91 Average val loss: -1.3403\n",
            "====> Epoch: 92 Average train loss: -1.9995\n",
            "====> Epoch: 92 Average val loss: -1.3403\n",
            "====> Epoch: 93 Average train loss: -1.9996\n",
            "====> Epoch: 93 Average val loss: -1.3402\n",
            "====> Epoch: 94 Average train loss: -1.9996\n",
            "====> Epoch: 94 Average val loss: -1.3402\n",
            "====> Epoch: 95 Average train loss: -1.9996\n",
            "====> Epoch: 95 Average val loss: -1.3403\n",
            "====> Epoch: 96 Average train loss: -1.9997\n",
            "====> Epoch: 96 Average val loss: -1.3403\n",
            "====> Epoch: 97 Average train loss: -1.9997\n",
            "====> Epoch: 97 Average val loss: -1.3403\n",
            "====> Epoch: 98 Average train loss: -1.9997\n",
            "====> Epoch: 98 Average val loss: -1.3403\n",
            "====> Epoch: 99 Average train loss: -1.9998\n",
            "====> Epoch: 99 Average val loss: -1.3403\n",
            "====> Epoch: 100 Average train loss: -1.9998\n",
            "====> Epoch: 100 Average val loss: -1.3404\n",
            "total parameters:  402948\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/cca_zoo/plot_utils.py:269: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  plt.figure()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "====> Epoch: 1 Average train loss: -0.2987\n",
            "====> Epoch: 1 Average val loss: -1.0767\n",
            "Min loss -1.08\n",
            "====> Epoch: 2 Average train loss: -1.2313\n",
            "====> Epoch: 2 Average val loss: -1.2231\n",
            "Min loss -1.22\n",
            "====> Epoch: 3 Average train loss: -1.4267\n",
            "====> Epoch: 3 Average val loss: -1.2763\n",
            "Min loss -1.28\n",
            "====> Epoch: 4 Average train loss: -1.5150\n",
            "====> Epoch: 4 Average val loss: -1.3096\n",
            "Min loss -1.31\n",
            "====> Epoch: 5 Average train loss: -1.5763\n",
            "====> Epoch: 5 Average val loss: -1.3333\n",
            "Min loss -1.33\n",
            "====> Epoch: 6 Average train loss: -1.6258\n",
            "====> Epoch: 6 Average val loss: -1.3512\n",
            "Min loss -1.35\n",
            "====> Epoch: 7 Average train loss: -1.6694\n",
            "====> Epoch: 7 Average val loss: -1.3607\n",
            "Min loss -1.36\n",
            "====> Epoch: 8 Average train loss: -1.7083\n",
            "====> Epoch: 8 Average val loss: -1.3578\n",
            "====> Epoch: 9 Average train loss: -1.7380\n",
            "====> Epoch: 9 Average val loss: -1.3492\n",
            "====> Epoch: 10 Average train loss: -1.7621\n",
            "====> Epoch: 10 Average val loss: -1.3477\n",
            "====> Epoch: 11 Average train loss: -1.7884\n",
            "====> Epoch: 11 Average val loss: -1.3566\n",
            "====> Epoch: 12 Average train loss: -1.8145\n",
            "====> Epoch: 12 Average val loss: -1.3639\n",
            "Min loss -1.36\n",
            "====> Epoch: 13 Average train loss: -1.8332\n",
            "====> Epoch: 13 Average val loss: -1.3643\n",
            "Min loss -1.36\n",
            "====> Epoch: 14 Average train loss: -1.8464\n",
            "====> Epoch: 14 Average val loss: -1.3577\n",
            "====> Epoch: 15 Average train loss: -1.8576\n",
            "====> Epoch: 15 Average val loss: -1.3462\n",
            "====> Epoch: 16 Average train loss: -1.8695\n",
            "====> Epoch: 16 Average val loss: -1.3327\n",
            "====> Epoch: 17 Average train loss: -1.8810\n",
            "====> Epoch: 17 Average val loss: -1.3213\n",
            "====> Epoch: 18 Average train loss: -1.8911\n",
            "====> Epoch: 18 Average val loss: -1.3148\n",
            "====> Epoch: 19 Average train loss: -1.9005\n",
            "====> Epoch: 19 Average val loss: -1.3140\n",
            "====> Epoch: 20 Average train loss: -1.9092\n",
            "====> Epoch: 20 Average val loss: -1.3172\n",
            "====> Epoch: 21 Average train loss: -1.9172\n",
            "====> Epoch: 21 Average val loss: -1.3198\n",
            "====> Epoch: 22 Average train loss: -1.9243\n",
            "====> Epoch: 22 Average val loss: -1.3197\n",
            "====> Epoch: 23 Average train loss: -1.9305\n",
            "====> Epoch: 23 Average val loss: -1.3203\n",
            "====> Epoch: 24 Average train loss: -1.9362\n",
            "====> Epoch: 24 Average val loss: -1.3191\n",
            "====> Epoch: 25 Average train loss: -1.9412\n",
            "====> Epoch: 25 Average val loss: -1.3155\n",
            "====> Epoch: 26 Average train loss: -1.9456\n",
            "====> Epoch: 26 Average val loss: -1.3100\n",
            "====> Epoch: 27 Average train loss: -1.9498\n",
            "====> Epoch: 27 Average val loss: -1.3060\n",
            "====> Epoch: 28 Average train loss: -1.9541\n",
            "====> Epoch: 28 Average val loss: -1.3046\n",
            "====> Epoch: 29 Average train loss: -1.9583\n",
            "====> Epoch: 29 Average val loss: -1.3058\n",
            "====> Epoch: 30 Average train loss: -1.9616\n",
            "====> Epoch: 30 Average val loss: -1.3057\n",
            "====> Epoch: 31 Average train loss: -1.9642\n",
            "====> Epoch: 31 Average val loss: -1.3042\n",
            "====> Epoch: 32 Average train loss: -1.9668\n",
            "====> Epoch: 32 Average val loss: -1.3020\n",
            "====> Epoch: 33 Average train loss: -1.9694\n",
            "====> Epoch: 33 Average val loss: -1.2983\n",
            "====> Epoch: 34 Average train loss: -1.9716\n",
            "====> Epoch: 34 Average val loss: -1.2962\n",
            "====> Epoch: 35 Average train loss: -1.9737\n",
            "====> Epoch: 35 Average val loss: -1.2962\n",
            "====> Epoch: 36 Average train loss: -1.9758\n",
            "====> Epoch: 36 Average val loss: -1.2965\n",
            "====> Epoch: 37 Average train loss: -1.9777\n",
            "====> Epoch: 37 Average val loss: -1.2959\n",
            "====> Epoch: 38 Average train loss: -1.9795\n",
            "====> Epoch: 38 Average val loss: -1.2942\n",
            "====> Epoch: 39 Average train loss: -1.9811\n",
            "====> Epoch: 39 Average val loss: -1.2928\n",
            "====> Epoch: 40 Average train loss: -1.9825\n",
            "====> Epoch: 40 Average val loss: -1.2914\n",
            "====> Epoch: 41 Average train loss: -1.9838\n",
            "====> Epoch: 41 Average val loss: -1.2901\n",
            "====> Epoch: 42 Average train loss: -1.9851\n",
            "====> Epoch: 42 Average val loss: -1.2885\n",
            "====> Epoch: 43 Average train loss: -1.9863\n",
            "====> Epoch: 43 Average val loss: -1.2872\n",
            "====> Epoch: 44 Average train loss: -1.9874\n",
            "====> Epoch: 44 Average val loss: -1.2874\n",
            "====> Epoch: 45 Average train loss: -1.9884\n",
            "====> Epoch: 45 Average val loss: -1.2892\n",
            "====> Epoch: 46 Average train loss: -1.9894\n",
            "====> Epoch: 46 Average val loss: -1.2904\n",
            "====> Epoch: 47 Average train loss: -1.9902\n",
            "====> Epoch: 47 Average val loss: -1.2898\n",
            "====> Epoch: 48 Average train loss: -1.9910\n",
            "====> Epoch: 48 Average val loss: -1.2882\n",
            "====> Epoch: 49 Average train loss: -1.9917\n",
            "====> Epoch: 49 Average val loss: -1.2873\n",
            "====> Epoch: 50 Average train loss: -1.9924\n",
            "====> Epoch: 50 Average val loss: -1.2876\n",
            "====> Epoch: 51 Average train loss: -1.9930\n",
            "====> Epoch: 51 Average val loss: -1.2880\n",
            "====> Epoch: 52 Average train loss: -1.9936\n",
            "====> Epoch: 52 Average val loss: -1.2877\n",
            "====> Epoch: 53 Average train loss: -1.9942\n",
            "====> Epoch: 53 Average val loss: -1.2862\n",
            "====> Epoch: 54 Average train loss: -1.9947\n",
            "====> Epoch: 54 Average val loss: -1.2850\n",
            "====> Epoch: 55 Average train loss: -1.9952\n",
            "====> Epoch: 55 Average val loss: -1.2853\n",
            "====> Epoch: 56 Average train loss: -1.9956\n",
            "====> Epoch: 56 Average val loss: -1.2856\n",
            "====> Epoch: 57 Average train loss: -1.9960\n",
            "====> Epoch: 57 Average val loss: -1.2850\n",
            "====> Epoch: 58 Average train loss: -1.9963\n",
            "====> Epoch: 58 Average val loss: -1.2837\n",
            "====> Epoch: 59 Average train loss: -1.9966\n",
            "====> Epoch: 59 Average val loss: -1.2832\n",
            "====> Epoch: 60 Average train loss: -1.9969\n",
            "====> Epoch: 60 Average val loss: -1.2834\n",
            "====> Epoch: 61 Average train loss: -1.9971\n",
            "====> Epoch: 61 Average val loss: -1.2834\n",
            "====> Epoch: 62 Average train loss: -1.9974\n",
            "====> Epoch: 62 Average val loss: -1.2825\n",
            "====> Epoch: 63 Average train loss: -1.9976\n",
            "====> Epoch: 63 Average val loss: -1.2818\n",
            "====> Epoch: 64 Average train loss: -1.9978\n",
            "====> Epoch: 64 Average val loss: -1.2819\n",
            "====> Epoch: 65 Average train loss: -1.9980\n",
            "====> Epoch: 65 Average val loss: -1.2829\n",
            "====> Epoch: 66 Average train loss: -1.9982\n",
            "====> Epoch: 66 Average val loss: -1.2835\n",
            "====> Epoch: 67 Average train loss: -1.9984\n",
            "====> Epoch: 67 Average val loss: -1.2831\n",
            "====> Epoch: 68 Average train loss: -1.9985\n",
            "====> Epoch: 68 Average val loss: -1.2822\n",
            "====> Epoch: 69 Average train loss: -1.9986\n",
            "====> Epoch: 69 Average val loss: -1.2817\n",
            "====> Epoch: 70 Average train loss: -1.9987\n",
            "====> Epoch: 70 Average val loss: -1.2815\n",
            "====> Epoch: 71 Average train loss: -1.9989\n",
            "====> Epoch: 71 Average val loss: -1.2813\n",
            "====> Epoch: 72 Average train loss: -1.9990\n",
            "====> Epoch: 72 Average val loss: -1.2809\n",
            "====> Epoch: 73 Average train loss: -1.9990\n",
            "====> Epoch: 73 Average val loss: -1.2803\n",
            "====> Epoch: 74 Average train loss: -1.9991\n",
            "====> Epoch: 74 Average val loss: -1.2801\n",
            "====> Epoch: 75 Average train loss: -1.9992\n",
            "====> Epoch: 75 Average val loss: -1.2804\n",
            "====> Epoch: 76 Average train loss: -1.9993\n",
            "====> Epoch: 76 Average val loss: -1.2807\n",
            "====> Epoch: 77 Average train loss: -1.9993\n",
            "====> Epoch: 77 Average val loss: -1.2807\n",
            "====> Epoch: 78 Average train loss: -1.9994\n",
            "====> Epoch: 78 Average val loss: -1.2806\n",
            "====> Epoch: 79 Average train loss: -1.9995\n",
            "====> Epoch: 79 Average val loss: -1.2805\n",
            "====> Epoch: 80 Average train loss: -1.9995\n",
            "====> Epoch: 80 Average val loss: -1.2804\n",
            "====> Epoch: 81 Average train loss: -1.9996\n",
            "====> Epoch: 81 Average val loss: -1.2802\n",
            "====> Epoch: 82 Average train loss: -1.9996\n",
            "====> Epoch: 82 Average val loss: -1.2801\n",
            "====> Epoch: 83 Average train loss: -1.9996\n",
            "====> Epoch: 83 Average val loss: -1.2802\n",
            "====> Epoch: 84 Average train loss: -1.9997\n",
            "====> Epoch: 84 Average val loss: -1.2802\n",
            "====> Epoch: 85 Average train loss: -1.9997\n",
            "====> Epoch: 85 Average val loss: -1.2800\n",
            "====> Epoch: 86 Average train loss: -1.9997\n",
            "====> Epoch: 86 Average val loss: -1.2798\n",
            "====> Epoch: 87 Average train loss: -1.9997\n",
            "====> Epoch: 87 Average val loss: -1.2799\n",
            "====> Epoch: 88 Average train loss: -1.9998\n",
            "====> Epoch: 88 Average val loss: -1.2802\n",
            "====> Epoch: 89 Average train loss: -1.9998\n",
            "====> Epoch: 89 Average val loss: -1.2803\n",
            "====> Epoch: 90 Average train loss: -1.9998\n",
            "====> Epoch: 90 Average val loss: -1.2800\n",
            "====> Epoch: 91 Average train loss: -1.9998\n",
            "====> Epoch: 91 Average val loss: -1.2798\n",
            "====> Epoch: 92 Average train loss: -1.9998\n",
            "====> Epoch: 92 Average val loss: -1.2798\n",
            "====> Epoch: 93 Average train loss: -1.9999\n",
            "====> Epoch: 93 Average val loss: -1.2799\n",
            "====> Epoch: 94 Average train loss: -1.9999\n",
            "====> Epoch: 94 Average val loss: -1.2800\n",
            "====> Epoch: 95 Average train loss: -1.9999\n",
            "====> Epoch: 95 Average val loss: -1.2800\n",
            "====> Epoch: 96 Average train loss: -1.9999\n",
            "====> Epoch: 96 Average val loss: -1.2801\n",
            "====> Epoch: 97 Average train loss: -1.9999\n",
            "====> Epoch: 97 Average val loss: -1.2801\n",
            "====> Epoch: 98 Average train loss: -1.9999\n",
            "====> Epoch: 98 Average val loss: -1.2799\n",
            "====> Epoch: 99 Average train loss: -1.9999\n",
            "====> Epoch: 99 Average val loss: -1.2796\n",
            "====> Epoch: 100 Average train loss: -1.9999\n",
            "====> Epoch: 100 Average val loss: -1.2796\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/cca_zoo/plot_utils.py:269: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  plt.figure()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "total parameters:  402948\n",
            "====> Epoch: 1 Average train loss: -0.1679\n",
            "====> Epoch: 1 Average val loss: -0.7035\n",
            "Min loss -0.70\n",
            "====> Epoch: 2 Average train loss: -0.7201\n",
            "====> Epoch: 2 Average val loss: -1.1391\n",
            "Min loss -1.14\n",
            "====> Epoch: 3 Average train loss: -1.3139\n",
            "====> Epoch: 3 Average val loss: -1.2081\n",
            "Min loss -1.21\n",
            "====> Epoch: 4 Average train loss: -1.4056\n",
            "====> Epoch: 4 Average val loss: -1.2373\n",
            "Min loss -1.24\n",
            "====> Epoch: 5 Average train loss: -1.4574\n",
            "====> Epoch: 5 Average val loss: -1.2524\n",
            "Min loss -1.25\n",
            "====> Epoch: 6 Average train loss: -1.4938\n",
            "====> Epoch: 6 Average val loss: -1.2643\n",
            "Min loss -1.26\n",
            "====> Epoch: 7 Average train loss: -1.5232\n",
            "====> Epoch: 7 Average val loss: -1.2754\n",
            "Min loss -1.28\n",
            "====> Epoch: 8 Average train loss: -1.5500\n",
            "====> Epoch: 8 Average val loss: -1.2859\n",
            "Min loss -1.29\n",
            "====> Epoch: 9 Average train loss: -1.5750\n",
            "====> Epoch: 9 Average val loss: -1.2957\n",
            "Min loss -1.30\n",
            "====> Epoch: 10 Average train loss: -1.5991\n",
            "====> Epoch: 10 Average val loss: -1.3044\n",
            "Min loss -1.30\n",
            "====> Epoch: 11 Average train loss: -1.6226\n",
            "====> Epoch: 11 Average val loss: -1.3116\n",
            "Min loss -1.31\n",
            "====> Epoch: 12 Average train loss: -1.6452\n",
            "====> Epoch: 12 Average val loss: -1.3178\n",
            "Min loss -1.32\n",
            "====> Epoch: 13 Average train loss: -1.6671\n",
            "====> Epoch: 13 Average val loss: -1.3223\n",
            "Min loss -1.32\n",
            "====> Epoch: 14 Average train loss: -1.6885\n",
            "====> Epoch: 14 Average val loss: -1.3253\n",
            "Min loss -1.33\n",
            "====> Epoch: 15 Average train loss: -1.7096\n",
            "====> Epoch: 15 Average val loss: -1.3252\n",
            "====> Epoch: 16 Average train loss: -1.7293\n",
            "====> Epoch: 16 Average val loss: -1.3214\n",
            "====> Epoch: 17 Average train loss: -1.7465\n",
            "====> Epoch: 17 Average val loss: -1.3157\n",
            "====> Epoch: 18 Average train loss: -1.7618\n",
            "====> Epoch: 18 Average val loss: -1.3086\n",
            "====> Epoch: 19 Average train loss: -1.7744\n",
            "====> Epoch: 19 Average val loss: -1.3023\n",
            "====> Epoch: 20 Average train loss: -1.7862\n",
            "====> Epoch: 20 Average val loss: -1.2997\n",
            "====> Epoch: 21 Average train loss: -1.7983\n",
            "====> Epoch: 21 Average val loss: -1.3046\n",
            "====> Epoch: 22 Average train loss: -1.8117\n",
            "====> Epoch: 22 Average val loss: -1.3113\n",
            "====> Epoch: 23 Average train loss: -1.8240\n",
            "====> Epoch: 23 Average val loss: -1.3169\n",
            "====> Epoch: 24 Average train loss: -1.8345\n",
            "====> Epoch: 24 Average val loss: -1.3201\n",
            "====> Epoch: 25 Average train loss: -1.8435\n",
            "====> Epoch: 25 Average val loss: -1.3207\n",
            "====> Epoch: 26 Average train loss: -1.8518\n",
            "====> Epoch: 26 Average val loss: -1.3190\n",
            "====> Epoch: 27 Average train loss: -1.8594\n",
            "====> Epoch: 27 Average val loss: -1.3164\n",
            "====> Epoch: 28 Average train loss: -1.8674\n",
            "====> Epoch: 28 Average val loss: -1.3132\n",
            "====> Epoch: 29 Average train loss: -1.8755\n",
            "====> Epoch: 29 Average val loss: -1.3085\n",
            "====> Epoch: 30 Average train loss: -1.8837\n",
            "====> Epoch: 30 Average val loss: -1.3030\n",
            "====> Epoch: 31 Average train loss: -1.8909\n",
            "====> Epoch: 31 Average val loss: -1.2952\n",
            "====> Epoch: 32 Average train loss: -1.8973\n",
            "====> Epoch: 32 Average val loss: -1.2854\n",
            "====> Epoch: 33 Average train loss: -1.9029\n",
            "====> Epoch: 33 Average val loss: -1.2770\n",
            "====> Epoch: 34 Average train loss: -1.9080\n",
            "====> Epoch: 34 Average val loss: -1.2734\n",
            "====> Epoch: 35 Average train loss: -1.9128\n",
            "====> Epoch: 35 Average val loss: -1.2740\n",
            "====> Epoch: 36 Average train loss: -1.9178\n",
            "====> Epoch: 36 Average val loss: -1.2754\n",
            "====> Epoch: 37 Average train loss: -1.9228\n",
            "====> Epoch: 37 Average val loss: -1.2764\n",
            "====> Epoch: 38 Average train loss: -1.9274\n",
            "====> Epoch: 38 Average val loss: -1.2781\n",
            "====> Epoch: 39 Average train loss: -1.9312\n",
            "====> Epoch: 39 Average val loss: -1.2794\n",
            "====> Epoch: 40 Average train loss: -1.9347\n",
            "====> Epoch: 40 Average val loss: -1.2803\n",
            "====> Epoch: 41 Average train loss: -1.9382\n",
            "====> Epoch: 41 Average val loss: -1.2805\n",
            "====> Epoch: 42 Average train loss: -1.9415\n",
            "====> Epoch: 42 Average val loss: -1.2788\n",
            "====> Epoch: 43 Average train loss: -1.9450\n",
            "====> Epoch: 43 Average val loss: -1.2750\n",
            "====> Epoch: 44 Average train loss: -1.9483\n",
            "====> Epoch: 44 Average val loss: -1.2708\n",
            "====> Epoch: 45 Average train loss: -1.9515\n",
            "====> Epoch: 45 Average val loss: -1.2677\n",
            "====> Epoch: 46 Average train loss: -1.9544\n",
            "====> Epoch: 46 Average val loss: -1.2657\n",
            "====> Epoch: 47 Average train loss: -1.9571\n",
            "====> Epoch: 47 Average val loss: -1.2650\n",
            "====> Epoch: 48 Average train loss: -1.9598\n",
            "====> Epoch: 48 Average val loss: -1.2663\n",
            "====> Epoch: 49 Average train loss: -1.9624\n",
            "====> Epoch: 49 Average val loss: -1.2679\n",
            "====> Epoch: 50 Average train loss: -1.9647\n",
            "====> Epoch: 50 Average val loss: -1.2688\n",
            "====> Epoch: 51 Average train loss: -1.9667\n",
            "====> Epoch: 51 Average val loss: -1.2690\n",
            "====> Epoch: 52 Average train loss: -1.9687\n",
            "====> Epoch: 52 Average val loss: -1.2680\n",
            "====> Epoch: 53 Average train loss: -1.9707\n",
            "====> Epoch: 53 Average val loss: -1.2667\n",
            "====> Epoch: 54 Average train loss: -1.9725\n",
            "====> Epoch: 54 Average val loss: -1.2652\n",
            "====> Epoch: 55 Average train loss: -1.9744\n",
            "====> Epoch: 55 Average val loss: -1.2630\n",
            "====> Epoch: 56 Average train loss: -1.9761\n",
            "====> Epoch: 56 Average val loss: -1.2606\n",
            "====> Epoch: 57 Average train loss: -1.9778\n",
            "====> Epoch: 57 Average val loss: -1.2594\n",
            "====> Epoch: 58 Average train loss: -1.9793\n",
            "====> Epoch: 58 Average val loss: -1.2596\n",
            "====> Epoch: 59 Average train loss: -1.9808\n",
            "====> Epoch: 59 Average val loss: -1.2606\n",
            "====> Epoch: 60 Average train loss: -1.9822\n",
            "====> Epoch: 60 Average val loss: -1.2622\n",
            "====> Epoch: 61 Average train loss: -1.9834\n",
            "====> Epoch: 61 Average val loss: -1.2619\n",
            "====> Epoch: 62 Average train loss: -1.9846\n",
            "====> Epoch: 62 Average val loss: -1.2610\n",
            "====> Epoch: 63 Average train loss: -1.9857\n",
            "====> Epoch: 63 Average val loss: -1.2598\n",
            "====> Epoch: 64 Average train loss: -1.9868\n",
            "====> Epoch: 64 Average val loss: -1.2569\n",
            "====> Epoch: 65 Average train loss: -1.9878\n",
            "====> Epoch: 65 Average val loss: -1.2545\n",
            "====> Epoch: 66 Average train loss: -1.9887\n",
            "====> Epoch: 66 Average val loss: -1.2530\n",
            "====> Epoch: 67 Average train loss: -1.9895\n",
            "====> Epoch: 67 Average val loss: -1.2516\n",
            "====> Epoch: 68 Average train loss: -1.9903\n",
            "====> Epoch: 68 Average val loss: -1.2516\n",
            "====> Epoch: 69 Average train loss: -1.9910\n",
            "====> Epoch: 69 Average val loss: -1.2511\n",
            "====> Epoch: 70 Average train loss: -1.9918\n",
            "====> Epoch: 70 Average val loss: -1.2503\n",
            "====> Epoch: 71 Average train loss: -1.9924\n",
            "====> Epoch: 71 Average val loss: -1.2501\n",
            "====> Epoch: 72 Average train loss: -1.9930\n",
            "====> Epoch: 72 Average val loss: -1.2496\n",
            "====> Epoch: 73 Average train loss: -1.9935\n",
            "====> Epoch: 73 Average val loss: -1.2486\n",
            "====> Epoch: 74 Average train loss: -1.9940\n",
            "====> Epoch: 74 Average val loss: -1.2484\n",
            "====> Epoch: 75 Average train loss: -1.9945\n",
            "====> Epoch: 75 Average val loss: -1.2474\n",
            "====> Epoch: 76 Average train loss: -1.9950\n",
            "====> Epoch: 76 Average val loss: -1.2461\n",
            "====> Epoch: 77 Average train loss: -1.9954\n",
            "====> Epoch: 77 Average val loss: -1.2462\n",
            "====> Epoch: 78 Average train loss: -1.9958\n",
            "====> Epoch: 78 Average val loss: -1.2457\n",
            "====> Epoch: 79 Average train loss: -1.9961\n",
            "====> Epoch: 79 Average val loss: -1.2446\n",
            "====> Epoch: 80 Average train loss: -1.9964\n",
            "====> Epoch: 80 Average val loss: -1.2437\n",
            "====> Epoch: 81 Average train loss: -1.9967\n",
            "====> Epoch: 81 Average val loss: -1.2432\n",
            "====> Epoch: 82 Average train loss: -1.9970\n",
            "====> Epoch: 82 Average val loss: -1.2421\n",
            "====> Epoch: 83 Average train loss: -1.9973\n",
            "====> Epoch: 83 Average val loss: -1.2412\n",
            "====> Epoch: 84 Average train loss: -1.9975\n",
            "====> Epoch: 84 Average val loss: -1.2412\n",
            "====> Epoch: 85 Average train loss: -1.9977\n",
            "====> Epoch: 85 Average val loss: -1.2410\n",
            "====> Epoch: 86 Average train loss: -1.9979\n",
            "====> Epoch: 86 Average val loss: -1.2402\n",
            "====> Epoch: 87 Average train loss: -1.9981\n",
            "====> Epoch: 87 Average val loss: -1.2387\n",
            "====> Epoch: 88 Average train loss: -1.9983\n",
            "====> Epoch: 88 Average val loss: -1.2383\n",
            "====> Epoch: 89 Average train loss: -1.9984\n",
            "====> Epoch: 89 Average val loss: -1.2382\n",
            "====> Epoch: 90 Average train loss: -1.9986\n",
            "====> Epoch: 90 Average val loss: -1.2376\n",
            "====> Epoch: 91 Average train loss: -1.9987\n",
            "====> Epoch: 91 Average val loss: -1.2375\n",
            "====> Epoch: 92 Average train loss: -1.9988\n",
            "====> Epoch: 92 Average val loss: -1.2376\n",
            "====> Epoch: 93 Average train loss: -1.9989\n",
            "====> Epoch: 93 Average val loss: -1.2378\n",
            "====> Epoch: 94 Average train loss: -1.9990\n",
            "====> Epoch: 94 Average val loss: -1.2373\n",
            "====> Epoch: 95 Average train loss: -1.9991\n",
            "====> Epoch: 95 Average val loss: -1.2367\n",
            "====> Epoch: 96 Average train loss: -1.9992\n",
            "====> Epoch: 96 Average val loss: -1.2365\n",
            "====> Epoch: 97 Average train loss: -1.9993\n",
            "====> Epoch: 97 Average val loss: -1.2359\n",
            "====> Epoch: 98 Average train loss: -1.9993\n",
            "====> Epoch: 98 Average val loss: -1.2353\n",
            "====> Epoch: 99 Average train loss: -1.9994\n",
            "====> Epoch: 99 Average val loss: -1.2359\n",
            "====> Epoch: 100 Average train loss: -1.9995\n",
            "====> Epoch: 100 Average val loss: -1.2362\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/cca_zoo/plot_utils.py:269: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  plt.figure()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCMeGlxJkp93"
      },
      "source": [
        "# Using different model architectures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "k9TEto00kpn2",
        "outputId": "5ebd2290-33dd-4955-f367-50115f7745d8"
      },
      "source": [
        "\"\"\"\r\n",
        "### Convolutional Deep Learning\r\n",
        "\r\n",
        "We can vary the encoder architecture from the default fcn to encoder/decoder based on the brainnetcnn architecture or a simple cnn\r\n",
        "\"\"\"\r\n",
        "from cca_zoo import deep_models\r\n",
        "# %%\r\n",
        "cfg = Config()\r\n",
        "cfg.epoch_num = 100\r\n",
        "cfg.encoder_models = [deep_models.CNNEncoder, deep_models.CNNEncoder]\r\n",
        "cfg.encoder_args = [{'channels': [3, 3]}, {'channels': [3, 3]}]\r\n",
        "# to change the models used change the cfg.encoder_models. We implement a CNN_Encoder and CNN_decoder as well\r\n",
        "# as some based on brainnet architecture in cca_zoo.deep_models. Equally you could pass your own encoder/decoder models\r\n",
        "\r\n",
        "dcca_conv = deepwrapper.DeepWrapper(cfg)\r\n",
        "\r\n",
        "dcca_conv.fit(train_view_1.reshape((-1, 1, 28, 28)), train_view_2.reshape((-1, 1, 28, 28)))\r\n",
        "\r\n",
        "dcca_conv_results = np.stack((dcca_conv.train_correlations, dcca_conv.predict_corr(test_view_1.reshape((-1, 1, 28, 28)),\r\n",
        "                                                                                   test_view_2.reshape(\r\n",
        "                                                                                       (-1, 1, 28, 28)))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total parameters:  1204\n",
            "====> Epoch: 1 Average train loss: -0.1742\n",
            "====> Epoch: 1 Average val loss: -0.1891\n",
            "Min loss -0.19\n",
            "====> Epoch: 2 Average train loss: -0.2741\n",
            "====> Epoch: 2 Average val loss: -0.2190\n",
            "Min loss -0.22\n",
            "====> Epoch: 3 Average train loss: -0.3481\n",
            "====> Epoch: 3 Average val loss: -0.2434\n",
            "Min loss -0.24\n",
            "====> Epoch: 4 Average train loss: -0.4097\n",
            "====> Epoch: 4 Average val loss: -0.2683\n",
            "Min loss -0.27\n",
            "====> Epoch: 5 Average train loss: -0.4734\n",
            "====> Epoch: 5 Average val loss: -0.2936\n",
            "Min loss -0.29\n",
            "====> Epoch: 6 Average train loss: -0.5331\n",
            "====> Epoch: 6 Average val loss: -0.3175\n",
            "Min loss -0.32\n",
            "====> Epoch: 7 Average train loss: -0.5839\n",
            "====> Epoch: 7 Average val loss: -0.3442\n",
            "Min loss -0.34\n",
            "====> Epoch: 8 Average train loss: -0.6289\n",
            "====> Epoch: 8 Average val loss: -0.3711\n",
            "Min loss -0.37\n",
            "====> Epoch: 9 Average train loss: -0.6714\n",
            "====> Epoch: 9 Average val loss: -0.4000\n",
            "Min loss -0.40\n",
            "====> Epoch: 10 Average train loss: -0.7146\n",
            "====> Epoch: 10 Average val loss: -0.4321\n",
            "Min loss -0.43\n",
            "====> Epoch: 11 Average train loss: -0.7588\n",
            "====> Epoch: 11 Average val loss: -0.4672\n",
            "Min loss -0.47\n",
            "====> Epoch: 12 Average train loss: -0.8025\n",
            "====> Epoch: 12 Average val loss: -0.5058\n",
            "Min loss -0.51\n",
            "====> Epoch: 13 Average train loss: -0.8466\n",
            "====> Epoch: 13 Average val loss: -0.5476\n",
            "Min loss -0.55\n",
            "====> Epoch: 14 Average train loss: -0.8905\n",
            "====> Epoch: 14 Average val loss: -0.5909\n",
            "Min loss -0.59\n",
            "====> Epoch: 15 Average train loss: -0.9347\n",
            "====> Epoch: 15 Average val loss: -0.6357\n",
            "Min loss -0.64\n",
            "====> Epoch: 16 Average train loss: -0.9789\n",
            "====> Epoch: 16 Average val loss: -0.6821\n",
            "Min loss -0.68\n",
            "====> Epoch: 17 Average train loss: -1.0226\n",
            "====> Epoch: 17 Average val loss: -0.7296\n",
            "Min loss -0.73\n",
            "====> Epoch: 18 Average train loss: -1.0666\n",
            "====> Epoch: 18 Average val loss: -0.7790\n",
            "Min loss -0.78\n",
            "====> Epoch: 19 Average train loss: -1.1087\n",
            "====> Epoch: 19 Average val loss: -0.8280\n",
            "Min loss -0.83\n",
            "====> Epoch: 20 Average train loss: -1.1488\n",
            "====> Epoch: 20 Average val loss: -0.8763\n",
            "Min loss -0.88\n",
            "====> Epoch: 21 Average train loss: -1.1865\n",
            "====> Epoch: 21 Average val loss: -0.9226\n",
            "Min loss -0.92\n",
            "====> Epoch: 22 Average train loss: -1.2221\n",
            "====> Epoch: 22 Average val loss: -0.9661\n",
            "Min loss -0.97\n",
            "====> Epoch: 23 Average train loss: -1.2545\n",
            "====> Epoch: 23 Average val loss: -1.0059\n",
            "Min loss -1.01\n",
            "====> Epoch: 24 Average train loss: -1.2832\n",
            "====> Epoch: 24 Average val loss: -1.0418\n",
            "Min loss -1.04\n",
            "====> Epoch: 25 Average train loss: -1.3097\n",
            "====> Epoch: 25 Average val loss: -1.0744\n",
            "Min loss -1.07\n",
            "====> Epoch: 26 Average train loss: -1.3336\n",
            "====> Epoch: 26 Average val loss: -1.1040\n",
            "Min loss -1.10\n",
            "====> Epoch: 27 Average train loss: -1.3546\n",
            "====> Epoch: 27 Average val loss: -1.1307\n",
            "Min loss -1.13\n",
            "====> Epoch: 28 Average train loss: -1.3734\n",
            "====> Epoch: 28 Average val loss: -1.1546\n",
            "Min loss -1.15\n",
            "====> Epoch: 29 Average train loss: -1.3904\n",
            "====> Epoch: 29 Average val loss: -1.1760\n",
            "Min loss -1.18\n",
            "====> Epoch: 30 Average train loss: -1.4059\n",
            "====> Epoch: 30 Average val loss: -1.1952\n",
            "Min loss -1.20\n",
            "====> Epoch: 31 Average train loss: -1.4197\n",
            "====> Epoch: 31 Average val loss: -1.2126\n",
            "Min loss -1.21\n",
            "====> Epoch: 32 Average train loss: -1.4322\n",
            "====> Epoch: 32 Average val loss: -1.2282\n",
            "Min loss -1.23\n",
            "====> Epoch: 33 Average train loss: -1.4439\n",
            "====> Epoch: 33 Average val loss: -1.2422\n",
            "Min loss -1.24\n",
            "====> Epoch: 34 Average train loss: -1.4547\n",
            "====> Epoch: 34 Average val loss: -1.2550\n",
            "Min loss -1.25\n",
            "====> Epoch: 35 Average train loss: -1.4650\n",
            "====> Epoch: 35 Average val loss: -1.2661\n",
            "Min loss -1.27\n",
            "====> Epoch: 36 Average train loss: -1.4747\n",
            "====> Epoch: 36 Average val loss: -1.2760\n",
            "Min loss -1.28\n",
            "====> Epoch: 37 Average train loss: -1.4839\n",
            "====> Epoch: 37 Average val loss: -1.2849\n",
            "Min loss -1.28\n",
            "====> Epoch: 38 Average train loss: -1.4923\n",
            "====> Epoch: 38 Average val loss: -1.2928\n",
            "Min loss -1.29\n",
            "====> Epoch: 39 Average train loss: -1.5003\n",
            "====> Epoch: 39 Average val loss: -1.2999\n",
            "Min loss -1.30\n",
            "====> Epoch: 40 Average train loss: -1.5079\n",
            "====> Epoch: 40 Average val loss: -1.3065\n",
            "Min loss -1.31\n",
            "====> Epoch: 41 Average train loss: -1.5151\n",
            "====> Epoch: 41 Average val loss: -1.3125\n",
            "Min loss -1.31\n",
            "====> Epoch: 42 Average train loss: -1.5221\n",
            "====> Epoch: 42 Average val loss: -1.3181\n",
            "Min loss -1.32\n",
            "====> Epoch: 43 Average train loss: -1.5290\n",
            "====> Epoch: 43 Average val loss: -1.3230\n",
            "Min loss -1.32\n",
            "====> Epoch: 44 Average train loss: -1.5357\n",
            "====> Epoch: 44 Average val loss: -1.3275\n",
            "Min loss -1.33\n",
            "====> Epoch: 45 Average train loss: -1.5424\n",
            "====> Epoch: 45 Average val loss: -1.3315\n",
            "Min loss -1.33\n",
            "====> Epoch: 46 Average train loss: -1.5491\n",
            "====> Epoch: 46 Average val loss: -1.3351\n",
            "Min loss -1.34\n",
            "====> Epoch: 47 Average train loss: -1.5557\n",
            "====> Epoch: 47 Average val loss: -1.3382\n",
            "Min loss -1.34\n",
            "====> Epoch: 48 Average train loss: -1.5622\n",
            "====> Epoch: 48 Average val loss: -1.3408\n",
            "Min loss -1.34\n",
            "====> Epoch: 49 Average train loss: -1.5686\n",
            "====> Epoch: 49 Average val loss: -1.3429\n",
            "Min loss -1.34\n",
            "====> Epoch: 50 Average train loss: -1.5749\n",
            "====> Epoch: 50 Average val loss: -1.3444\n",
            "Min loss -1.34\n",
            "====> Epoch: 51 Average train loss: -1.5810\n",
            "====> Epoch: 51 Average val loss: -1.3457\n",
            "Min loss -1.35\n",
            "====> Epoch: 52 Average train loss: -1.5870\n",
            "====> Epoch: 52 Average val loss: -1.3467\n",
            "Min loss -1.35\n",
            "====> Epoch: 53 Average train loss: -1.5927\n",
            "====> Epoch: 53 Average val loss: -1.3474\n",
            "Min loss -1.35\n",
            "====> Epoch: 54 Average train loss: -1.5981\n",
            "====> Epoch: 54 Average val loss: -1.3479\n",
            "Min loss -1.35\n",
            "====> Epoch: 55 Average train loss: -1.6033\n",
            "====> Epoch: 55 Average val loss: -1.3480\n",
            "Min loss -1.35\n",
            "====> Epoch: 56 Average train loss: -1.6083\n",
            "====> Epoch: 56 Average val loss: -1.3480\n",
            "====> Epoch: 57 Average train loss: -1.6131\n",
            "====> Epoch: 57 Average val loss: -1.3479\n",
            "====> Epoch: 58 Average train loss: -1.6178\n",
            "====> Epoch: 58 Average val loss: -1.3479\n",
            "====> Epoch: 59 Average train loss: -1.6225\n",
            "====> Epoch: 59 Average val loss: -1.3478\n",
            "====> Epoch: 60 Average train loss: -1.6271\n",
            "====> Epoch: 60 Average val loss: -1.3475\n",
            "====> Epoch: 61 Average train loss: -1.6316\n",
            "====> Epoch: 61 Average val loss: -1.3471\n",
            "====> Epoch: 62 Average train loss: -1.6360\n",
            "====> Epoch: 62 Average val loss: -1.3465\n",
            "====> Epoch: 63 Average train loss: -1.6402\n",
            "====> Epoch: 63 Average val loss: -1.3458\n",
            "====> Epoch: 64 Average train loss: -1.6443\n",
            "====> Epoch: 64 Average val loss: -1.3452\n",
            "====> Epoch: 65 Average train loss: -1.6484\n",
            "====> Epoch: 65 Average val loss: -1.3446\n",
            "====> Epoch: 66 Average train loss: -1.6523\n",
            "====> Epoch: 66 Average val loss: -1.3441\n",
            "====> Epoch: 67 Average train loss: -1.6562\n",
            "====> Epoch: 67 Average val loss: -1.3438\n",
            "====> Epoch: 68 Average train loss: -1.6600\n",
            "====> Epoch: 68 Average val loss: -1.3436\n",
            "====> Epoch: 69 Average train loss: -1.6639\n",
            "====> Epoch: 69 Average val loss: -1.3435\n",
            "====> Epoch: 70 Average train loss: -1.6678\n",
            "====> Epoch: 70 Average val loss: -1.3436\n",
            "====> Epoch: 71 Average train loss: -1.6715\n",
            "====> Epoch: 71 Average val loss: -1.3438\n",
            "====> Epoch: 72 Average train loss: -1.6752\n",
            "====> Epoch: 72 Average val loss: -1.3440\n",
            "====> Epoch: 73 Average train loss: -1.6787\n",
            "====> Epoch: 73 Average val loss: -1.3441\n",
            "====> Epoch: 74 Average train loss: -1.6823\n",
            "====> Epoch: 74 Average val loss: -1.3440\n",
            "====> Epoch: 75 Average train loss: -1.6858\n",
            "====> Epoch: 75 Average val loss: -1.3437\n",
            "====> Epoch: 76 Average train loss: -1.6893\n",
            "====> Epoch: 76 Average val loss: -1.3432\n",
            "====> Epoch: 77 Average train loss: -1.6928\n",
            "====> Epoch: 77 Average val loss: -1.3426\n",
            "====> Epoch: 78 Average train loss: -1.6963\n",
            "====> Epoch: 78 Average val loss: -1.3420\n",
            "====> Epoch: 79 Average train loss: -1.6997\n",
            "====> Epoch: 79 Average val loss: -1.3412\n",
            "====> Epoch: 80 Average train loss: -1.7031\n",
            "====> Epoch: 80 Average val loss: -1.3404\n",
            "====> Epoch: 81 Average train loss: -1.7065\n",
            "====> Epoch: 81 Average val loss: -1.3399\n",
            "====> Epoch: 82 Average train loss: -1.7099\n",
            "====> Epoch: 82 Average val loss: -1.3395\n",
            "====> Epoch: 83 Average train loss: -1.7133\n",
            "====> Epoch: 83 Average val loss: -1.3392\n",
            "====> Epoch: 84 Average train loss: -1.7166\n",
            "====> Epoch: 84 Average val loss: -1.3389\n",
            "====> Epoch: 85 Average train loss: -1.7200\n",
            "====> Epoch: 85 Average val loss: -1.3386\n",
            "====> Epoch: 86 Average train loss: -1.7234\n",
            "====> Epoch: 86 Average val loss: -1.3381\n",
            "====> Epoch: 87 Average train loss: -1.7266\n",
            "====> Epoch: 87 Average val loss: -1.3376\n",
            "====> Epoch: 88 Average train loss: -1.7298\n",
            "====> Epoch: 88 Average val loss: -1.3369\n",
            "====> Epoch: 89 Average train loss: -1.7328\n",
            "====> Epoch: 89 Average val loss: -1.3360\n",
            "====> Epoch: 90 Average train loss: -1.7359\n",
            "====> Epoch: 90 Average val loss: -1.3351\n",
            "====> Epoch: 91 Average train loss: -1.7390\n",
            "====> Epoch: 91 Average val loss: -1.3340\n",
            "====> Epoch: 92 Average train loss: -1.7419\n",
            "====> Epoch: 92 Average val loss: -1.3328\n",
            "====> Epoch: 93 Average train loss: -1.7448\n",
            "====> Epoch: 93 Average val loss: -1.3317\n",
            "====> Epoch: 94 Average train loss: -1.7478\n",
            "====> Epoch: 94 Average val loss: -1.3308\n",
            "====> Epoch: 95 Average train loss: -1.7507\n",
            "====> Epoch: 95 Average val loss: -1.3300\n",
            "====> Epoch: 96 Average train loss: -1.7536\n",
            "====> Epoch: 96 Average val loss: -1.3294\n",
            "====> Epoch: 97 Average train loss: -1.7563\n",
            "====> Epoch: 97 Average val loss: -1.3292\n",
            "====> Epoch: 98 Average train loss: -1.7591\n",
            "====> Epoch: 98 Average val loss: -1.3294\n",
            "====> Epoch: 99 Average train loss: -1.7618\n",
            "====> Epoch: 99 Average val loss: -1.3296\n",
            "====> Epoch: 100 Average train loss: -1.7645\n",
            "====> Epoch: 100 Average val loss: -1.3296\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/cca_zoo/plot_utils.py:269: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  plt.figure()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHaLX_AnkeqG"
      },
      "source": [
        "# Deep Variational CCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VNTWkuzLkZ6I",
        "outputId": "18d8eb06-6408-4be4-8f45-1b87a9b40e5b"
      },
      "source": [
        "\"\"\"\r\n",
        "### Deep Variational Learning\r\n",
        "Finally we have Deep Variational CCA methods.\r\n",
        "- Deep Variational CCA (DVCCA)\r\n",
        "- Deep Variational CCA - private (DVVCA_p)\r\n",
        "\r\n",
        "These are both implemented by the DVCCA class with private=True/False and both_encoders=True/False. If both_encoders,\r\n",
        "the encoder to the shared information Q(z_shared|x) is modelled for both x_1 and x_2 whereas if both_encoders is false\r\n",
        "it is modelled for x_1 as in the paper\r\n",
        "\"\"\"\r\n",
        "from cca_zoo import dvcca\r\n",
        "# %%\r\n",
        "# DVCCA (technically bi-DVCCA)\r\n",
        "cfg = Config()\r\n",
        "cfg.method = dvcca.DVCCA\r\n",
        "cfg.epoch_num = 100\r\n",
        "dvcca = deepwrapper.DeepWrapper(cfg)\r\n",
        "\r\n",
        "dvcca.fit(train_view_1, train_view_2)\r\n",
        "\r\n",
        "dvcca_results = np.stack((dvcca.train_correlations, dvcca.predict_corr(test_view_1, test_view_2)))\r\n",
        "\r\n",
        "# DVCCA_private (technically bi-DVCCA_private)\r\n",
        "# switch private=False default to private=True\r\n",
        "cfg.private = True\r\n",
        "\r\n",
        "dvcca_p = deepwrapper.DeepWrapper(cfg)\r\n",
        "\r\n",
        "dvcca_p.fit(train_view_1, train_view_2)\r\n",
        "\r\n",
        "dvcca_p_results = np.stack((dvcca_p.train_correlations, dvcca_p.predict_corr(test_view_1, test_view_2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total parameters:  809516\n",
            "====> Epoch: 1 Average train loss: 1105.8721\n",
            "====> Epoch: 1 Average val loss: 1079.6569\n",
            "Min loss 1079.66\n",
            "====> Epoch: 2 Average train loss: 1079.5342\n",
            "====> Epoch: 2 Average val loss: 1062.3976\n",
            "Min loss 1062.40\n",
            "====> Epoch: 3 Average train loss: 1061.5380\n",
            "====> Epoch: 3 Average val loss: 1040.3821\n",
            "Min loss 1040.38\n",
            "====> Epoch: 4 Average train loss: 1039.0693\n",
            "====> Epoch: 4 Average val loss: 1013.6394\n",
            "Min loss 1013.64\n",
            "====> Epoch: 5 Average train loss: 1011.4689\n",
            "====> Epoch: 5 Average val loss: 990.8416\n",
            "Min loss 990.84\n",
            "====> Epoch: 6 Average train loss: 986.9456\n",
            "====> Epoch: 6 Average val loss: 968.4504\n",
            "Min loss 968.45\n",
            "====> Epoch: 7 Average train loss: 962.8571\n",
            "====> Epoch: 7 Average val loss: 948.5939\n",
            "Min loss 948.59\n",
            "====> Epoch: 8 Average train loss: 942.2664\n",
            "====> Epoch: 8 Average val loss: 933.8574\n",
            "Min loss 933.86\n",
            "====> Epoch: 9 Average train loss: 927.0457\n",
            "====> Epoch: 9 Average val loss: 921.9867\n",
            "Min loss 921.99\n",
            "====> Epoch: 10 Average train loss: 914.4153\n",
            "====> Epoch: 10 Average val loss: 911.5957\n",
            "Min loss 911.60\n",
            "====> Epoch: 11 Average train loss: 903.9348\n",
            "====> Epoch: 11 Average val loss: 905.0898\n",
            "Min loss 905.09\n",
            "====> Epoch: 12 Average train loss: 896.3495\n",
            "====> Epoch: 12 Average val loss: 899.2653\n",
            "Min loss 899.27\n",
            "====> Epoch: 13 Average train loss: 890.3842\n",
            "====> Epoch: 13 Average val loss: 894.7830\n",
            "Min loss 894.78\n",
            "====> Epoch: 14 Average train loss: 885.8187\n",
            "====> Epoch: 14 Average val loss: 890.9470\n",
            "Min loss 890.95\n",
            "====> Epoch: 15 Average train loss: 882.3113\n",
            "====> Epoch: 15 Average val loss: 887.4998\n",
            "Min loss 887.50\n",
            "====> Epoch: 16 Average train loss: 879.4444\n",
            "====> Epoch: 16 Average val loss: 885.9406\n",
            "Min loss 885.94\n",
            "====> Epoch: 17 Average train loss: 877.4181\n",
            "====> Epoch: 17 Average val loss: 883.4570\n",
            "Min loss 883.46\n",
            "====> Epoch: 18 Average train loss: 874.2795\n",
            "====> Epoch: 18 Average val loss: 879.9458\n",
            "Min loss 879.95\n",
            "====> Epoch: 19 Average train loss: 871.7136\n",
            "====> Epoch: 19 Average val loss: 878.4378\n",
            "Min loss 878.44\n",
            "====> Epoch: 20 Average train loss: 869.5004\n",
            "====> Epoch: 20 Average val loss: 877.3969\n",
            "Min loss 877.40\n",
            "====> Epoch: 21 Average train loss: 867.0839\n",
            "====> Epoch: 21 Average val loss: 874.6700\n",
            "Min loss 874.67\n",
            "====> Epoch: 22 Average train loss: 865.0750\n",
            "====> Epoch: 22 Average val loss: 872.3822\n",
            "Min loss 872.38\n",
            "====> Epoch: 23 Average train loss: 863.1871\n",
            "====> Epoch: 23 Average val loss: 871.4406\n",
            "Min loss 871.44\n",
            "====> Epoch: 24 Average train loss: 862.2764\n",
            "====> Epoch: 24 Average val loss: 870.3185\n",
            "Min loss 870.32\n",
            "====> Epoch: 25 Average train loss: 859.9271\n",
            "====> Epoch: 25 Average val loss: 868.5974\n",
            "Min loss 868.60\n",
            "====> Epoch: 26 Average train loss: 859.3647\n",
            "====> Epoch: 26 Average val loss: 867.5392\n",
            "Min loss 867.54\n",
            "====> Epoch: 27 Average train loss: 858.2134\n",
            "====> Epoch: 27 Average val loss: 866.4376\n",
            "Min loss 866.44\n",
            "====> Epoch: 28 Average train loss: 856.7977\n",
            "====> Epoch: 28 Average val loss: 865.7399\n",
            "Min loss 865.74\n",
            "====> Epoch: 29 Average train loss: 855.7921\n",
            "====> Epoch: 29 Average val loss: 863.8759\n",
            "Min loss 863.88\n",
            "====> Epoch: 30 Average train loss: 855.4148\n",
            "====> Epoch: 30 Average val loss: 863.3797\n",
            "Min loss 863.38\n",
            "====> Epoch: 31 Average train loss: 853.7205\n",
            "====> Epoch: 31 Average val loss: 862.0994\n",
            "Min loss 862.10\n",
            "====> Epoch: 32 Average train loss: 852.7935\n",
            "====> Epoch: 32 Average val loss: 862.1401\n",
            "====> Epoch: 33 Average train loss: 851.9034\n",
            "====> Epoch: 33 Average val loss: 860.8850\n",
            "Min loss 860.89\n",
            "====> Epoch: 34 Average train loss: 851.0355\n",
            "====> Epoch: 34 Average val loss: 860.1305\n",
            "Min loss 860.13\n",
            "====> Epoch: 35 Average train loss: 850.2411\n",
            "====> Epoch: 35 Average val loss: 859.8013\n",
            "Min loss 859.80\n",
            "====> Epoch: 36 Average train loss: 849.8132\n",
            "====> Epoch: 36 Average val loss: 858.0233\n",
            "Min loss 858.02\n",
            "====> Epoch: 37 Average train loss: 849.1222\n",
            "====> Epoch: 37 Average val loss: 857.2781\n",
            "Min loss 857.28\n",
            "====> Epoch: 38 Average train loss: 848.0289\n",
            "====> Epoch: 38 Average val loss: 857.2172\n",
            "Min loss 857.22\n",
            "====> Epoch: 39 Average train loss: 847.2611\n",
            "====> Epoch: 39 Average val loss: 856.1500\n",
            "Min loss 856.15\n",
            "====> Epoch: 40 Average train loss: 845.8761\n",
            "====> Epoch: 40 Average val loss: 855.6805\n",
            "Min loss 855.68\n",
            "====> Epoch: 41 Average train loss: 844.9324\n",
            "====> Epoch: 41 Average val loss: 854.3186\n",
            "Min loss 854.32\n",
            "====> Epoch: 42 Average train loss: 843.8995\n",
            "====> Epoch: 42 Average val loss: 853.3363\n",
            "Min loss 853.34\n",
            "====> Epoch: 43 Average train loss: 842.4107\n",
            "====> Epoch: 43 Average val loss: 852.8639\n",
            "Min loss 852.86\n",
            "====> Epoch: 44 Average train loss: 841.9940\n",
            "====> Epoch: 44 Average val loss: 850.9692\n",
            "Min loss 850.97\n",
            "====> Epoch: 45 Average train loss: 840.0720\n",
            "====> Epoch: 45 Average val loss: 849.9398\n",
            "Min loss 849.94\n",
            "====> Epoch: 46 Average train loss: 838.8698\n",
            "====> Epoch: 46 Average val loss: 848.2423\n",
            "Min loss 848.24\n",
            "====> Epoch: 47 Average train loss: 837.8816\n",
            "====> Epoch: 47 Average val loss: 847.1721\n",
            "Min loss 847.17\n",
            "====> Epoch: 48 Average train loss: 836.4010\n",
            "====> Epoch: 48 Average val loss: 845.8672\n",
            "Min loss 845.87\n",
            "====> Epoch: 49 Average train loss: 835.3984\n",
            "====> Epoch: 49 Average val loss: 843.9441\n",
            "Min loss 843.94\n",
            "====> Epoch: 50 Average train loss: 833.1704\n",
            "====> Epoch: 50 Average val loss: 843.0504\n",
            "Min loss 843.05\n",
            "====> Epoch: 51 Average train loss: 832.0181\n",
            "====> Epoch: 51 Average val loss: 841.8303\n",
            "Min loss 841.83\n",
            "====> Epoch: 52 Average train loss: 830.9984\n",
            "====> Epoch: 52 Average val loss: 840.4135\n",
            "Min loss 840.41\n",
            "====> Epoch: 53 Average train loss: 828.7383\n",
            "====> Epoch: 53 Average val loss: 839.7471\n",
            "Min loss 839.75\n",
            "====> Epoch: 54 Average train loss: 827.4451\n",
            "====> Epoch: 54 Average val loss: 837.6609\n",
            "Min loss 837.66\n",
            "====> Epoch: 55 Average train loss: 825.8110\n",
            "====> Epoch: 55 Average val loss: 835.8055\n",
            "Min loss 835.81\n",
            "====> Epoch: 56 Average train loss: 824.1760\n",
            "====> Epoch: 56 Average val loss: 834.6777\n",
            "Min loss 834.68\n",
            "====> Epoch: 57 Average train loss: 822.9042\n",
            "====> Epoch: 57 Average val loss: 833.2518\n",
            "Min loss 833.25\n",
            "====> Epoch: 58 Average train loss: 821.9508\n",
            "====> Epoch: 58 Average val loss: 831.9279\n",
            "Min loss 831.93\n",
            "====> Epoch: 59 Average train loss: 820.6349\n",
            "====> Epoch: 59 Average val loss: 830.8829\n",
            "Min loss 830.88\n",
            "====> Epoch: 60 Average train loss: 819.6894\n",
            "====> Epoch: 60 Average val loss: 829.2461\n",
            "Min loss 829.25\n",
            "====> Epoch: 61 Average train loss: 818.3065\n",
            "====> Epoch: 61 Average val loss: 829.3905\n",
            "====> Epoch: 62 Average train loss: 817.2207\n",
            "====> Epoch: 62 Average val loss: 828.2091\n",
            "Min loss 828.21\n",
            "====> Epoch: 63 Average train loss: 816.9740\n",
            "====> Epoch: 63 Average val loss: 828.0496\n",
            "Min loss 828.05\n",
            "====> Epoch: 64 Average train loss: 815.9265\n",
            "====> Epoch: 64 Average val loss: 827.1087\n",
            "Min loss 827.11\n",
            "====> Epoch: 65 Average train loss: 815.2938\n",
            "====> Epoch: 65 Average val loss: 826.8368\n",
            "Min loss 826.84\n",
            "====> Epoch: 66 Average train loss: 814.5537\n",
            "====> Epoch: 66 Average val loss: 826.0773\n",
            "Min loss 826.08\n",
            "====> Epoch: 67 Average train loss: 814.4021\n",
            "====> Epoch: 67 Average val loss: 826.1977\n",
            "====> Epoch: 68 Average train loss: 813.5201\n",
            "====> Epoch: 68 Average val loss: 825.9578\n",
            "Min loss 825.96\n",
            "====> Epoch: 69 Average train loss: 812.6511\n",
            "====> Epoch: 69 Average val loss: 824.9127\n",
            "Min loss 824.91\n",
            "====> Epoch: 70 Average train loss: 812.1594\n",
            "====> Epoch: 70 Average val loss: 824.8807\n",
            "Min loss 824.88\n",
            "====> Epoch: 71 Average train loss: 811.7045\n",
            "====> Epoch: 71 Average val loss: 824.4716\n",
            "Min loss 824.47\n",
            "====> Epoch: 72 Average train loss: 811.3107\n",
            "====> Epoch: 72 Average val loss: 823.7205\n",
            "Min loss 823.72\n",
            "====> Epoch: 73 Average train loss: 810.6977\n",
            "====> Epoch: 73 Average val loss: 823.9029\n",
            "====> Epoch: 74 Average train loss: 810.5751\n",
            "====> Epoch: 74 Average val loss: 823.6968\n",
            "Min loss 823.70\n",
            "====> Epoch: 75 Average train loss: 809.6754\n",
            "====> Epoch: 75 Average val loss: 823.2783\n",
            "Min loss 823.28\n",
            "====> Epoch: 76 Average train loss: 809.3894\n",
            "====> Epoch: 76 Average val loss: 822.5369\n",
            "Min loss 822.54\n",
            "====> Epoch: 77 Average train loss: 808.7322\n",
            "====> Epoch: 77 Average val loss: 822.2507\n",
            "Min loss 822.25\n",
            "====> Epoch: 78 Average train loss: 808.3715\n",
            "====> Epoch: 78 Average val loss: 822.2974\n",
            "====> Epoch: 79 Average train loss: 807.5774\n",
            "====> Epoch: 79 Average val loss: 821.8263\n",
            "Min loss 821.83\n",
            "====> Epoch: 80 Average train loss: 806.9267\n",
            "====> Epoch: 80 Average val loss: 821.5750\n",
            "Min loss 821.57\n",
            "====> Epoch: 81 Average train loss: 806.4165\n",
            "====> Epoch: 81 Average val loss: 821.1604\n",
            "Min loss 821.16\n",
            "====> Epoch: 82 Average train loss: 805.7778\n",
            "====> Epoch: 82 Average val loss: 820.9918\n",
            "Min loss 820.99\n",
            "====> Epoch: 83 Average train loss: 805.1969\n",
            "====> Epoch: 83 Average val loss: 820.7137\n",
            "Min loss 820.71\n",
            "====> Epoch: 84 Average train loss: 805.0457\n",
            "====> Epoch: 84 Average val loss: 820.1023\n",
            "Min loss 820.10\n",
            "====> Epoch: 85 Average train loss: 804.2107\n",
            "====> Epoch: 85 Average val loss: 820.0529\n",
            "Min loss 820.05\n",
            "====> Epoch: 86 Average train loss: 803.6871\n",
            "====> Epoch: 86 Average val loss: 820.0054\n",
            "Min loss 820.01\n",
            "====> Epoch: 87 Average train loss: 802.9983\n",
            "====> Epoch: 87 Average val loss: 819.6976\n",
            "Min loss 819.70\n",
            "====> Epoch: 88 Average train loss: 802.3801\n",
            "====> Epoch: 88 Average val loss: 819.0109\n",
            "Min loss 819.01\n",
            "====> Epoch: 89 Average train loss: 801.7537\n",
            "====> Epoch: 89 Average val loss: 819.1711\n",
            "====> Epoch: 90 Average train loss: 801.8610\n",
            "====> Epoch: 90 Average val loss: 819.4573\n",
            "====> Epoch: 91 Average train loss: 801.3581\n",
            "====> Epoch: 91 Average val loss: 818.4967\n",
            "Min loss 818.50\n",
            "====> Epoch: 92 Average train loss: 800.5536\n",
            "====> Epoch: 92 Average val loss: 818.3872\n",
            "Min loss 818.39\n",
            "====> Epoch: 93 Average train loss: 799.8160\n",
            "====> Epoch: 93 Average val loss: 817.9228\n",
            "Min loss 817.92\n",
            "====> Epoch: 94 Average train loss: 799.2849\n",
            "====> Epoch: 94 Average val loss: 817.5948\n",
            "Min loss 817.59\n",
            "====> Epoch: 95 Average train loss: 798.8102\n",
            "====> Epoch: 95 Average val loss: 817.6761\n",
            "====> Epoch: 96 Average train loss: 798.3671\n",
            "====> Epoch: 96 Average val loss: 816.8131\n",
            "Min loss 816.81\n",
            "====> Epoch: 97 Average train loss: 798.0797\n",
            "====> Epoch: 97 Average val loss: 817.5331\n",
            "====> Epoch: 98 Average train loss: 797.5811\n",
            "====> Epoch: 98 Average val loss: 816.8146\n",
            "====> Epoch: 99 Average train loss: 796.4487\n",
            "====> Epoch: 99 Average val loss: 816.0919\n",
            "Min loss 816.09\n",
            "====> Epoch: 100 Average train loss: 795.9072\n",
            "====> Epoch: 100 Average val loss: 817.0696\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/cca_zoo/plot_utils.py:269: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  plt.figure()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "total parameters:  1216568\n",
            "====> Epoch: 1 Average train loss: 1101.5437\n",
            "====> Epoch: 1 Average val loss: 1078.9376\n",
            "Min loss 1078.94\n",
            "====> Epoch: 2 Average train loss: 1079.0117\n",
            "====> Epoch: 2 Average val loss: 1059.9119\n",
            "Min loss 1059.91\n",
            "====> Epoch: 3 Average train loss: 1060.0469\n",
            "====> Epoch: 3 Average val loss: 1032.5344\n",
            "Min loss 1032.53\n",
            "====> Epoch: 4 Average train loss: 1033.2188\n",
            "====> Epoch: 4 Average val loss: 1005.0295\n",
            "Min loss 1005.03\n",
            "====> Epoch: 5 Average train loss: 1006.3236\n",
            "====> Epoch: 5 Average val loss: 980.5747\n",
            "Min loss 980.57\n",
            "====> Epoch: 6 Average train loss: 981.8994\n",
            "====> Epoch: 6 Average val loss: 957.4884\n",
            "Min loss 957.49\n",
            "====> Epoch: 7 Average train loss: 958.9430\n",
            "====> Epoch: 7 Average val loss: 938.8829\n",
            "Min loss 938.88\n",
            "====> Epoch: 8 Average train loss: 940.0383\n",
            "====> Epoch: 8 Average val loss: 924.3047\n",
            "Min loss 924.30\n",
            "====> Epoch: 9 Average train loss: 925.4579\n",
            "====> Epoch: 9 Average val loss: 912.7220\n",
            "Min loss 912.72\n",
            "====> Epoch: 10 Average train loss: 913.4520\n",
            "====> Epoch: 10 Average val loss: 904.7958\n",
            "Min loss 904.80\n",
            "====> Epoch: 11 Average train loss: 905.3921\n",
            "====> Epoch: 11 Average val loss: 897.5015\n",
            "Min loss 897.50\n",
            "====> Epoch: 12 Average train loss: 898.6812\n",
            "====> Epoch: 12 Average val loss: 891.9644\n",
            "Min loss 891.96\n",
            "====> Epoch: 13 Average train loss: 892.5563\n",
            "====> Epoch: 13 Average val loss: 887.7097\n",
            "Min loss 887.71\n",
            "====> Epoch: 14 Average train loss: 888.2715\n",
            "====> Epoch: 14 Average val loss: 883.5336\n",
            "Min loss 883.53\n",
            "====> Epoch: 15 Average train loss: 884.6600\n",
            "====> Epoch: 15 Average val loss: 880.1432\n",
            "Min loss 880.14\n",
            "====> Epoch: 16 Average train loss: 880.4580\n",
            "====> Epoch: 16 Average val loss: 877.0476\n",
            "Min loss 877.05\n",
            "====> Epoch: 17 Average train loss: 877.6000\n",
            "====> Epoch: 17 Average val loss: 874.0562\n",
            "Min loss 874.06\n",
            "====> Epoch: 18 Average train loss: 874.3053\n",
            "====> Epoch: 18 Average val loss: 870.2654\n",
            "Min loss 870.27\n",
            "====> Epoch: 19 Average train loss: 871.0529\n",
            "====> Epoch: 19 Average val loss: 867.7842\n",
            "Min loss 867.78\n",
            "====> Epoch: 20 Average train loss: 868.6168\n",
            "====> Epoch: 20 Average val loss: 863.8961\n",
            "Min loss 863.90\n",
            "====> Epoch: 21 Average train loss: 865.5399\n",
            "====> Epoch: 21 Average val loss: 861.3399\n",
            "Min loss 861.34\n",
            "====> Epoch: 22 Average train loss: 862.2131\n",
            "====> Epoch: 22 Average val loss: 858.0124\n",
            "Min loss 858.01\n",
            "====> Epoch: 23 Average train loss: 859.6262\n",
            "====> Epoch: 23 Average val loss: 854.7637\n",
            "Min loss 854.76\n",
            "====> Epoch: 24 Average train loss: 856.6960\n",
            "====> Epoch: 24 Average val loss: 852.1873\n",
            "Min loss 852.19\n",
            "====> Epoch: 25 Average train loss: 854.3376\n",
            "====> Epoch: 25 Average val loss: 849.2151\n",
            "Min loss 849.22\n",
            "====> Epoch: 26 Average train loss: 851.2086\n",
            "====> Epoch: 26 Average val loss: 846.7124\n",
            "Min loss 846.71\n",
            "====> Epoch: 27 Average train loss: 848.1539\n",
            "====> Epoch: 27 Average val loss: 843.5990\n",
            "Min loss 843.60\n",
            "====> Epoch: 28 Average train loss: 846.0233\n",
            "====> Epoch: 28 Average val loss: 840.3903\n",
            "Min loss 840.39\n",
            "====> Epoch: 29 Average train loss: 842.5249\n",
            "====> Epoch: 29 Average val loss: 837.4920\n",
            "Min loss 837.49\n",
            "====> Epoch: 30 Average train loss: 840.2001\n",
            "====> Epoch: 30 Average val loss: 835.2992\n",
            "Min loss 835.30\n",
            "====> Epoch: 31 Average train loss: 837.8695\n",
            "====> Epoch: 31 Average val loss: 832.8057\n",
            "Min loss 832.81\n",
            "====> Epoch: 32 Average train loss: 835.2482\n",
            "====> Epoch: 32 Average val loss: 829.8863\n",
            "Min loss 829.89\n",
            "====> Epoch: 33 Average train loss: 832.7184\n",
            "====> Epoch: 33 Average val loss: 826.7136\n",
            "Min loss 826.71\n",
            "====> Epoch: 34 Average train loss: 830.2648\n",
            "====> Epoch: 34 Average val loss: 825.3696\n",
            "Min loss 825.37\n",
            "====> Epoch: 35 Average train loss: 827.4452\n",
            "====> Epoch: 35 Average val loss: 822.0627\n",
            "Min loss 822.06\n",
            "====> Epoch: 36 Average train loss: 825.1614\n",
            "====> Epoch: 36 Average val loss: 820.5272\n",
            "Min loss 820.53\n",
            "====> Epoch: 37 Average train loss: 823.2919\n",
            "====> Epoch: 37 Average val loss: 818.3214\n",
            "Min loss 818.32\n",
            "====> Epoch: 38 Average train loss: 820.6432\n",
            "====> Epoch: 38 Average val loss: 815.6862\n",
            "Min loss 815.69\n",
            "====> Epoch: 39 Average train loss: 818.7913\n",
            "====> Epoch: 39 Average val loss: 814.3401\n",
            "Min loss 814.34\n",
            "====> Epoch: 40 Average train loss: 816.6571\n",
            "====> Epoch: 40 Average val loss: 812.3160\n",
            "Min loss 812.32\n",
            "====> Epoch: 41 Average train loss: 814.3795\n",
            "====> Epoch: 41 Average val loss: 810.6839\n",
            "Min loss 810.68\n",
            "====> Epoch: 42 Average train loss: 812.5831\n",
            "====> Epoch: 42 Average val loss: 809.1890\n",
            "Min loss 809.19\n",
            "====> Epoch: 43 Average train loss: 811.5714\n",
            "====> Epoch: 43 Average val loss: 807.7136\n",
            "Min loss 807.71\n",
            "====> Epoch: 44 Average train loss: 809.5469\n",
            "====> Epoch: 44 Average val loss: 806.4915\n",
            "Min loss 806.49\n",
            "====> Epoch: 45 Average train loss: 807.6951\n",
            "====> Epoch: 45 Average val loss: 804.4565\n",
            "Min loss 804.46\n",
            "====> Epoch: 46 Average train loss: 805.7507\n",
            "====> Epoch: 46 Average val loss: 803.1402\n",
            "Min loss 803.14\n",
            "====> Epoch: 47 Average train loss: 804.8042\n",
            "====> Epoch: 47 Average val loss: 801.3516\n",
            "Min loss 801.35\n",
            "====> Epoch: 48 Average train loss: 802.4633\n",
            "====> Epoch: 48 Average val loss: 799.6667\n",
            "Min loss 799.67\n",
            "====> Epoch: 49 Average train loss: 800.9117\n",
            "====> Epoch: 49 Average val loss: 798.6351\n",
            "Min loss 798.64\n",
            "====> Epoch: 50 Average train loss: 798.9125\n",
            "====> Epoch: 50 Average val loss: 797.1915\n",
            "Min loss 797.19\n",
            "====> Epoch: 51 Average train loss: 798.1412\n",
            "====> Epoch: 51 Average val loss: 795.4808\n",
            "Min loss 795.48\n",
            "====> Epoch: 52 Average train loss: 796.1000\n",
            "====> Epoch: 52 Average val loss: 794.4877\n",
            "Min loss 794.49\n",
            "====> Epoch: 53 Average train loss: 794.2858\n",
            "====> Epoch: 53 Average val loss: 793.2549\n",
            "Min loss 793.25\n",
            "====> Epoch: 54 Average train loss: 793.3073\n",
            "====> Epoch: 54 Average val loss: 791.2468\n",
            "Min loss 791.25\n",
            "====> Epoch: 55 Average train loss: 791.3342\n",
            "====> Epoch: 55 Average val loss: 789.2021\n",
            "Min loss 789.20\n",
            "====> Epoch: 56 Average train loss: 789.6517\n",
            "====> Epoch: 56 Average val loss: 788.1926\n",
            "Min loss 788.19\n",
            "====> Epoch: 57 Average train loss: 788.1786\n",
            "====> Epoch: 57 Average val loss: 787.1311\n",
            "Min loss 787.13\n",
            "====> Epoch: 58 Average train loss: 787.0040\n",
            "====> Epoch: 58 Average val loss: 786.0242\n",
            "Min loss 786.02\n",
            "====> Epoch: 59 Average train loss: 785.1951\n",
            "====> Epoch: 59 Average val loss: 784.3719\n",
            "Min loss 784.37\n",
            "====> Epoch: 60 Average train loss: 784.1566\n",
            "====> Epoch: 60 Average val loss: 783.3922\n",
            "Min loss 783.39\n",
            "====> Epoch: 61 Average train loss: 782.4001\n",
            "====> Epoch: 61 Average val loss: 782.0692\n",
            "Min loss 782.07\n",
            "====> Epoch: 62 Average train loss: 780.6804\n",
            "====> Epoch: 62 Average val loss: 781.1741\n",
            "Min loss 781.17\n",
            "====> Epoch: 63 Average train loss: 779.1801\n",
            "====> Epoch: 63 Average val loss: 780.0179\n",
            "Min loss 780.02\n",
            "====> Epoch: 64 Average train loss: 777.8265\n",
            "====> Epoch: 64 Average val loss: 779.2645\n",
            "Min loss 779.26\n",
            "====> Epoch: 65 Average train loss: 776.7187\n",
            "====> Epoch: 65 Average val loss: 777.9249\n",
            "Min loss 777.92\n",
            "====> Epoch: 66 Average train loss: 775.1638\n",
            "====> Epoch: 66 Average val loss: 776.4296\n",
            "Min loss 776.43\n",
            "====> Epoch: 67 Average train loss: 774.2640\n",
            "====> Epoch: 67 Average val loss: 775.5254\n",
            "Min loss 775.53\n",
            "====> Epoch: 68 Average train loss: 772.8149\n",
            "====> Epoch: 68 Average val loss: 775.5750\n",
            "====> Epoch: 69 Average train loss: 771.6942\n",
            "====> Epoch: 69 Average val loss: 774.1823\n",
            "Min loss 774.18\n",
            "====> Epoch: 70 Average train loss: 770.8462\n",
            "====> Epoch: 70 Average val loss: 773.4898\n",
            "Min loss 773.49\n",
            "====> Epoch: 71 Average train loss: 770.8782\n",
            "====> Epoch: 71 Average val loss: 774.2773\n",
            "====> Epoch: 72 Average train loss: 769.2637\n",
            "====> Epoch: 72 Average val loss: 771.3470\n",
            "Min loss 771.35\n",
            "====> Epoch: 73 Average train loss: 768.1167\n",
            "====> Epoch: 73 Average val loss: 770.1075\n",
            "Min loss 770.11\n",
            "====> Epoch: 74 Average train loss: 766.7063\n",
            "====> Epoch: 74 Average val loss: 770.6257\n",
            "====> Epoch: 75 Average train loss: 766.3339\n",
            "====> Epoch: 75 Average val loss: 769.6714\n",
            "Min loss 769.67\n",
            "====> Epoch: 76 Average train loss: 765.1084\n",
            "====> Epoch: 76 Average val loss: 768.7143\n",
            "Min loss 768.71\n",
            "====> Epoch: 77 Average train loss: 764.1517\n",
            "====> Epoch: 77 Average val loss: 767.4626\n",
            "Min loss 767.46\n",
            "====> Epoch: 78 Average train loss: 763.5276\n",
            "====> Epoch: 78 Average val loss: 767.1146\n",
            "Min loss 767.11\n",
            "====> Epoch: 79 Average train loss: 762.2251\n",
            "====> Epoch: 79 Average val loss: 767.2295\n",
            "====> Epoch: 80 Average train loss: 761.6892\n",
            "====> Epoch: 80 Average val loss: 766.5709\n",
            "Min loss 766.57\n",
            "====> Epoch: 81 Average train loss: 760.9293\n",
            "====> Epoch: 81 Average val loss: 765.1732\n",
            "Min loss 765.17\n",
            "====> Epoch: 82 Average train loss: 760.2159\n",
            "====> Epoch: 82 Average val loss: 764.9403\n",
            "Min loss 764.94\n",
            "====> Epoch: 83 Average train loss: 759.5743\n",
            "====> Epoch: 83 Average val loss: 765.0089\n",
            "====> Epoch: 84 Average train loss: 758.6124\n",
            "====> Epoch: 84 Average val loss: 764.9298\n",
            "Min loss 764.93\n",
            "====> Epoch: 85 Average train loss: 758.7284\n",
            "====> Epoch: 85 Average val loss: 766.1570\n",
            "====> Epoch: 86 Average train loss: 758.8693\n",
            "====> Epoch: 86 Average val loss: 765.5479\n",
            "====> Epoch: 87 Average train loss: 759.4586\n",
            "====> Epoch: 87 Average val loss: 764.8845\n",
            "Min loss 764.88\n",
            "====> Epoch: 88 Average train loss: 757.4208\n",
            "====> Epoch: 88 Average val loss: 762.3715\n",
            "Min loss 762.37\n",
            "====> Epoch: 89 Average train loss: 755.5154\n",
            "====> Epoch: 89 Average val loss: 762.6442\n",
            "====> Epoch: 90 Average train loss: 755.6855\n",
            "====> Epoch: 90 Average val loss: 763.1947\n",
            "====> Epoch: 91 Average train loss: 755.5786\n",
            "====> Epoch: 91 Average val loss: 762.0341\n",
            "Min loss 762.03\n",
            "====> Epoch: 92 Average train loss: 754.1638\n",
            "====> Epoch: 92 Average val loss: 761.6863\n",
            "Min loss 761.69\n",
            "====> Epoch: 93 Average train loss: 753.6308\n",
            "====> Epoch: 93 Average val loss: 762.0930\n",
            "====> Epoch: 94 Average train loss: 753.7233\n",
            "====> Epoch: 94 Average val loss: 760.3320\n",
            "Min loss 760.33\n",
            "====> Epoch: 95 Average train loss: 752.9584\n",
            "====> Epoch: 95 Average val loss: 759.2847\n",
            "Min loss 759.28\n",
            "====> Epoch: 96 Average train loss: 751.8971\n",
            "====> Epoch: 96 Average val loss: 760.2527\n",
            "====> Epoch: 97 Average train loss: 752.4484\n",
            "====> Epoch: 97 Average val loss: 759.8309\n",
            "====> Epoch: 98 Average train loss: 751.7109\n",
            "====> Epoch: 98 Average val loss: 759.1096\n",
            "Min loss 759.11\n",
            "====> Epoch: 99 Average train loss: 749.7936\n",
            "====> Epoch: 99 Average val loss: 759.7253\n",
            "====> Epoch: 100 Average train loss: 750.2084\n",
            "====> Epoch: 100 Average val loss: 758.5455\n",
            "Min loss 758.55\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/cca_zoo/plot_utils.py:269: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  plt.figure()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhYAL8vxkiAh"
      },
      "source": [
        "# Generate Some Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jNeUaqjwhcj7",
        "outputId": "942512b3-b9a2-4320-ffe8-0206347bc863"
      },
      "source": [
        "\"\"\"\r\n",
        "### Make results plot to compare methods\r\n",
        "\"\"\"\r\n",
        "# %%\r\n",
        "\r\n",
        "all_results = np.stack(\r\n",
        "    [linear_cca_results, scikit_cca_results, gcca_results, mcca_results, pls_results, scca_results, pmd_results,\r\n",
        "     elastic_results,\r\n",
        "     kernel_reg_results,\r\n",
        "     kernel_poly_results,\r\n",
        "     kernel_gaussian_results, dcca_results, dgcca_results,dmcca_results, dcca_conv_results,dvcca_results,dvcca_p_results],\r\n",
        "    axis=0)\r\n",
        "all_labels = ['linear', 'scikit', 'gcca', 'mcca', 'pls', 'pmd', 'elastic', 'scca', 'linear kernel', 'polynomial kernel',\r\n",
        "              'gaussian kernel', 'deep CCA', 'deep generalized CCA','deep multiset CCA', 'deep convolutional cca',\r\n",
        "              'deep variational CCA','deep variational CCA (private)']\r\n",
        "\r\n",
        "from cca_zoo import plot_utils\r\n",
        "plot_utils.plot_results(all_results, all_labels)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/cca_zoo/plot_utils.py:108: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig, ax = plt.subplots()\n",
            "/usr/local/lib/python3.6/dist-packages/cca_zoo/plot_utils.py:126: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  plt.figure()\n",
            "/usr/local/lib/python3.6/dist-packages/cca_zoo/plot_utils.py:141: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  plt.figure()\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}