{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cca-zoo-tutorial.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO/+24u4XZeuDIsjycK+rwG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jameschapman19/cca_zoo/blob/master/cca_zoo_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFVm_oT3cmZH",
        "outputId": "8eee0141-f4b4-4cda-b007-5b5b563aa981"
      },
      "source": [
        "!pip install cca-zoo --upgrade"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: cca-zoo in /usr/local/lib/python3.6/dist-packages (1.1.9)\n",
            "Requirement already satisfied, skipping upgrade: seaborn in /usr/local/lib/python3.6/dist-packages (from cca-zoo) (0.11.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from cca-zoo) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.6/dist-packages (from cca-zoo) (1.7.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: mvlearn in /usr/local/lib/python3.6/dist-packages (from cca-zoo) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: torchvision in /usr/local/lib/python3.6/dist-packages (from cca-zoo) (0.8.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from cca-zoo) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from cca-zoo) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from cca-zoo) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from cca-zoo) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: Pillow in /usr/local/lib/python3.6/dist-packages (from cca-zoo) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cca-zoo) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cca-zoo) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cca-zoo) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cca-zoo) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->cca-zoo) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->cca-zoo) (0.8)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch->cca-zoo) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from mvlearn->cca-zoo) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->cca-zoo) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->cca-zoo) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKgX47gILXS-"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFsRNCJ0crH8"
      },
      "source": [
        "# Imports\r\n",
        "import numpy as np\r\n",
        "from cca_zoo import wrappers\r\n",
        "from cca_zoo import data\r\n",
        "import itertools\r\n",
        "import os\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from torch.utils.data import Subset\r\n",
        "\r\n",
        "# Load MNIST Data\r\n",
        "os.chdir('..')\r\n",
        "N = 1000\r\n",
        "dataset = data.Noisy_MNIST_Dataset(mnist_type='FashionMNIST', train=True)\r\n",
        "ids = np.arange(min(2 * N, len(dataset)))\r\n",
        "np.random.shuffle(ids)\r\n",
        "train_ids, val_ids = np.array_split(ids, 2)\r\n",
        "val_dataset = Subset(dataset, val_ids)\r\n",
        "train_dataset = Subset(dataset, train_ids)\r\n",
        "test_dataset = data.Noisy_MNIST_Dataset(mnist_type='FashionMNIST', train=False)\r\n",
        "test_ids = np.arange(min(N, len(test_dataset)))\r\n",
        "np.random.shuffle(test_ids)\r\n",
        "test_dataset = Subset(test_dataset, test_ids)\r\n",
        "train_view_1, train_view_2, train_rotations, train_OH_labels, train_labels = train_dataset.dataset.to_numpy(\r\n",
        "    train_dataset.indices)\r\n",
        "val_view_1, val_view_2, val_rotations, val_OH_labels, val_labels = val_dataset.dataset.to_numpy(val_dataset.indices)\r\n",
        "test_view_1, test_view_2, test_rotations, test_OH_labels, test_labels = test_dataset.dataset.to_numpy(\r\n",
        "    test_dataset.indices)\r\n",
        "\r\n",
        "# Settings\r\n",
        "\r\n",
        "# The number of latent dimensions across models\r\n",
        "latent_dims = 2\r\n",
        "# The number of folds used for cross-validation/hyperparameter tuning\r\n",
        "cv_folds = 5\r\n",
        "# For running hyperparameter tuning in parallel (0 if not)\r\n",
        "jobs = 2\r\n",
        "# Number of iterations for iterative algorithms\r\n",
        "max_iter = 10\r\n",
        "# number of epochs for deep models\r\n",
        "epochs = 50"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOryUM6ShmQf"
      },
      "source": [
        "# Canonical Correlation Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSGgSD7vgh1b"
      },
      "source": [
        "\"\"\"\r\n",
        "### Linear CCA via alternating least squares (can pass more than 2 views)\r\n",
        "\"\"\"\r\n",
        "linear_cca = wrappers.CCA(latent_dims=latent_dims, max_iter=max_iter)\r\n",
        "\r\n",
        "linear_cca.fit(train_view_1, train_view_2)\r\n",
        "\r\n",
        "linear_cca_results = np.stack(\r\n",
        "    (linear_cca.train_correlations[0, 1], linear_cca.predict_corr(test_view_1, test_view_2)[0, 1]))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZtZUfZ3huKE"
      },
      "source": [
        "# Partial Least Squares\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei3rASx3ghtJ"
      },
      "source": [
        "\"\"\"\r\n",
        "### PLS with scikit-learn (only permits 2 views)\r\n",
        "\"\"\"\r\n",
        "pls = wrappers.PLS(latent_dims=latent_dims)\r\n",
        "\r\n",
        "pls.fit(train_view_1, train_view_2)\r\n",
        "\r\n",
        "pls_results = np.stack(\r\n",
        "    (pls.train_correlations[0, 1], pls.predict_corr(test_view_1, test_view_2)[0, 1]))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88vAaUxIi1H7"
      },
      "source": [
        "# Extension to multiple views\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Fx0dj8GghbD"
      },
      "source": [
        "\"\"\"\r\n",
        "### (Regularized) Generalized CCA(can pass more than 2 views)\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "gcca = wrappers.GCCA(latent_dims=latent_dims)\r\n",
        "\r\n",
        "# small ammount of regularisation added since data is not full rank\r\n",
        "c=[0.5,0.5,0.5]\r\n",
        "\r\n",
        "gcca.fit(train_view_1, train_view_2,train_view_1, c=c)\r\n",
        "\r\n",
        "gcca_results = np.stack((gcca.train_correlations[0, 1], gcca.predict_corr(test_view_1, test_view_2)[0, 1]))\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "### (Regularized) Multiset CCA(can pass more than 2 views)\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "mcca = wrappers.MCCA(latent_dims=latent_dims)\r\n",
        "\r\n",
        "mcca.fit(train_view_1, train_view_2,train_view_1, c=c)\r\n",
        "\r\n",
        "mcca_results = np.stack((mcca.train_correlations[0, 1], mcca.predict_corr(test_view_1, test_view_2)[0, 1]))\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "### Multiset CCA by alternating least squares\r\n",
        "\"\"\"\r\n",
        "mcca_als = wrappers.CCA(latent_dims=latent_dims, max_iter=max_iter)\r\n",
        "\r\n",
        "mcca_als.fit(train_view_1, train_view_2,train_view_1)\r\n",
        "\r\n",
        "mcca_als_results = np.stack(\r\n",
        "    (mcca_als.train_correlations[0, 1], mcca_als.predict_corr(test_view_1, test_view_2)[0, 1]))\r\n",
        "\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "### Multiset PLS by alternating least squares\r\n",
        "\"\"\"\r\n",
        "mcca_pls = wrappers.PLS(latent_dims=latent_dims, max_iter=max_iter)\r\n",
        "\r\n",
        "mcca_pls.fit(train_view_1, train_view_2,train_view_1)\r\n",
        "\r\n",
        "mcca_pls_results = np.stack(\r\n",
        "    (mcca_als.train_correlations[0, 1], mcca_pls.predict_corr(test_view_1, test_view_2)[0, 1]))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9847WJ3liT6v"
      },
      "source": [
        "# Rgularised CCA solutions based on alternating minimisation/alternating least squares\r\n",
        "\r\n",
        "We implement Witten's penalized matrix decomposition form of sparse CCA using 'pmd'\r\n",
        "\r\n",
        "We implement Waaijenborg's penalized CCA using elastic net using 'elastic'\r\n",
        "\r\n",
        "We implement Mai's sparse CCA using 'scca'\r\n",
        "\r\n",
        "Furthermore, any of these methods can be extended to multiple views. Witten describes this method explicitly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts_yQvzdhDQe",
        "outputId": "1f94a1aa-ba5d-43e1-e0bd-525a85bc7818"
      },
      "source": [
        "\"\"\"\r\n",
        "### Sparse CCA (Penalized Matrix Decomposition) (can pass more than 2 views)\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "# PMD\r\n",
        "c1 = [1, 3, 7, 9]\r\n",
        "c2 = [1, 3, 7, 9]\r\n",
        "param_candidates = {'c': list(itertools.product(c1, c2))}\r\n",
        "\r\n",
        "pmd = wrappers.PMD(latent_dims=latent_dims, tol=1e-5, max_iter=max_iter).gridsearch_fit(\r\n",
        "    train_view_1,\r\n",
        "    train_view_2,\r\n",
        "    param_candidates=param_candidates,\r\n",
        "    folds=cv_folds,\r\n",
        "    verbose=True, jobs=jobs,\r\n",
        "    plot=True)\r\n",
        "\r\n",
        "pmd_results = np.stack((pmd.train_correlations[0, 1, :], pmd.predict_corr(test_view_1, test_view_2)[0, 1, :]))\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "### Sparse CCA (can pass more than 2 views)\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "# Sparse CCA\r\n",
        "c1 = [0.00001, 0.0001]\r\n",
        "c2 = [0.00001, 0.0001]\r\n",
        "param_candidates = {'c': list(itertools.product(c1, c2))}\r\n",
        "\r\n",
        "scca = wrappers.SCCA(latent_dims=latent_dims, tol=1e-5, max_iter=max_iter).gridsearch_fit(\r\n",
        "    train_view_1,\r\n",
        "    train_view_2,\r\n",
        "    param_candidates=param_candidates,\r\n",
        "    folds=cv_folds,\r\n",
        "    verbose=True,\r\n",
        "    jobs=jobs, plot=True)\r\n",
        "\r\n",
        "scca_results = np.stack(\r\n",
        "    (scca.train_correlations[0, 1, :], scca.predict_corr(test_view_1, test_view_2)[0, 1, :]))\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "# Sparse CCA with ADMM\r\n",
        "c1 = [0.00001, 0.0001]\r\n",
        "c2 = [0.00001, 0.0001]\r\n",
        "param_candidates = {'c': list(itertools.product(c1, c2))}\r\n",
        "\r\n",
        "scca_admm = wrappers.SCCA_ADMM(latent_dims=latent_dims, tol=1e-5, max_iter=max_iter).gridsearch_fit(\r\n",
        "    train_view_1,\r\n",
        "    train_view_2,\r\n",
        "    param_candidates=param_candidates,\r\n",
        "    folds=cv_folds,\r\n",
        "    verbose=True,\r\n",
        "    jobs=jobs, plot=True)\r\n",
        "\r\n",
        "scca_admm_results = np.stack(\r\n",
        "    (scca_admm.train_correlations[0, 1, :], scca_admm.predict_corr(test_view_1, test_view_2)[0, 1, :]))\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "### Elastic CCA (can pass more than 2 views)\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "# Elastic CCA\r\n",
        "c1 = [0.001, 0.0001]\r\n",
        "c2 = [0.001, 0.0001]\r\n",
        "l1_1 = [0.01, 0.1]\r\n",
        "l1_2 = [0.01, 0.1]\r\n",
        "param_candidates = {'c': list(itertools.product(c1, c2)), 'l1_ratio': list(itertools.product(l1_1, l1_2))}\r\n",
        "\r\n",
        "elastic = wrappers.ElasticCCA(latent_dims=latent_dims, tol=1e-5,\r\n",
        "                              max_iter=max_iter).gridsearch_fit(train_view_1,\r\n",
        "                                                                train_view_2,\r\n",
        "                                                                param_candidates=param_candidates,\r\n",
        "                                                                folds=cv_folds,\r\n",
        "                                                                verbose=True,\r\n",
        "                                                                jobs=jobs,\r\n",
        "                                                                plot=True)\r\n",
        "\r\n",
        "elastic_results = np.stack(\r\n",
        "    (elastic.train_correlations[0, 1, :], elastic.predict_corr(test_view_1, test_view_2)[0, 1, :]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cross validation\n",
            "number of folds:  5\n",
            "Best score :  1.229268604951622\n",
            "{'c': (9, 9)}\n",
            "cross validation\n",
            "number of folds:  5\n",
            "Best score :  1.276732458714244\n",
            "{'c': (0.0001, 0.0001)}\n",
            "cross validation\n",
            "number of folds:  5\n",
            "Best score :  0.12498643511537114\n",
            "{'c': (0.0001, 0.0001), 'l1_ratio': (0.01, 0.1)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaHqF5CljrCb"
      },
      "source": [
        "# Kernel CCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtH38KO8hLFL",
        "outputId": "bf6b5b67-d94a-4024-a107-84a6c66bed8a"
      },
      "source": [
        "\"\"\"\r\n",
        "### Kernel CCA\r\n",
        "\r\n",
        "Similarly, we can use kernel CCA methods with [method='kernel']\r\n",
        "\r\n",
        "We can use different kernels and their associated parameters in a similar manner to before\r\n",
        "- regularized linear kernel CCA: parameters :  'kernel'='linear', 0<'c'<1\r\n",
        "- polynomial kernel CCA: parameters : 'kernel'='poly', 'degree', 0<'c'<1\r\n",
        "- gaussian rbf kernel CCA: parameters : 'kernel'='gaussian', 'sigma', 0<'c'<1\r\n",
        "\"\"\"\r\n",
        "# %%\r\n",
        "# r-kernel cca\r\n",
        "c1 = [0.9, 0.99]\r\n",
        "c2 = [0.9, 0.99]\r\n",
        "\r\n",
        "param_candidates = {'kernel': ['linear'], 'c': list(itertools.product(c1, c2))}\r\n",
        "\r\n",
        "kernel_reg = wrappers.KCCA(latent_dims=latent_dims).gridsearch_fit(train_view_1, train_view_2,\r\n",
        "                                                                   folds=cv_folds,\r\n",
        "                                                                   param_candidates=param_candidates,\r\n",
        "                                                                   verbose=True, jobs=jobs,\r\n",
        "                                                                   plot=True)\r\n",
        "kernel_reg_results = np.stack((\r\n",
        "    kernel_reg.train_correlations[0, 1, :],\r\n",
        "    kernel_reg.predict_corr(test_view_1, test_view_2)[0, 1, :]))\r\n",
        "\r\n",
        "# kernel cca (poly)\r\n",
        "param_candidates = {'kernel': ['poly'], 'degree': [2, 3], 'c': list(itertools.product(c1, c2))}\r\n",
        "\r\n",
        "kernel_poly = wrappers.KCCA(latent_dims=latent_dims).gridsearch_fit(train_view_1, train_view_2,\r\n",
        "                                                                    folds=cv_folds,\r\n",
        "                                                                    param_candidates=param_candidates,\r\n",
        "                                                                    verbose=True, jobs=jobs,\r\n",
        "                                                                    plot=True)\r\n",
        "\r\n",
        "kernel_poly_results = np.stack((\r\n",
        "    kernel_poly.train_correlations[0, 1, :],\r\n",
        "    kernel_poly.predict_corr(test_view_1, test_view_2)[0, 1, :]))\r\n",
        "\r\n",
        "# kernel cca (gaussian)\r\n",
        "param_candidates = {'kernel': ['rbf'], 'sigma': [1e+1, 1e+2, 1e+3], 'c': list(itertools.product(c1, c2))}\r\n",
        "\r\n",
        "kernel_gaussian = wrappers.KCCA(latent_dims=latent_dims).gridsearch_fit(train_view_1, train_view_2,\r\n",
        "                                                                        folds=cv_folds,\r\n",
        "                                                                        param_candidates=param_candidates,\r\n",
        "                                                                        verbose=True, jobs=jobs,\r\n",
        "                                                                        plot=True)\r\n",
        "\r\n",
        "kernel_gaussian_results = np.stack((\r\n",
        "    kernel_gaussian.train_correlations[0, 1, :],\r\n",
        "    kernel_gaussian.predict_corr(test_view_1, test_view_2)[0, 1, :]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cross validation\n",
            "number of folds:  5\n",
            "Best score :  1.5098116454497703\n",
            "{'kernel': 'linear', 'c': (0.99, 0.9)}\n",
            "cross validation\n",
            "number of folds:  5\n",
            "Best score :  1.0811411549353331\n",
            "{'kernel': 'poly', 'degree': 3, 'c': (0.9, 0.9)}\n",
            "cross validation\n",
            "number of folds:  5\n",
            "Best score :  1.2515382003494193\n",
            "{'kernel': 'rbf', 'sigma': 100.0, 'c': (0.99, 0.9)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44ltKrtIkICK"
      },
      "source": [
        "# Deep CCA\r\n",
        "\r\n",
        "DCCA can be optimized using Andrew's original tracenorm objective or Wang's DCCA by nonlinear orthogonal iterations using the argument als=True."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0nTlPSEhVeP",
        "outputId": "4dc04989-b58a-45d4-b64f-dd6327ac3554"
      },
      "source": [
        "\"\"\"\r\n",
        "### Deep Learning\r\n",
        "\r\n",
        "We also have deep CCA methods (and autoencoder variants)\r\n",
        "- Deep CCA (DCCA)\r\n",
        "- Deep Canonically Correlated Autoencoders (DCCAE)\r\n",
        "\r\n",
        "We introduce a Config class from configuration.py. This contains a number of default settings for running DCCA.\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "from cca_zoo import deepwrapper, objectives, dcca, deep_models\r\n",
        "\r\n",
        "# %%\r\n",
        "# DCCA\r\n",
        "print('DCCA')\r\n",
        "encoder_1 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\r\n",
        "encoder_2 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\r\n",
        "dcca_model = dcca.DCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2])\r\n",
        "\r\n",
        "dcca_model = deepwrapper.DeepWrapper(dcca_model)\r\n",
        "\r\n",
        "dcca_model.fit(train_view_1, train_view_2, epochs=epochs)\r\n",
        "\r\n",
        "dcca_results = np.stack((dcca_model.train_correlations[0, 1], dcca_model.predict_corr(test_view_1, test_view_2)[0, 1]))\r\n",
        "\r\n",
        "\r\n",
        "# DCCA_NOI\r\n",
        "# Note that als=True\r\n",
        "print('DCCA by non-linear orthogonal iterations')\r\n",
        "encoder_1 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\r\n",
        "encoder_2 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\r\n",
        "dcca_noi_model = dcca.DCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2], als=True)\r\n",
        "\r\n",
        "dcca_noi_model = deepwrapper.DeepWrapper(dcca_noi_model)\r\n",
        "\r\n",
        "dcca_noi_model.fit(train_view_1, train_view_2, epochs=epochs)\r\n",
        "\r\n",
        "dcca_noi_results = np.stack(\r\n",
        "    (dcca_noi_model.train_correlations[0, 1], dcca_noi_model.predict_corr(test_view_1, test_view_2)[0, 1]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DCCA\n",
            "total parameters:  201476\n",
            "====> Epoch: 1 Average train loss: -0.2295\n",
            "====> Epoch: 1 Average val loss: -0.7630\n",
            "Min loss -0.76\n",
            "====> Epoch: 2 Average train loss: -0.7464\n",
            "====> Epoch: 2 Average val loss: -1.0584\n",
            "Min loss -1.06\n",
            "====> Epoch: 3 Average train loss: -1.1421\n",
            "====> Epoch: 3 Average val loss: -1.1717\n",
            "Min loss -1.17\n",
            "====> Epoch: 4 Average train loss: -1.2775\n",
            "====> Epoch: 4 Average val loss: -1.2257\n",
            "Min loss -1.23\n",
            "====> Epoch: 5 Average train loss: -1.3402\n",
            "====> Epoch: 5 Average val loss: -1.2559\n",
            "Min loss -1.26\n",
            "====> Epoch: 6 Average train loss: -1.3759\n",
            "====> Epoch: 6 Average val loss: -1.2751\n",
            "Min loss -1.28\n",
            "====> Epoch: 7 Average train loss: -1.3999\n",
            "====> Epoch: 7 Average val loss: -1.2887\n",
            "Min loss -1.29\n",
            "====> Epoch: 8 Average train loss: -1.4186\n",
            "====> Epoch: 8 Average val loss: -1.2991\n",
            "Min loss -1.30\n",
            "====> Epoch: 9 Average train loss: -1.4348\n",
            "====> Epoch: 9 Average val loss: -1.3077\n",
            "Min loss -1.31\n",
            "====> Epoch: 10 Average train loss: -1.4497\n",
            "====> Epoch: 10 Average val loss: -1.3151\n",
            "Min loss -1.32\n",
            "====> Epoch: 11 Average train loss: -1.4640\n",
            "====> Epoch: 11 Average val loss: -1.3216\n",
            "Min loss -1.32\n",
            "====> Epoch: 12 Average train loss: -1.4780\n",
            "====> Epoch: 12 Average val loss: -1.3276\n",
            "Min loss -1.33\n",
            "====> Epoch: 13 Average train loss: -1.4919\n",
            "====> Epoch: 13 Average val loss: -1.3330\n",
            "Min loss -1.33\n",
            "====> Epoch: 14 Average train loss: -1.5056\n",
            "====> Epoch: 14 Average val loss: -1.3379\n",
            "Min loss -1.34\n",
            "====> Epoch: 15 Average train loss: -1.5191\n",
            "====> Epoch: 15 Average val loss: -1.3425\n",
            "Min loss -1.34\n",
            "====> Epoch: 16 Average train loss: -1.5325\n",
            "====> Epoch: 16 Average val loss: -1.3466\n",
            "Min loss -1.35\n",
            "====> Epoch: 17 Average train loss: -1.5458\n",
            "====> Epoch: 17 Average val loss: -1.3503\n",
            "Min loss -1.35\n",
            "====> Epoch: 18 Average train loss: -1.5588\n",
            "====> Epoch: 18 Average val loss: -1.3536\n",
            "Min loss -1.35\n",
            "====> Epoch: 19 Average train loss: -1.5717\n",
            "====> Epoch: 19 Average val loss: -1.3566\n",
            "Min loss -1.36\n",
            "====> Epoch: 20 Average train loss: -1.5844\n",
            "====> Epoch: 20 Average val loss: -1.3593\n",
            "Min loss -1.36\n",
            "====> Epoch: 21 Average train loss: -1.5970\n",
            "====> Epoch: 21 Average val loss: -1.3615\n",
            "Min loss -1.36\n",
            "====> Epoch: 22 Average train loss: -1.6094\n",
            "====> Epoch: 22 Average val loss: -1.3635\n",
            "Min loss -1.36\n",
            "====> Epoch: 23 Average train loss: -1.6217\n",
            "====> Epoch: 23 Average val loss: -1.3651\n",
            "Min loss -1.37\n",
            "====> Epoch: 24 Average train loss: -1.6339\n",
            "====> Epoch: 24 Average val loss: -1.3664\n",
            "Min loss -1.37\n",
            "====> Epoch: 25 Average train loss: -1.6460\n",
            "====> Epoch: 25 Average val loss: -1.3673\n",
            "Min loss -1.37\n",
            "====> Epoch: 26 Average train loss: -1.6580\n",
            "====> Epoch: 26 Average val loss: -1.3678\n",
            "Min loss -1.37\n",
            "====> Epoch: 27 Average train loss: -1.6700\n",
            "====> Epoch: 27 Average val loss: -1.3678\n",
            "====> Epoch: 28 Average train loss: -1.6818\n",
            "====> Epoch: 28 Average val loss: -1.3671\n",
            "====> Epoch: 29 Average train loss: -1.6934\n",
            "====> Epoch: 29 Average val loss: -1.3658\n",
            "====> Epoch: 30 Average train loss: -1.7047\n",
            "====> Epoch: 30 Average val loss: -1.3637\n",
            "====> Epoch: 31 Average train loss: -1.7156\n",
            "====> Epoch: 31 Average val loss: -1.3608\n",
            "====> Epoch: 32 Average train loss: -1.7259\n",
            "====> Epoch: 32 Average val loss: -1.3569\n",
            "====> Epoch: 33 Average train loss: -1.7355\n",
            "====> Epoch: 33 Average val loss: -1.3523\n",
            "====> Epoch: 34 Average train loss: -1.7443\n",
            "====> Epoch: 34 Average val loss: -1.3470\n",
            "====> Epoch: 35 Average train loss: -1.7523\n",
            "====> Epoch: 35 Average val loss: -1.3415\n",
            "====> Epoch: 36 Average train loss: -1.7596\n",
            "====> Epoch: 36 Average val loss: -1.3363\n",
            "====> Epoch: 37 Average train loss: -1.7663\n",
            "====> Epoch: 37 Average val loss: -1.3318\n",
            "====> Epoch: 38 Average train loss: -1.7727\n",
            "====> Epoch: 38 Average val loss: -1.3285\n",
            "====> Epoch: 39 Average train loss: -1.7789\n",
            "====> Epoch: 39 Average val loss: -1.3264\n",
            "====> Epoch: 40 Average train loss: -1.7850\n",
            "====> Epoch: 40 Average val loss: -1.3255\n",
            "====> Epoch: 41 Average train loss: -1.7909\n",
            "====> Epoch: 41 Average val loss: -1.3254\n",
            "====> Epoch: 42 Average train loss: -1.7966\n",
            "====> Epoch: 42 Average val loss: -1.3256\n",
            "====> Epoch: 43 Average train loss: -1.8021\n",
            "====> Epoch: 43 Average val loss: -1.3258\n",
            "====> Epoch: 44 Average train loss: -1.8076\n",
            "====> Epoch: 44 Average val loss: -1.3256\n",
            "====> Epoch: 45 Average train loss: -1.8130\n",
            "====> Epoch: 45 Average val loss: -1.3249\n",
            "====> Epoch: 46 Average train loss: -1.8187\n",
            "====> Epoch: 46 Average val loss: -1.3233\n",
            "====> Epoch: 47 Average train loss: -1.8246\n",
            "====> Epoch: 47 Average val loss: -1.3209\n",
            "====> Epoch: 48 Average train loss: -1.8306\n",
            "====> Epoch: 48 Average val loss: -1.3174\n",
            "====> Epoch: 49 Average train loss: -1.8366\n",
            "====> Epoch: 49 Average val loss: -1.3129\n",
            "====> Epoch: 50 Average train loss: -1.8422\n",
            "====> Epoch: 50 Average val loss: -1.3076\n",
            "DCCA by non-linear orthogonal iterations\n",
            "total parameters:  201476\n",
            "====> Epoch: 1 Average train loss: -0.2216\n",
            "====> Epoch: 1 Average val loss: -0.4145\n",
            "Min loss -0.41\n",
            "====> Epoch: 2 Average train loss: -0.6000\n",
            "====> Epoch: 2 Average val loss: -0.4256\n",
            "Min loss -0.43\n",
            "====> Epoch: 3 Average train loss: -0.6048\n",
            "====> Epoch: 3 Average val loss: -0.3648\n",
            "====> Epoch: 4 Average train loss: -0.5094\n",
            "====> Epoch: 4 Average val loss: -0.3403\n",
            "====> Epoch: 5 Average train loss: -0.3834\n",
            "====> Epoch: 5 Average val loss: -0.5191\n",
            "Min loss -0.52\n",
            "====> Epoch: 6 Average train loss: -0.5779\n",
            "====> Epoch: 6 Average val loss: -0.5154\n",
            "====> Epoch: 7 Average train loss: -0.5784\n",
            "====> Epoch: 7 Average val loss: -0.4664\n",
            "====> Epoch: 8 Average train loss: -0.5281\n",
            "====> Epoch: 8 Average val loss: -0.3333\n",
            "====> Epoch: 9 Average train loss: -0.4134\n",
            "====> Epoch: 9 Average val loss: -0.4264\n",
            "====> Epoch: 10 Average train loss: -0.4573\n",
            "====> Epoch: 10 Average val loss: -0.3801\n",
            "====> Epoch: 11 Average train loss: -0.3906\n",
            "====> Epoch: 11 Average val loss: -0.1569\n",
            "====> Epoch: 12 Average train loss: -0.3204\n",
            "====> Epoch: 12 Average val loss: -0.2605\n",
            "====> Epoch: 13 Average train loss: -0.4171\n",
            "====> Epoch: 13 Average val loss: -0.3874\n",
            "====> Epoch: 14 Average train loss: -0.6031\n",
            "====> Epoch: 14 Average val loss: -0.3722\n",
            "====> Epoch: 15 Average train loss: -0.5546\n",
            "====> Epoch: 15 Average val loss: -0.3871\n",
            "====> Epoch: 16 Average train loss: -0.4809\n",
            "====> Epoch: 16 Average val loss: -0.3239\n",
            "====> Epoch: 17 Average train loss: -0.4520\n",
            "====> Epoch: 17 Average val loss: -0.2265\n",
            "====> Epoch: 18 Average train loss: -0.3384\n",
            "====> Epoch: 18 Average val loss: -0.4225\n",
            "====> Epoch: 19 Average train loss: -0.4241\n",
            "====> Epoch: 19 Average val loss: -0.4553\n",
            "====> Epoch: 20 Average train loss: -0.4268\n",
            "====> Epoch: 20 Average val loss: -0.3940\n",
            "====> Epoch: 21 Average train loss: -0.3850\n",
            "====> Epoch: 21 Average val loss: -0.2297\n",
            "====> Epoch: 22 Average train loss: -0.3552\n",
            "====> Epoch: 22 Average val loss: -0.1869\n",
            "====> Epoch: 23 Average train loss: -0.2086\n",
            "====> Epoch: 23 Average val loss: -0.3302\n",
            "====> Epoch: 24 Average train loss: -0.4925\n",
            "====> Epoch: 24 Average val loss: -0.3791\n",
            "====> Epoch: 25 Average train loss: -0.5257\n",
            "====> Epoch: 25 Average val loss: -0.3829\n",
            "====> Epoch: 26 Average train loss: -0.5040\n",
            "====> Epoch: 26 Average val loss: -0.2841\n",
            "====> Epoch: 27 Average train loss: -0.4182\n",
            "====> Epoch: 27 Average val loss: -0.1802\n",
            "====> Epoch: 28 Average train loss: -0.2833\n",
            "====> Epoch: 28 Average val loss: -0.1875\n",
            "====> Epoch: 29 Average train loss: -0.3007\n",
            "====> Epoch: 29 Average val loss: -0.2109\n",
            "====> Epoch: 30 Average train loss: -0.3069\n",
            "====> Epoch: 30 Average val loss: -0.1089\n",
            "====> Epoch: 31 Average train loss: -0.1800\n",
            "====> Epoch: 31 Average val loss: -0.2625\n",
            "====> Epoch: 32 Average train loss: -0.3084\n",
            "====> Epoch: 32 Average val loss: -0.2916\n",
            "====> Epoch: 33 Average train loss: -0.3644\n",
            "====> Epoch: 33 Average val loss: -0.2719\n",
            "====> Epoch: 34 Average train loss: -0.3508\n",
            "====> Epoch: 34 Average val loss: -0.2623\n",
            "====> Epoch: 35 Average train loss: -0.3848\n",
            "====> Epoch: 35 Average val loss: -0.2017\n",
            "====> Epoch: 36 Average train loss: -0.3135\n",
            "====> Epoch: 36 Average val loss: -0.2088\n",
            "====> Epoch: 37 Average train loss: -0.3019\n",
            "====> Epoch: 37 Average val loss: -0.2296\n",
            "====> Epoch: 38 Average train loss: -0.3534\n",
            "====> Epoch: 38 Average val loss: -0.1696\n",
            "====> Epoch: 39 Average train loss: -0.2493\n",
            "====> Epoch: 39 Average val loss: -0.1098\n",
            "====> Epoch: 40 Average train loss: -0.2964\n",
            "====> Epoch: 40 Average val loss: -0.1149\n",
            "====> Epoch: 41 Average train loss: -0.1911\n",
            "====> Epoch: 41 Average val loss: -0.2219\n",
            "====> Epoch: 42 Average train loss: -0.2469\n",
            "====> Epoch: 42 Average val loss: -0.1700\n",
            "====> Epoch: 43 Average train loss: -0.2357\n",
            "====> Epoch: 43 Average val loss: -0.1726\n",
            "====> Epoch: 44 Average train loss: -0.2634\n",
            "====> Epoch: 44 Average val loss: -0.1415\n",
            "====> Epoch: 45 Average train loss: -0.2052\n",
            "====> Epoch: 45 Average val loss: -0.2935\n",
            "====> Epoch: 46 Average train loss: -0.4594\n",
            "====> Epoch: 46 Average val loss: -0.3391\n",
            "====> Epoch: 47 Average train loss: -0.4347\n",
            "====> Epoch: 47 Average val loss: -0.1790\n",
            "====> Epoch: 48 Average train loss: -0.3674\n",
            "====> Epoch: 48 Average val loss: -0.1738\n",
            "====> Epoch: 49 Average train loss: -0.4651\n",
            "====> Epoch: 49 Average val loss: -0.2366\n",
            "====> Epoch: 50 Average train loss: -0.2951\n",
            "====> Epoch: 50 Average val loss: -0.2198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NZ5ZB9cNx-o"
      },
      "source": [
        "# DGCCA and DMCCA for more than 2 views\r\n",
        "\r\n",
        "The only change we need to make is to the objective argument to perform DGCCA and DMCCA."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAClfNMYNxq4",
        "outputId": "97c6494e-585e-4207-a161-31542646347f"
      },
      "source": [
        "# DGCCA\r\n",
        "print('DGCCA')\r\n",
        "encoder_1 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\r\n",
        "encoder_2 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\r\n",
        "dgcca_model = dcca.DCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2], objective=objectives.GCCA)\r\n",
        "\r\n",
        "dgcca_model = deepwrapper.DeepWrapper(dgcca_model)\r\n",
        "\r\n",
        "dgcca_model.fit(train_view_1, train_view_2, epochs=epochs)\r\n",
        "\r\n",
        "dgcca_results = np.stack(\r\n",
        "    (dgcca_model.train_correlations[0, 1], dgcca_model.predict_corr(test_view_1, test_view_2)[0, 1]))\r\n",
        "\r\n",
        "# DMCCA\r\n",
        "print('DMCCA')\r\n",
        "encoder_1 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\r\n",
        "encoder_2 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\r\n",
        "dmcca_model = dcca.DCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2], objective=objectives.MCCA)\r\n",
        "\r\n",
        "dmcca_model = deepwrapper.DeepWrapper(dmcca_model)\r\n",
        "\r\n",
        "dmcca_model.fit(train_view_1, train_view_2, epochs=epochs)\r\n",
        "\r\n",
        "dmcca_results = np.stack(\r\n",
        "    (dmcca_model.train_correlations[0, 1], dmcca_model.predict_corr(test_view_1, test_view_2)[0, 1]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DGCCA\n",
            "total parameters:  201476\n",
            "====> Epoch: 1 Average train loss: -0.1510\n",
            "====> Epoch: 1 Average val loss: -0.4711\n",
            "Min loss -0.47\n",
            "====> Epoch: 2 Average train loss: -0.5664\n",
            "====> Epoch: 2 Average val loss: -1.1723\n",
            "Min loss -1.17\n",
            "====> Epoch: 3 Average train loss: -1.2070\n",
            "====> Epoch: 3 Average val loss: -1.3020\n",
            "Min loss -1.30\n",
            "====> Epoch: 4 Average train loss: -1.3488\n",
            "====> Epoch: 4 Average val loss: -1.3520\n",
            "Min loss -1.35\n",
            "====> Epoch: 5 Average train loss: -1.4095\n",
            "====> Epoch: 5 Average val loss: -1.3759\n",
            "Min loss -1.38\n",
            "====> Epoch: 6 Average train loss: -1.4446\n",
            "====> Epoch: 6 Average val loss: -1.3902\n",
            "Min loss -1.39\n",
            "====> Epoch: 7 Average train loss: -1.4712\n",
            "====> Epoch: 7 Average val loss: -1.4013\n",
            "Min loss -1.40\n",
            "====> Epoch: 8 Average train loss: -1.4962\n",
            "====> Epoch: 8 Average val loss: -1.4114\n",
            "Min loss -1.41\n",
            "====> Epoch: 9 Average train loss: -1.5217\n",
            "====> Epoch: 9 Average val loss: -1.4208\n",
            "Min loss -1.42\n",
            "====> Epoch: 10 Average train loss: -1.5478\n",
            "====> Epoch: 10 Average val loss: -1.4287\n",
            "Min loss -1.43\n",
            "====> Epoch: 11 Average train loss: -1.5734\n",
            "====> Epoch: 11 Average val loss: -1.4343\n",
            "Min loss -1.43\n",
            "====> Epoch: 12 Average train loss: -1.5973\n",
            "====> Epoch: 12 Average val loss: -1.4372\n",
            "Min loss -1.44\n",
            "====> Epoch: 13 Average train loss: -1.6184\n",
            "====> Epoch: 13 Average val loss: -1.4374\n",
            "Min loss -1.44\n",
            "====> Epoch: 14 Average train loss: -1.6366\n",
            "====> Epoch: 14 Average val loss: -1.4358\n",
            "====> Epoch: 15 Average train loss: -1.6521\n",
            "====> Epoch: 15 Average val loss: -1.4335\n",
            "====> Epoch: 16 Average train loss: -1.6657\n",
            "====> Epoch: 16 Average val loss: -1.4318\n",
            "====> Epoch: 17 Average train loss: -1.6783\n",
            "====> Epoch: 17 Average val loss: -1.4314\n",
            "====> Epoch: 18 Average train loss: -1.6905\n",
            "====> Epoch: 18 Average val loss: -1.4327\n",
            "====> Epoch: 19 Average train loss: -1.7025\n",
            "====> Epoch: 19 Average val loss: -1.4352\n",
            "====> Epoch: 20 Average train loss: -1.7140\n",
            "====> Epoch: 20 Average val loss: -1.4382\n",
            "Min loss -1.44\n",
            "====> Epoch: 21 Average train loss: -1.7247\n",
            "====> Epoch: 21 Average val loss: -1.4410\n",
            "Min loss -1.44\n",
            "====> Epoch: 22 Average train loss: -1.7344\n",
            "====> Epoch: 22 Average val loss: -1.4432\n",
            "Min loss -1.44\n",
            "====> Epoch: 23 Average train loss: -1.7434\n",
            "====> Epoch: 23 Average val loss: -1.4448\n",
            "Min loss -1.44\n",
            "====> Epoch: 24 Average train loss: -1.7519\n",
            "====> Epoch: 24 Average val loss: -1.4455\n",
            "Min loss -1.45\n",
            "====> Epoch: 25 Average train loss: -1.7600\n",
            "====> Epoch: 25 Average val loss: -1.4452\n",
            "====> Epoch: 26 Average train loss: -1.7676\n",
            "====> Epoch: 26 Average val loss: -1.4437\n",
            "====> Epoch: 27 Average train loss: -1.7746\n",
            "====> Epoch: 27 Average val loss: -1.4411\n",
            "====> Epoch: 28 Average train loss: -1.7809\n",
            "====> Epoch: 28 Average val loss: -1.4375\n",
            "====> Epoch: 29 Average train loss: -1.7870\n",
            "====> Epoch: 29 Average val loss: -1.4333\n",
            "====> Epoch: 30 Average train loss: -1.7931\n",
            "====> Epoch: 30 Average val loss: -1.4286\n",
            "====> Epoch: 31 Average train loss: -1.7995\n",
            "====> Epoch: 31 Average val loss: -1.4235\n",
            "====> Epoch: 32 Average train loss: -1.8059\n",
            "====> Epoch: 32 Average val loss: -1.4179\n",
            "====> Epoch: 33 Average train loss: -1.8121\n",
            "====> Epoch: 33 Average val loss: -1.4121\n",
            "====> Epoch: 34 Average train loss: -1.8180\n",
            "====> Epoch: 34 Average val loss: -1.4061\n",
            "====> Epoch: 35 Average train loss: -1.8234\n",
            "====> Epoch: 35 Average val loss: -1.4005\n",
            "====> Epoch: 36 Average train loss: -1.8284\n",
            "====> Epoch: 36 Average val loss: -1.3956\n",
            "====> Epoch: 37 Average train loss: -1.8335\n",
            "====> Epoch: 37 Average val loss: -1.3920\n",
            "====> Epoch: 38 Average train loss: -1.8385\n",
            "====> Epoch: 38 Average val loss: -1.3896\n",
            "====> Epoch: 39 Average train loss: -1.8435\n",
            "====> Epoch: 39 Average val loss: -1.3885\n",
            "====> Epoch: 40 Average train loss: -1.8483\n",
            "====> Epoch: 40 Average val loss: -1.3883\n",
            "====> Epoch: 41 Average train loss: -1.8529\n",
            "====> Epoch: 41 Average val loss: -1.3887\n",
            "====> Epoch: 42 Average train loss: -1.8571\n",
            "====> Epoch: 42 Average val loss: -1.3892\n",
            "====> Epoch: 43 Average train loss: -1.8612\n",
            "====> Epoch: 43 Average val loss: -1.3893\n",
            "====> Epoch: 44 Average train loss: -1.8653\n",
            "====> Epoch: 44 Average val loss: -1.3885\n",
            "====> Epoch: 45 Average train loss: -1.8693\n",
            "====> Epoch: 45 Average val loss: -1.3867\n",
            "====> Epoch: 46 Average train loss: -1.8733\n",
            "====> Epoch: 46 Average val loss: -1.3838\n",
            "====> Epoch: 47 Average train loss: -1.8772\n",
            "====> Epoch: 47 Average val loss: -1.3798\n",
            "====> Epoch: 48 Average train loss: -1.8810\n",
            "====> Epoch: 48 Average val loss: -1.3752\n",
            "====> Epoch: 49 Average train loss: -1.8846\n",
            "====> Epoch: 49 Average val loss: -1.3705\n",
            "====> Epoch: 50 Average train loss: -1.8881\n",
            "====> Epoch: 50 Average val loss: -1.3663\n",
            "DMCCA\n",
            "total parameters:  201476\n",
            "====> Epoch: 1 Average train loss: -0.2496\n",
            "====> Epoch: 1 Average val loss: -0.9559\n",
            "Min loss -0.96\n",
            "====> Epoch: 2 Average train loss: -1.1018\n",
            "====> Epoch: 2 Average val loss: -1.1854\n",
            "Min loss -1.19\n",
            "====> Epoch: 3 Average train loss: -1.3482\n",
            "====> Epoch: 3 Average val loss: -1.2393\n",
            "Min loss -1.24\n",
            "====> Epoch: 4 Average train loss: -1.4146\n",
            "====> Epoch: 4 Average val loss: -1.2687\n",
            "Min loss -1.27\n",
            "====> Epoch: 5 Average train loss: -1.4583\n",
            "====> Epoch: 5 Average val loss: -1.2905\n",
            "Min loss -1.29\n",
            "====> Epoch: 6 Average train loss: -1.4951\n",
            "====> Epoch: 6 Average val loss: -1.3088\n",
            "Min loss -1.31\n",
            "====> Epoch: 7 Average train loss: -1.5285\n",
            "====> Epoch: 7 Average val loss: -1.3247\n",
            "Min loss -1.32\n",
            "====> Epoch: 8 Average train loss: -1.5593\n",
            "====> Epoch: 8 Average val loss: -1.3386\n",
            "Min loss -1.34\n",
            "====> Epoch: 9 Average train loss: -1.5880\n",
            "====> Epoch: 9 Average val loss: -1.3507\n",
            "Min loss -1.35\n",
            "====> Epoch: 10 Average train loss: -1.6146\n",
            "====> Epoch: 10 Average val loss: -1.3611\n",
            "Min loss -1.36\n",
            "====> Epoch: 11 Average train loss: -1.6392\n",
            "====> Epoch: 11 Average val loss: -1.3697\n",
            "Min loss -1.37\n",
            "====> Epoch: 12 Average train loss: -1.6615\n",
            "====> Epoch: 12 Average val loss: -1.3764\n",
            "Min loss -1.38\n",
            "====> Epoch: 13 Average train loss: -1.6814\n",
            "====> Epoch: 13 Average val loss: -1.3811\n",
            "Min loss -1.38\n",
            "====> Epoch: 14 Average train loss: -1.6986\n",
            "====> Epoch: 14 Average val loss: -1.3839\n",
            "Min loss -1.38\n",
            "====> Epoch: 15 Average train loss: -1.7132\n",
            "====> Epoch: 15 Average val loss: -1.3847\n",
            "Min loss -1.38\n",
            "====> Epoch: 16 Average train loss: -1.7255\n",
            "====> Epoch: 16 Average val loss: -1.3839\n",
            "====> Epoch: 17 Average train loss: -1.7358\n",
            "====> Epoch: 17 Average val loss: -1.3818\n",
            "====> Epoch: 18 Average train loss: -1.7450\n",
            "====> Epoch: 18 Average val loss: -1.3789\n",
            "====> Epoch: 19 Average train loss: -1.7538\n",
            "====> Epoch: 19 Average val loss: -1.3754\n",
            "====> Epoch: 20 Average train loss: -1.7628\n",
            "====> Epoch: 20 Average val loss: -1.3717\n",
            "====> Epoch: 21 Average train loss: -1.7722\n",
            "====> Epoch: 21 Average val loss: -1.3678\n",
            "====> Epoch: 22 Average train loss: -1.7819\n",
            "====> Epoch: 22 Average val loss: -1.3637\n",
            "====> Epoch: 23 Average train loss: -1.7917\n",
            "====> Epoch: 23 Average val loss: -1.3593\n",
            "====> Epoch: 24 Average train loss: -1.8012\n",
            "====> Epoch: 24 Average val loss: -1.3548\n",
            "====> Epoch: 25 Average train loss: -1.8101\n",
            "====> Epoch: 25 Average val loss: -1.3499\n",
            "====> Epoch: 26 Average train loss: -1.8183\n",
            "====> Epoch: 26 Average val loss: -1.3448\n",
            "====> Epoch: 27 Average train loss: -1.8259\n",
            "====> Epoch: 27 Average val loss: -1.3394\n",
            "====> Epoch: 28 Average train loss: -1.8330\n",
            "====> Epoch: 28 Average val loss: -1.3338\n",
            "====> Epoch: 29 Average train loss: -1.8396\n",
            "====> Epoch: 29 Average val loss: -1.3279\n",
            "====> Epoch: 30 Average train loss: -1.8460\n",
            "====> Epoch: 30 Average val loss: -1.3220\n",
            "====> Epoch: 31 Average train loss: -1.8522\n",
            "====> Epoch: 31 Average val loss: -1.3159\n",
            "====> Epoch: 32 Average train loss: -1.8581\n",
            "====> Epoch: 32 Average val loss: -1.3100\n",
            "====> Epoch: 33 Average train loss: -1.8637\n",
            "====> Epoch: 33 Average val loss: -1.3042\n",
            "====> Epoch: 34 Average train loss: -1.8690\n",
            "====> Epoch: 34 Average val loss: -1.2988\n",
            "====> Epoch: 35 Average train loss: -1.8739\n",
            "====> Epoch: 35 Average val loss: -1.2938\n",
            "====> Epoch: 36 Average train loss: -1.8785\n",
            "====> Epoch: 36 Average val loss: -1.2894\n",
            "====> Epoch: 37 Average train loss: -1.8828\n",
            "====> Epoch: 37 Average val loss: -1.2854\n",
            "====> Epoch: 38 Average train loss: -1.8870\n",
            "====> Epoch: 38 Average val loss: -1.2819\n",
            "====> Epoch: 39 Average train loss: -1.8910\n",
            "====> Epoch: 39 Average val loss: -1.2787\n",
            "====> Epoch: 40 Average train loss: -1.8950\n",
            "====> Epoch: 40 Average val loss: -1.2756\n",
            "====> Epoch: 41 Average train loss: -1.8989\n",
            "====> Epoch: 41 Average val loss: -1.2725\n",
            "====> Epoch: 42 Average train loss: -1.9028\n",
            "====> Epoch: 42 Average val loss: -1.2695\n",
            "====> Epoch: 43 Average train loss: -1.9066\n",
            "====> Epoch: 43 Average val loss: -1.2664\n",
            "====> Epoch: 44 Average train loss: -1.9102\n",
            "====> Epoch: 44 Average val loss: -1.2634\n",
            "====> Epoch: 45 Average train loss: -1.9136\n",
            "====> Epoch: 45 Average val loss: -1.2606\n",
            "====> Epoch: 46 Average train loss: -1.9169\n",
            "====> Epoch: 46 Average val loss: -1.2581\n",
            "====> Epoch: 47 Average train loss: -1.9200\n",
            "====> Epoch: 47 Average val loss: -1.2559\n",
            "====> Epoch: 48 Average train loss: -1.9231\n",
            "====> Epoch: 48 Average val loss: -1.2540\n",
            "====> Epoch: 49 Average train loss: -1.9260\n",
            "====> Epoch: 49 Average val loss: -1.2522\n",
            "====> Epoch: 50 Average train loss: -1.9289\n",
            "====> Epoch: 50 Average val loss: -1.2503\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ym0WfC6uOA-8"
      },
      "source": [
        "# Deep Canonically Correlated Autoencoders\r\n",
        "We need to add decoders in order to model deep canonically correlated autoencoders and we also use the DCCAE class which inherits from DCCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwiNJf-MOBOg",
        "outputId": "b12ac146-80eb-4fba-99b3-f687001cf64c"
      },
      "source": [
        "from cca_zoo import dccae\r\n",
        "\r\n",
        "# DCCAE\r\n",
        "print('DCCAE')\r\n",
        "encoder_1 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\r\n",
        "encoder_2 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784)\r\n",
        "decoder_1 = deep_models.Decoder(latent_dims=latent_dims, feature_size=784)\r\n",
        "decoder_2 = deep_models.Decoder(latent_dims=latent_dims, feature_size=784)\r\n",
        "dccae_model = dccae.DCCAE(latent_dims=latent_dims, encoders=[encoder_1, encoder_2], decoders=[decoder_1, decoder_2])\r\n",
        "\r\n",
        "dccae_model = deepwrapper.DeepWrapper(dccae_model)\r\n",
        "\r\n",
        "dccae_model.fit(train_view_1, train_view_2, epochs=epochs)\r\n",
        "\r\n",
        "dccae_results = np.stack(\r\n",
        "    (dccae_model.train_correlations[0, 1], dccae_model.predict_corr(test_view_1, test_view_2)[0, 1]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DCCAE\n",
            "total parameters:  404516\n",
            "====> Epoch: 1 Average train loss: 177033.7656\n",
            "====> Epoch: 1 Average val loss: 155792.2969\n",
            "Min loss 155792.30\n",
            "====> Epoch: 2 Average train loss: 153120.7500\n",
            "====> Epoch: 2 Average val loss: 134652.6250\n",
            "Min loss 134652.62\n",
            "====> Epoch: 3 Average train loss: 132245.5000\n",
            "====> Epoch: 3 Average val loss: 115017.2344\n",
            "Min loss 115017.23\n",
            "====> Epoch: 4 Average train loss: 112915.2812\n",
            "====> Epoch: 4 Average val loss: 99213.5312\n",
            "Min loss 99213.53\n",
            "====> Epoch: 5 Average train loss: 97374.1641\n",
            "====> Epoch: 5 Average val loss: 86769.4297\n",
            "Min loss 86769.43\n",
            "====> Epoch: 6 Average train loss: 85148.4453\n",
            "====> Epoch: 6 Average val loss: 75465.8047\n",
            "Min loss 75465.80\n",
            "====> Epoch: 7 Average train loss: 74069.2266\n",
            "====> Epoch: 7 Average val loss: 65957.0000\n",
            "Min loss 65957.00\n",
            "====> Epoch: 8 Average train loss: 64779.8125\n",
            "====> Epoch: 8 Average val loss: 58767.3281\n",
            "Min loss 58767.33\n",
            "====> Epoch: 9 Average train loss: 57784.1992\n",
            "====> Epoch: 9 Average val loss: 53202.5781\n",
            "Min loss 53202.58\n",
            "====> Epoch: 10 Average train loss: 52389.3164\n",
            "====> Epoch: 10 Average val loss: 48643.5586\n",
            "Min loss 48643.56\n",
            "====> Epoch: 11 Average train loss: 47983.6328\n",
            "====> Epoch: 11 Average val loss: 44899.7773\n",
            "Min loss 44899.78\n",
            "====> Epoch: 12 Average train loss: 44377.9531\n",
            "====> Epoch: 12 Average val loss: 42146.8984\n",
            "Min loss 42146.90\n",
            "====> Epoch: 13 Average train loss: 41740.7812\n",
            "====> Epoch: 13 Average val loss: 40360.9766\n",
            "Min loss 40360.98\n",
            "====> Epoch: 14 Average train loss: 40044.6680\n",
            "====> Epoch: 14 Average val loss: 39166.8008\n",
            "Min loss 39166.80\n",
            "====> Epoch: 15 Average train loss: 38922.0625\n",
            "====> Epoch: 15 Average val loss: 38237.3828\n",
            "Min loss 38237.38\n",
            "====> Epoch: 16 Average train loss: 38056.5859\n",
            "====> Epoch: 16 Average val loss: 37489.7930\n",
            "Min loss 37489.79\n",
            "====> Epoch: 17 Average train loss: 37369.3125\n",
            "====> Epoch: 17 Average val loss: 37025.0586\n",
            "Min loss 37025.06\n",
            "====> Epoch: 18 Average train loss: 36955.6211\n",
            "====> Epoch: 18 Average val loss: 36818.6055\n",
            "Min loss 36818.61\n",
            "====> Epoch: 19 Average train loss: 36784.4922\n",
            "====> Epoch: 19 Average val loss: 36705.5938\n",
            "Min loss 36705.59\n",
            "====> Epoch: 20 Average train loss: 36689.5781\n",
            "====> Epoch: 20 Average val loss: 36564.5273\n",
            "Min loss 36564.53\n",
            "====> Epoch: 21 Average train loss: 36551.8203\n",
            "====> Epoch: 21 Average val loss: 36360.2656\n",
            "Min loss 36360.27\n",
            "====> Epoch: 22 Average train loss: 36340.4414\n",
            "====> Epoch: 22 Average val loss: 36142.8945\n",
            "Min loss 36142.89\n",
            "====> Epoch: 23 Average train loss: 36109.9922\n",
            "====> Epoch: 23 Average val loss: 35946.9180\n",
            "Min loss 35946.92\n",
            "====> Epoch: 24 Average train loss: 35898.9844\n",
            "====> Epoch: 24 Average val loss: 35749.4961\n",
            "Min loss 35749.50\n",
            "====> Epoch: 25 Average train loss: 35686.7812\n",
            "====> Epoch: 25 Average val loss: 35511.6328\n",
            "Min loss 35511.63\n",
            "====> Epoch: 26 Average train loss: 35433.7305\n",
            "====> Epoch: 26 Average val loss: 35203.1445\n",
            "Min loss 35203.14\n",
            "====> Epoch: 27 Average train loss: 35107.7891\n",
            "====> Epoch: 27 Average val loss: 34858.3828\n",
            "Min loss 34858.38\n",
            "====> Epoch: 28 Average train loss: 34741.5977\n",
            "====> Epoch: 28 Average val loss: 34533.1094\n",
            "Min loss 34533.11\n",
            "====> Epoch: 29 Average train loss: 34391.1641\n",
            "====> Epoch: 29 Average val loss: 34242.7227\n",
            "Min loss 34242.72\n",
            "====> Epoch: 30 Average train loss: 34074.8242\n",
            "====> Epoch: 30 Average val loss: 33964.9062\n",
            "Min loss 33964.91\n",
            "====> Epoch: 31 Average train loss: 33773.8750\n",
            "====> Epoch: 31 Average val loss: 33670.5469\n",
            "Min loss 33670.55\n",
            "====> Epoch: 32 Average train loss: 33460.5391\n",
            "====> Epoch: 32 Average val loss: 33370.6211\n",
            "Min loss 33370.62\n",
            "====> Epoch: 33 Average train loss: 33143.6367\n",
            "====> Epoch: 33 Average val loss: 33089.1445\n",
            "Min loss 33089.14\n",
            "====> Epoch: 34 Average train loss: 32844.0234\n",
            "====> Epoch: 34 Average val loss: 32839.1484\n",
            "Min loss 32839.15\n",
            "====> Epoch: 35 Average train loss: 32573.5000\n",
            "====> Epoch: 35 Average val loss: 32615.8945\n",
            "Min loss 32615.89\n",
            "====> Epoch: 36 Average train loss: 32329.1289\n",
            "====> Epoch: 36 Average val loss: 32396.5215\n",
            "Min loss 32396.52\n",
            "====> Epoch: 37 Average train loss: 32091.9922\n",
            "====> Epoch: 37 Average val loss: 32170.7246\n",
            "Min loss 32170.72\n",
            "====> Epoch: 38 Average train loss: 31854.7500\n",
            "====> Epoch: 38 Average val loss: 31943.3301\n",
            "Min loss 31943.33\n",
            "====> Epoch: 39 Average train loss: 31621.9297\n",
            "====> Epoch: 39 Average val loss: 31731.4395\n",
            "Min loss 31731.44\n",
            "====> Epoch: 40 Average train loss: 31407.3633\n",
            "====> Epoch: 40 Average val loss: 31539.0137\n",
            "Min loss 31539.01\n",
            "====> Epoch: 41 Average train loss: 31211.5586\n",
            "====> Epoch: 41 Average val loss: 31359.1777\n",
            "Min loss 31359.18\n",
            "====> Epoch: 42 Average train loss: 31026.1602\n",
            "====> Epoch: 42 Average val loss: 31186.3633\n",
            "Min loss 31186.36\n",
            "====> Epoch: 43 Average train loss: 30846.5312\n",
            "====> Epoch: 43 Average val loss: 31015.9297\n",
            "Min loss 31015.93\n",
            "====> Epoch: 44 Average train loss: 30670.7812\n",
            "====> Epoch: 44 Average val loss: 30848.2285\n",
            "Min loss 30848.23\n",
            "====> Epoch: 45 Average train loss: 30501.6426\n",
            "====> Epoch: 45 Average val loss: 30685.3984\n",
            "Min loss 30685.40\n",
            "====> Epoch: 46 Average train loss: 30341.0723\n",
            "====> Epoch: 46 Average val loss: 30532.3398\n",
            "Min loss 30532.34\n",
            "====> Epoch: 47 Average train loss: 30191.2344\n",
            "====> Epoch: 47 Average val loss: 30385.4902\n",
            "Min loss 30385.49\n",
            "====> Epoch: 48 Average train loss: 30046.0410\n",
            "====> Epoch: 48 Average val loss: 30241.5664\n",
            "Min loss 30241.57\n",
            "====> Epoch: 49 Average train loss: 29902.0723\n",
            "====> Epoch: 49 Average val loss: 30099.0586\n",
            "Min loss 30099.06\n",
            "====> Epoch: 50 Average train loss: 29759.6914\n",
            "====> Epoch: 50 Average val loss: 29961.1367\n",
            "Min loss 29961.14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwOTBYZ0O9SP"
      },
      "source": [
        "# Deep Variational CCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SogqelCuO9rm",
        "outputId": "c24f67fb-0456-4ec7-84b7-793656b7e5e8"
      },
      "source": [
        "\"\"\"\r\n",
        "### Deep Variational Learning\r\n",
        "Finally we have Deep Variational CCA methods.\r\n",
        "- Deep Variational CCA (DVCCA)\r\n",
        "- Deep Variational CCA - private (DVVCA_p)\r\n",
        "\r\n",
        "These are both implemented by the DVCCA class with private=True/False and both_encoders=True/False. If both_encoders,\r\n",
        "the encoder to the shared information Q(z_shared|x) is modelled for both x_1 and x_2 whereas if both_encoders is false\r\n",
        "it is modelled for x_1 as in the paper\r\n",
        "\"\"\"\r\n",
        "from cca_zoo import dvcca\r\n",
        "\r\n",
        "# %%\r\n",
        "# DVCCA (technically bi-DVCCA)\r\n",
        "print('DVCCA')\r\n",
        "encoder_1 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\r\n",
        "encoder_2 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\r\n",
        "decoder_1 = deep_models.Decoder(latent_dims=latent_dims, feature_size=784, norm_output=True)\r\n",
        "decoder_2 = deep_models.Decoder(latent_dims=latent_dims, feature_size=784, norm_output=True)\r\n",
        "dvcca_model = dvcca.DVCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2], decoders=[decoder_1, decoder_2],\r\n",
        "                          private=False)\r\n",
        "\r\n",
        "dvcca_model = deepwrapper.DeepWrapper(dvcca_model)\r\n",
        "\r\n",
        "dvcca_model.fit(train_view_1, train_view_2, epochs=epochs)\r\n",
        "\r\n",
        "dvcca_model_results = np.stack(\r\n",
        "    (dvcca_model.train_correlations[0, 1], dvcca_model.predict_corr(test_view_1, test_view_2)[0, 1]))\r\n",
        "\r\n",
        "# DVCCA_private (technically bi-DVCCA_private)\r\n",
        "print('DVCCA_private')\r\n",
        "encoder_1 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\r\n",
        "encoder_2 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\r\n",
        "private_encoder_1 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\r\n",
        "private_encoder_2 = deep_models.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\r\n",
        "decoder_1 = deep_models.Decoder(latent_dims=latent_dims * 3, feature_size=784, norm_output=True)\r\n",
        "decoder_2 = deep_models.Decoder(latent_dims=latent_dims * 3, feature_size=784, norm_output=True)\r\n",
        "dvccap_model = dvcca.DVCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2], decoders=[decoder_1, decoder_2],\r\n",
        "                           private_encoders=[private_encoder_1, private_encoder_2], private=True)\r\n",
        "\r\n",
        "dvccap_model = deepwrapper.DeepWrapper(dvccap_model)\r\n",
        "\r\n",
        "dvccap_model.fit(train_view_1, train_view_2, epochs=epochs)\r\n",
        "\r\n",
        "dvccap_model_results = np.stack(\r\n",
        "    (dvccap_model.train_correlations[0, 1], dvccap_model.predict_corr(test_view_1, test_view_2)[0, 1]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DVCCA\n",
            "total parameters:  405548\n",
            "====> Epoch: 1 Average train loss: 1104.1184\n",
            "====> Epoch: 1 Average val loss: 1083.6385\n",
            "Min loss 1083.64\n",
            "====> Epoch: 2 Average train loss: 1083.7947\n",
            "====> Epoch: 2 Average val loss: 1063.4221\n",
            "Min loss 1063.42\n",
            "====> Epoch: 3 Average train loss: 1063.3655\n",
            "====> Epoch: 3 Average val loss: 1044.7902\n",
            "Min loss 1044.79\n",
            "====> Epoch: 4 Average train loss: 1044.6582\n",
            "====> Epoch: 4 Average val loss: 1029.1282\n",
            "Min loss 1029.13\n",
            "====> Epoch: 5 Average train loss: 1028.8289\n",
            "====> Epoch: 5 Average val loss: 1013.7655\n",
            "Min loss 1013.77\n",
            "====> Epoch: 6 Average train loss: 1013.4308\n",
            "====> Epoch: 6 Average val loss: 999.0323\n",
            "Min loss 999.03\n",
            "====> Epoch: 7 Average train loss: 998.6824\n",
            "====> Epoch: 7 Average val loss: 985.9468\n",
            "Min loss 985.95\n",
            "====> Epoch: 8 Average train loss: 985.5276\n",
            "====> Epoch: 8 Average val loss: 974.3967\n",
            "Min loss 974.40\n",
            "====> Epoch: 9 Average train loss: 973.8835\n",
            "====> Epoch: 9 Average val loss: 963.5659\n",
            "Min loss 963.57\n",
            "====> Epoch: 10 Average train loss: 963.0035\n",
            "====> Epoch: 10 Average val loss: 953.3594\n",
            "Min loss 953.36\n",
            "====> Epoch: 11 Average train loss: 952.8304\n",
            "====> Epoch: 11 Average val loss: 944.1158\n",
            "Min loss 944.12\n",
            "====> Epoch: 12 Average train loss: 943.4390\n",
            "====> Epoch: 12 Average val loss: 935.8490\n",
            "Min loss 935.85\n",
            "====> Epoch: 13 Average train loss: 935.2332\n",
            "====> Epoch: 13 Average val loss: 928.3596\n",
            "Min loss 928.36\n",
            "====> Epoch: 14 Average train loss: 927.9099\n",
            "====> Epoch: 14 Average val loss: 921.5051\n",
            "Min loss 921.51\n",
            "====> Epoch: 15 Average train loss: 920.9446\n",
            "====> Epoch: 15 Average val loss: 915.1193\n",
            "Min loss 915.12\n",
            "====> Epoch: 16 Average train loss: 914.6657\n",
            "====> Epoch: 16 Average val loss: 909.3191\n",
            "Min loss 909.32\n",
            "====> Epoch: 17 Average train loss: 908.7615\n",
            "====> Epoch: 17 Average val loss: 904.2504\n",
            "Min loss 904.25\n",
            "====> Epoch: 18 Average train loss: 903.7429\n",
            "====> Epoch: 18 Average val loss: 899.6801\n",
            "Min loss 899.68\n",
            "====> Epoch: 19 Average train loss: 899.2078\n",
            "====> Epoch: 19 Average val loss: 895.4833\n",
            "Min loss 895.48\n",
            "====> Epoch: 20 Average train loss: 894.9315\n",
            "====> Epoch: 20 Average val loss: 891.5302\n",
            "Min loss 891.53\n",
            "====> Epoch: 21 Average train loss: 891.1985\n",
            "====> Epoch: 21 Average val loss: 888.0712\n",
            "Min loss 888.07\n",
            "====> Epoch: 22 Average train loss: 887.5639\n",
            "====> Epoch: 22 Average val loss: 884.9333\n",
            "Min loss 884.93\n",
            "====> Epoch: 23 Average train loss: 884.5070\n",
            "====> Epoch: 23 Average val loss: 882.1547\n",
            "Min loss 882.15\n",
            "====> Epoch: 24 Average train loss: 881.8130\n",
            "====> Epoch: 24 Average val loss: 879.6958\n",
            "Min loss 879.70\n",
            "====> Epoch: 25 Average train loss: 879.2018\n",
            "====> Epoch: 25 Average val loss: 877.1234\n",
            "Min loss 877.12\n",
            "====> Epoch: 26 Average train loss: 876.7570\n",
            "====> Epoch: 26 Average val loss: 874.9755\n",
            "Min loss 874.98\n",
            "====> Epoch: 27 Average train loss: 874.6176\n",
            "====> Epoch: 27 Average val loss: 873.1976\n",
            "Min loss 873.20\n",
            "====> Epoch: 28 Average train loss: 872.7310\n",
            "====> Epoch: 28 Average val loss: 871.2889\n",
            "Min loss 871.29\n",
            "====> Epoch: 29 Average train loss: 870.6930\n",
            "====> Epoch: 29 Average val loss: 869.6082\n",
            "Min loss 869.61\n",
            "====> Epoch: 30 Average train loss: 869.0884\n",
            "====> Epoch: 30 Average val loss: 868.0028\n",
            "Min loss 868.00\n",
            "====> Epoch: 31 Average train loss: 867.5453\n",
            "====> Epoch: 31 Average val loss: 866.4171\n",
            "Min loss 866.42\n",
            "====> Epoch: 32 Average train loss: 866.1750\n",
            "====> Epoch: 32 Average val loss: 865.1016\n",
            "Min loss 865.10\n",
            "====> Epoch: 33 Average train loss: 864.6488\n",
            "====> Epoch: 33 Average val loss: 863.8027\n",
            "Min loss 863.80\n",
            "====> Epoch: 34 Average train loss: 863.6543\n",
            "====> Epoch: 34 Average val loss: 862.7384\n",
            "Min loss 862.74\n",
            "====> Epoch: 35 Average train loss: 862.0701\n",
            "====> Epoch: 35 Average val loss: 861.4637\n",
            "Min loss 861.46\n",
            "====> Epoch: 36 Average train loss: 860.9648\n",
            "====> Epoch: 36 Average val loss: 860.4537\n",
            "Min loss 860.45\n",
            "====> Epoch: 37 Average train loss: 859.8116\n",
            "====> Epoch: 37 Average val loss: 859.4419\n",
            "Min loss 859.44\n",
            "====> Epoch: 38 Average train loss: 858.8525\n",
            "====> Epoch: 38 Average val loss: 858.3662\n",
            "Min loss 858.37\n",
            "====> Epoch: 39 Average train loss: 857.7368\n",
            "====> Epoch: 39 Average val loss: 857.3959\n",
            "Min loss 857.40\n",
            "====> Epoch: 40 Average train loss: 856.6731\n",
            "====> Epoch: 40 Average val loss: 856.4573\n",
            "Min loss 856.46\n",
            "====> Epoch: 41 Average train loss: 855.7616\n",
            "====> Epoch: 41 Average val loss: 855.3207\n",
            "Min loss 855.32\n",
            "====> Epoch: 42 Average train loss: 854.5380\n",
            "====> Epoch: 42 Average val loss: 854.1561\n",
            "Min loss 854.16\n",
            "====> Epoch: 43 Average train loss: 853.5200\n",
            "====> Epoch: 43 Average val loss: 853.3632\n",
            "Min loss 853.36\n",
            "====> Epoch: 44 Average train loss: 852.7966\n",
            "====> Epoch: 44 Average val loss: 852.6306\n",
            "Min loss 852.63\n",
            "====> Epoch: 45 Average train loss: 851.7737\n",
            "====> Epoch: 45 Average val loss: 851.6348\n",
            "Min loss 851.63\n",
            "====> Epoch: 46 Average train loss: 850.5159\n",
            "====> Epoch: 46 Average val loss: 850.6021\n",
            "Min loss 850.60\n",
            "====> Epoch: 47 Average train loss: 849.6866\n",
            "====> Epoch: 47 Average val loss: 849.5726\n",
            "Min loss 849.57\n",
            "====> Epoch: 48 Average train loss: 848.3619\n",
            "====> Epoch: 48 Average val loss: 849.1711\n",
            "Min loss 849.17\n",
            "====> Epoch: 49 Average train loss: 847.4727\n",
            "====> Epoch: 49 Average val loss: 847.6968\n",
            "Min loss 847.70\n",
            "====> Epoch: 50 Average train loss: 846.6523\n",
            "====> Epoch: 50 Average val loss: 846.7859\n",
            "Min loss 846.79\n",
            "DVCCA_private\n",
            "total parameters:  609080\n",
            "====> Epoch: 1 Average train loss: 1106.9209\n",
            "====> Epoch: 1 Average val loss: 1092.8141\n",
            "Min loss 1092.81\n",
            "====> Epoch: 2 Average train loss: 1092.4490\n",
            "====> Epoch: 2 Average val loss: 1066.7837\n",
            "Min loss 1066.78\n",
            "====> Epoch: 3 Average train loss: 1066.5352\n",
            "====> Epoch: 3 Average val loss: 1048.4045\n",
            "Min loss 1048.40\n",
            "====> Epoch: 4 Average train loss: 1047.9417\n",
            "====> Epoch: 4 Average val loss: 1033.3870\n",
            "Min loss 1033.39\n",
            "====> Epoch: 5 Average train loss: 1032.7979\n",
            "====> Epoch: 5 Average val loss: 1016.8925\n",
            "Min loss 1016.89\n",
            "====> Epoch: 6 Average train loss: 1016.1830\n",
            "====> Epoch: 6 Average val loss: 1000.6571\n",
            "Min loss 1000.66\n",
            "====> Epoch: 7 Average train loss: 999.8379\n",
            "====> Epoch: 7 Average val loss: 986.8129\n",
            "Min loss 986.81\n",
            "====> Epoch: 8 Average train loss: 985.8638\n",
            "====> Epoch: 8 Average val loss: 975.1042\n",
            "Min loss 975.10\n",
            "====> Epoch: 9 Average train loss: 974.1342\n",
            "====> Epoch: 9 Average val loss: 964.3875\n",
            "Min loss 964.39\n",
            "====> Epoch: 10 Average train loss: 963.6262\n",
            "====> Epoch: 10 Average val loss: 953.7012\n",
            "Min loss 953.70\n",
            "====> Epoch: 11 Average train loss: 952.9037\n",
            "====> Epoch: 11 Average val loss: 943.6967\n",
            "Min loss 943.70\n",
            "====> Epoch: 12 Average train loss: 942.6809\n",
            "====> Epoch: 12 Average val loss: 934.9275\n",
            "Min loss 934.93\n",
            "====> Epoch: 13 Average train loss: 933.8839\n",
            "====> Epoch: 13 Average val loss: 927.4637\n",
            "Min loss 927.46\n",
            "====> Epoch: 14 Average train loss: 926.2377\n",
            "====> Epoch: 14 Average val loss: 920.8154\n",
            "Min loss 920.82\n",
            "====> Epoch: 15 Average train loss: 919.4486\n",
            "====> Epoch: 15 Average val loss: 914.3978\n",
            "Min loss 914.40\n",
            "====> Epoch: 16 Average train loss: 913.1489\n",
            "====> Epoch: 16 Average val loss: 908.2419\n",
            "Min loss 908.24\n",
            "====> Epoch: 17 Average train loss: 907.1938\n",
            "====> Epoch: 17 Average val loss: 902.8459\n",
            "Min loss 902.85\n",
            "====> Epoch: 18 Average train loss: 901.5608\n",
            "====> Epoch: 18 Average val loss: 897.9111\n",
            "Min loss 897.91\n",
            "====> Epoch: 19 Average train loss: 896.7199\n",
            "====> Epoch: 19 Average val loss: 893.4979\n",
            "Min loss 893.50\n",
            "====> Epoch: 20 Average train loss: 892.4589\n",
            "====> Epoch: 20 Average val loss: 889.9629\n",
            "Min loss 889.96\n",
            "====> Epoch: 21 Average train loss: 888.7781\n",
            "====> Epoch: 21 Average val loss: 886.6088\n",
            "Min loss 886.61\n",
            "====> Epoch: 22 Average train loss: 885.5154\n",
            "====> Epoch: 22 Average val loss: 883.2827\n",
            "Min loss 883.28\n",
            "====> Epoch: 23 Average train loss: 881.9867\n",
            "====> Epoch: 23 Average val loss: 880.4107\n",
            "Min loss 880.41\n",
            "====> Epoch: 24 Average train loss: 879.2169\n",
            "====> Epoch: 24 Average val loss: 877.8224\n",
            "Min loss 877.82\n",
            "====> Epoch: 25 Average train loss: 876.5200\n",
            "====> Epoch: 25 Average val loss: 875.4628\n",
            "Min loss 875.46\n",
            "====> Epoch: 26 Average train loss: 874.0865\n",
            "====> Epoch: 26 Average val loss: 873.2756\n",
            "Min loss 873.28\n",
            "====> Epoch: 27 Average train loss: 872.0773\n",
            "====> Epoch: 27 Average val loss: 871.2561\n",
            "Min loss 871.26\n",
            "====> Epoch: 28 Average train loss: 869.7454\n",
            "====> Epoch: 28 Average val loss: 869.3959\n",
            "Min loss 869.40\n",
            "====> Epoch: 29 Average train loss: 868.2920\n",
            "====> Epoch: 29 Average val loss: 867.5767\n",
            "Min loss 867.58\n",
            "====> Epoch: 30 Average train loss: 866.5385\n",
            "====> Epoch: 30 Average val loss: 866.2571\n",
            "Min loss 866.26\n",
            "====> Epoch: 31 Average train loss: 864.8030\n",
            "====> Epoch: 31 Average val loss: 864.7103\n",
            "Min loss 864.71\n",
            "====> Epoch: 32 Average train loss: 863.1864\n",
            "====> Epoch: 32 Average val loss: 863.0221\n",
            "Min loss 863.02\n",
            "====> Epoch: 33 Average train loss: 861.7301\n",
            "====> Epoch: 33 Average val loss: 861.7765\n",
            "Min loss 861.78\n",
            "====> Epoch: 34 Average train loss: 860.2555\n",
            "====> Epoch: 34 Average val loss: 860.5312\n",
            "Min loss 860.53\n",
            "====> Epoch: 35 Average train loss: 858.9091\n",
            "====> Epoch: 35 Average val loss: 859.3376\n",
            "Min loss 859.34\n",
            "====> Epoch: 36 Average train loss: 857.5138\n",
            "====> Epoch: 36 Average val loss: 858.0610\n",
            "Min loss 858.06\n",
            "====> Epoch: 37 Average train loss: 856.4081\n",
            "====> Epoch: 37 Average val loss: 856.7505\n",
            "Min loss 856.75\n",
            "====> Epoch: 38 Average train loss: 855.0334\n",
            "====> Epoch: 38 Average val loss: 855.6592\n",
            "Min loss 855.66\n",
            "====> Epoch: 39 Average train loss: 853.8333\n",
            "====> Epoch: 39 Average val loss: 854.5139\n",
            "Min loss 854.51\n",
            "====> Epoch: 40 Average train loss: 852.6562\n",
            "====> Epoch: 40 Average val loss: 853.2377\n",
            "Min loss 853.24\n",
            "====> Epoch: 41 Average train loss: 851.4516\n",
            "====> Epoch: 41 Average val loss: 852.4539\n",
            "Min loss 852.45\n",
            "====> Epoch: 42 Average train loss: 850.2383\n",
            "====> Epoch: 42 Average val loss: 851.6708\n",
            "Min loss 851.67\n",
            "====> Epoch: 43 Average train loss: 849.1064\n",
            "====> Epoch: 43 Average val loss: 850.3347\n",
            "Min loss 850.33\n",
            "====> Epoch: 44 Average train loss: 848.0972\n",
            "====> Epoch: 44 Average val loss: 849.2440\n",
            "Min loss 849.24\n",
            "====> Epoch: 45 Average train loss: 846.7636\n",
            "====> Epoch: 45 Average val loss: 848.2544\n",
            "Min loss 848.25\n",
            "====> Epoch: 46 Average train loss: 845.7233\n",
            "====> Epoch: 46 Average val loss: 847.2699\n",
            "Min loss 847.27\n",
            "====> Epoch: 47 Average train loss: 844.5441\n",
            "====> Epoch: 47 Average val loss: 846.0507\n",
            "Min loss 846.05\n",
            "====> Epoch: 48 Average train loss: 843.4480\n",
            "====> Epoch: 48 Average val loss: 845.4172\n",
            "Min loss 845.42\n",
            "====> Epoch: 49 Average train loss: 842.1721\n",
            "====> Epoch: 49 Average val loss: 844.3853\n",
            "Min loss 844.39\n",
            "====> Epoch: 50 Average train loss: 841.0510\n",
            "====> Epoch: 50 Average val loss: 843.4072\n",
            "Min loss 843.41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCMeGlxJkp93"
      },
      "source": [
        "# Convolutional Deep CCA (and using other architectures)\r\n",
        "We provide a standard CNN encoder and decoder but users can build their own encoders and decoders by inheriting BaseEncoder and BaseDecoder for seamless integration with the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9TEto00kpn2",
        "outputId": "7879d8e2-4631-44a0-a6f8-80929e91becd"
      },
      "source": [
        "print('Convolutional DCCA')\r\n",
        "encoder_1 = deep_models.CNNEncoder(latent_dims=latent_dims, channels=[3, 3])\r\n",
        "encoder_2 = deep_models.CNNEncoder(latent_dims=latent_dims, channels=[3, 3])\r\n",
        "dcca_conv_model = dcca.DCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2])\r\n",
        "\r\n",
        "dcca_conv_model = deepwrapper.DeepWrapper(dcca_conv_model)\r\n",
        "\r\n",
        "# to change the models used change the cfg.encoder_models. We implement a CNN_Encoder and CNN_decoder as well\r\n",
        "# as some based on brainnet architecture in cca_zoo.deep_models. Equally you could pass your own encoder/decoder models\r\n",
        "\r\n",
        "dcca_conv_model.fit(train_view_1.reshape((-1, 1, 28, 28)), train_view_2.reshape((-1, 1, 28, 28)), epochs=epochs)\r\n",
        "\r\n",
        "dcca_conv_results = np.stack(\r\n",
        "    (dcca_conv_model.train_correlations[0, 1], dcca_conv_model.predict_corr(test_view_1.reshape((-1, 1, 28, 28)),\r\n",
        "                                                                            test_view_2.reshape(\r\n",
        "                                                                                (-1, 1, 28, 28)))[0, 1]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Convolutional DCCA\n",
            "total parameters:  2512\n",
            "====> Epoch: 1 Average train loss: -0.1936\n",
            "====> Epoch: 1 Average val loss: -0.3435\n",
            "Min loss -0.34\n",
            "====> Epoch: 2 Average train loss: -0.4168\n",
            "====> Epoch: 2 Average val loss: -0.4928\n",
            "Min loss -0.49\n",
            "====> Epoch: 3 Average train loss: -0.6000\n",
            "====> Epoch: 3 Average val loss: -0.6421\n",
            "Min loss -0.64\n",
            "====> Epoch: 4 Average train loss: -0.7638\n",
            "====> Epoch: 4 Average val loss: -0.7862\n",
            "Min loss -0.79\n",
            "====> Epoch: 5 Average train loss: -0.9068\n",
            "====> Epoch: 5 Average val loss: -0.9084\n",
            "Min loss -0.91\n",
            "====> Epoch: 6 Average train loss: -1.0224\n",
            "====> Epoch: 6 Average val loss: -1.0031\n",
            "Min loss -1.00\n",
            "====> Epoch: 7 Average train loss: -1.1115\n",
            "====> Epoch: 7 Average val loss: -1.0742\n",
            "Min loss -1.07\n",
            "====> Epoch: 8 Average train loss: -1.1796\n",
            "====> Epoch: 8 Average val loss: -1.1283\n",
            "Min loss -1.13\n",
            "====> Epoch: 9 Average train loss: -1.2329\n",
            "====> Epoch: 9 Average val loss: -1.1703\n",
            "Min loss -1.17\n",
            "====> Epoch: 10 Average train loss: -1.2756\n",
            "====> Epoch: 10 Average val loss: -1.2039\n",
            "Min loss -1.20\n",
            "====> Epoch: 11 Average train loss: -1.3106\n",
            "====> Epoch: 11 Average val loss: -1.2314\n",
            "Min loss -1.23\n",
            "====> Epoch: 12 Average train loss: -1.3400\n",
            "====> Epoch: 12 Average val loss: -1.2540\n",
            "Min loss -1.25\n",
            "====> Epoch: 13 Average train loss: -1.3650\n",
            "====> Epoch: 13 Average val loss: -1.2726\n",
            "Min loss -1.27\n",
            "====> Epoch: 14 Average train loss: -1.3864\n",
            "====> Epoch: 14 Average val loss: -1.2878\n",
            "Min loss -1.29\n",
            "====> Epoch: 15 Average train loss: -1.4047\n",
            "====> Epoch: 15 Average val loss: -1.3003\n",
            "Min loss -1.30\n",
            "====> Epoch: 16 Average train loss: -1.4205\n",
            "====> Epoch: 16 Average val loss: -1.3105\n",
            "Min loss -1.31\n",
            "====> Epoch: 17 Average train loss: -1.4342\n",
            "====> Epoch: 17 Average val loss: -1.3187\n",
            "Min loss -1.32\n",
            "====> Epoch: 18 Average train loss: -1.4462\n",
            "====> Epoch: 18 Average val loss: -1.3256\n",
            "Min loss -1.33\n",
            "====> Epoch: 19 Average train loss: -1.4568\n",
            "====> Epoch: 19 Average val loss: -1.3314\n",
            "Min loss -1.33\n",
            "====> Epoch: 20 Average train loss: -1.4665\n",
            "====> Epoch: 20 Average val loss: -1.3366\n",
            "Min loss -1.34\n",
            "====> Epoch: 21 Average train loss: -1.4756\n",
            "====> Epoch: 21 Average val loss: -1.3414\n",
            "Min loss -1.34\n",
            "====> Epoch: 22 Average train loss: -1.4844\n",
            "====> Epoch: 22 Average val loss: -1.3461\n",
            "Min loss -1.35\n",
            "====> Epoch: 23 Average train loss: -1.4931\n",
            "====> Epoch: 23 Average val loss: -1.3507\n",
            "Min loss -1.35\n",
            "====> Epoch: 24 Average train loss: -1.5019\n",
            "====> Epoch: 24 Average val loss: -1.3553\n",
            "Min loss -1.36\n",
            "====> Epoch: 25 Average train loss: -1.5107\n",
            "====> Epoch: 25 Average val loss: -1.3598\n",
            "Min loss -1.36\n",
            "====> Epoch: 26 Average train loss: -1.5197\n",
            "====> Epoch: 26 Average val loss: -1.3643\n",
            "Min loss -1.36\n",
            "====> Epoch: 27 Average train loss: -1.5286\n",
            "====> Epoch: 27 Average val loss: -1.3685\n",
            "Min loss -1.37\n",
            "====> Epoch: 28 Average train loss: -1.5373\n",
            "====> Epoch: 28 Average val loss: -1.3724\n",
            "Min loss -1.37\n",
            "====> Epoch: 29 Average train loss: -1.5458\n",
            "====> Epoch: 29 Average val loss: -1.3761\n",
            "Min loss -1.38\n",
            "====> Epoch: 30 Average train loss: -1.5542\n",
            "====> Epoch: 30 Average val loss: -1.3796\n",
            "Min loss -1.38\n",
            "====> Epoch: 31 Average train loss: -1.5622\n",
            "====> Epoch: 31 Average val loss: -1.3828\n",
            "Min loss -1.38\n",
            "====> Epoch: 32 Average train loss: -1.5700\n",
            "====> Epoch: 32 Average val loss: -1.3857\n",
            "Min loss -1.39\n",
            "====> Epoch: 33 Average train loss: -1.5776\n",
            "====> Epoch: 33 Average val loss: -1.3885\n",
            "Min loss -1.39\n",
            "====> Epoch: 34 Average train loss: -1.5850\n",
            "====> Epoch: 34 Average val loss: -1.3911\n",
            "Min loss -1.39\n",
            "====> Epoch: 35 Average train loss: -1.5923\n",
            "====> Epoch: 35 Average val loss: -1.3936\n",
            "Min loss -1.39\n",
            "====> Epoch: 36 Average train loss: -1.5995\n",
            "====> Epoch: 36 Average val loss: -1.3959\n",
            "Min loss -1.40\n",
            "====> Epoch: 37 Average train loss: -1.6066\n",
            "====> Epoch: 37 Average val loss: -1.3980\n",
            "Min loss -1.40\n",
            "====> Epoch: 38 Average train loss: -1.6137\n",
            "====> Epoch: 38 Average val loss: -1.4000\n",
            "Min loss -1.40\n",
            "====> Epoch: 39 Average train loss: -1.6207\n",
            "====> Epoch: 39 Average val loss: -1.4017\n",
            "Min loss -1.40\n",
            "====> Epoch: 40 Average train loss: -1.6277\n",
            "====> Epoch: 40 Average val loss: -1.4030\n",
            "Min loss -1.40\n",
            "====> Epoch: 41 Average train loss: -1.6346\n",
            "====> Epoch: 41 Average val loss: -1.4042\n",
            "Min loss -1.40\n",
            "====> Epoch: 42 Average train loss: -1.6414\n",
            "====> Epoch: 42 Average val loss: -1.4050\n",
            "Min loss -1.41\n",
            "====> Epoch: 43 Average train loss: -1.6481\n",
            "====> Epoch: 43 Average val loss: -1.4056\n",
            "Min loss -1.41\n",
            "====> Epoch: 44 Average train loss: -1.6545\n",
            "====> Epoch: 44 Average val loss: -1.4061\n",
            "Min loss -1.41\n",
            "====> Epoch: 45 Average train loss: -1.6608\n",
            "====> Epoch: 45 Average val loss: -1.4064\n",
            "Min loss -1.41\n",
            "====> Epoch: 46 Average train loss: -1.6668\n",
            "====> Epoch: 46 Average val loss: -1.4065\n",
            "Min loss -1.41\n",
            "====> Epoch: 47 Average train loss: -1.6727\n",
            "====> Epoch: 47 Average val loss: -1.4065\n",
            "====> Epoch: 48 Average train loss: -1.6784\n",
            "====> Epoch: 48 Average val loss: -1.4063\n",
            "====> Epoch: 49 Average train loss: -1.6840\n",
            "====> Epoch: 49 Average val loss: -1.4060\n",
            "====> Epoch: 50 Average train loss: -1.6895\n",
            "====> Epoch: 50 Average val loss: -1.4056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhYAL8vxkiAh"
      },
      "source": [
        "# Generate Some Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNeUaqjwhcj7"
      },
      "source": [
        "\"\"\"\r\n",
        "### Make results plot to compare methods\r\n",
        "\"\"\"\r\n",
        "# %%\r\n",
        "\r\n",
        "all_results = np.stack(\r\n",
        "    [linear_cca_results, gcca_results, mcca_results, pls_results, pmd_results, elastic_results,\r\n",
        "     scca_results, kernel_reg_results, kernel_poly_results,\r\n",
        "     kernel_gaussian_results, dcca_results, dgcca_results, dmcca_results, dccae_results, dvcca_model_results,\r\n",
        "     dcca_conv_results],\r\n",
        "    axis=0)\r\n",
        "all_labels = ['linear', 'gcca', 'mcca', 'pls', 'pmd', 'elastic', 'scca', 'linear kernel', 'polynomial kernel',\r\n",
        "              'gaussian kernel', 'deep CCA', 'deep generalized CCA', 'deep multiset CCA', 'deep CCAE', 'deep VCCA',\r\n",
        "              'deep convolutional cca']\r\n",
        "\r\n",
        "from cca_zoo import plot_utils\r\n",
        "\r\n",
        "plot_utils.plot_results(all_results, all_labels)\r\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": []
    }
  ]
}