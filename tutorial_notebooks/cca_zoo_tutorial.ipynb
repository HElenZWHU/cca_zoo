{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/jameschapman19/cca_zoo/blob/master/tutorial_notebooks/cca_zoo_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# A tutorial comparing the train and test correlations of different models on MNIST data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install cca-zoo[deep,probabilistic]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from cca_zoo.data import Noisy_MNIST_Dataset\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Subset\n",
    "from torch import optim\n",
    "from cca_zoo.deepmodels import objectives, architectures, DeepWrapper, DCCA,DCCA_NOI,DVCCA,DCCAE,DTCCA\n",
    "\n",
    "# Load MNIST Data\n",
    "N = 500\n",
    "dataset = Noisy_MNIST_Dataset(mnist_type='FashionMNIST', train=True)\n",
    "ids = np.arange(min(2 * N, len(dataset)))\n",
    "np.random.shuffle(ids)\n",
    "train_ids, val_ids = np.array_split(ids, 2)\n",
    "val_dataset = Subset(dataset, val_ids)\n",
    "train_dataset = Subset(dataset, train_ids)\n",
    "test_dataset = Noisy_MNIST_Dataset(mnist_type='FashionMNIST', train=False)\n",
    "test_ids = np.arange(min(N, len(test_dataset)))\n",
    "np.random.shuffle(test_ids)\n",
    "test_dataset = Subset(test_dataset, test_ids)\n",
    "train_view_1, train_view_2, train_rotations, train_OH_labels, train_labels = train_dataset.dataset.to_numpy(\n",
    "    train_dataset.indices)\n",
    "val_view_1, val_view_2, val_rotations, val_OH_labels, val_labels = val_dataset.dataset.to_numpy(val_dataset.indices)\n",
    "test_view_1, test_view_2, test_rotations, test_OH_labels, test_labels = test_dataset.dataset.to_numpy(\n",
    "    test_dataset.indices)\n",
    "\n",
    "# Settings\n",
    "\n",
    "# The number of latent dimensions across models\n",
    "latent_dims = 2\n",
    "# The number of folds used for cross-validation/hyperparameter tuning\n",
    "cv_folds = 5\n",
    "# For running hyperparameter tuning in parallel (0 if not)\n",
    "jobs = 2\n",
    "# Number of iterations for iterative algorithms\n",
    "max_iter = 2\n",
    "# number of epochs for deep models\n",
    "epochs = 50"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Canonical Correlation Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from cca_zoo.models import CCA, CCA_ALS\n",
    "\"\"\"\n",
    "### Linear CCA by eigendecomposition\n",
    "\"\"\"\n",
    "linear_cca = CCA(latent_dims=latent_dims)\n",
    "\n",
    "linear_cca.fit(train_view_1, train_view_2)\n",
    "\n",
    "linear_cca_results = np.stack(\n",
    "    (linear_cca.score(train_view_1, train_view_2), linear_cca.score(test_view_1, test_view_2)))\n",
    "\n",
    "\"\"\"\n",
    "### Linear CCA by alternating least squares (can pass more than 2 views)\n",
    "\"\"\"\n",
    "\n",
    "linear_cca_als = CCA_ALS(latent_dims=latent_dims)\n",
    "\n",
    "linear_cca_als.fit(train_view_1, train_view_2)\n",
    "\n",
    "linear_cca_als_results = np.stack(\n",
    "    (linear_cca_als.score(train_view_1, train_view_2), linear_cca_als.score(test_view_1, test_view_2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Partial Least Squares\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from cca_zoo.models import PLS\n",
    "\"\"\"\n",
    "### PLS with scikit-learn (only permits 2 views)\n",
    "\"\"\"\n",
    "pls = PLS(latent_dims=latent_dims)\n",
    "\n",
    "pls.fit(train_view_1, train_view_2)\n",
    "\n",
    "pls_results = np.stack(\n",
    "    (pls.score(train_view_1, train_view_2), pls.score(test_view_1, test_view_2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extension to multiple views\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from cca_zoo.models import GCCA, MCCA\n",
    "\"\"\"\n",
    "### (Regularized) Generalized CCA(can pass more than 2 views)\n",
    "\"\"\"\n",
    "train_view_3=train_view_1+np.random.rand(train_view_1.shape)\n",
    "test_view_3=test_view_1+np.random.rand(test_view_1.shape)\n",
    "\n",
    "# small ammount of regularisation added since data is not full rank\n",
    "c=[0.5,0.5,0.5]\n",
    "\n",
    "gcca = GCCA(latent_dims=latent_dims,c=c)\n",
    "\n",
    "gcca.fit(train_view_1, train_view_2,train_view_3)\n",
    "\n",
    "gcca_results = np.stack((gcca.score(train_view_1, train_view_2, train_view_3), gcca.score(test_view_1, test_view_2, test_view_3)))\n",
    "\n",
    "\"\"\"\n",
    "### (Regularized) Multiset CCA(can pass more than 2 views)\n",
    "\"\"\"\n",
    "\n",
    "mcca = MCCA(latent_dims=latent_dims, c=c)\n",
    "\n",
    "mcca.fit(train_view_1, train_view_2,train_view_1)\n",
    "\n",
    "mcca_results = np.stack((mcca.score(train_view_1, train_view_2, train_view_3), mcca.score(test_view_1, test_view_2, test_view_3)))\n",
    "\n",
    "\"\"\"\n",
    "### Multiset CCA by alternating least squares\n",
    "\"\"\"\n",
    "mcca_als = CCA_ALS(latent_dims=latent_dims, max_iter=max_iter)\n",
    "\n",
    "mcca_als.fit(train_view_1, train_view_2,train_view_3)\n",
    "\n",
    "mcca_als_results = np.stack(\n",
    "    (mcca_als.score(train_view_1, train_view_2, train_view_3), mcca_als.score(test_view_1, test_view_2, test_view_3)))\n",
    "\n",
    "\"\"\"\n",
    "### Multiset PLS by alternating least squares\n",
    "\"\"\"\n",
    "mcca_pls = PLS(latent_dims=latent_dims, max_iter=max_iter)\n",
    "\n",
    "mcca_pls.fit(train_view_1, train_view_2,train_view_1)\n",
    "\n",
    "mcca_pls_results = np.stack(\n",
    "    (mcca_als.score(train_view_1, train_view_2, train_view_3), mcca_pls.score(test_view_1, test_view_2, test_view_3)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tensor CCA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from cca_zoo.models import TCCA\n",
    "\"\"\"\n",
    "### (Regularized) Tensor CCA(can pass more than 2 views)\n",
    "\"\"\"\n",
    "\n",
    "tcca = TCCA(latent_dims=latent_dims, c=c)\n",
    "\n",
    "#memory requirement for tensor is massive so take first 100 features\n",
    "tcca.fit(train_view_1[:,:100], train_view_2[:,:100],train_view_3[:,:100])\n",
    "\n",
    "tcca_results = np.stack((tcca.score(train_view_1[:,:100], train_view_2[:,:100], train_view_3[:,:100]), tcca.score(test_view_1[:,:100], test_view_2[:,:100], test_view_3[:,:100])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Weighted GCCA/Missing Observation GCCA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#observation_matrix\n",
    "K = np.ones((3, N))\n",
    "K[0, 200:] = 0\n",
    "K[1, :100] = 0\n",
    "\n",
    "#view weights\n",
    "view_weights=[1,2,1.2]\n",
    "\n",
    "c=[0.5,0.5,0.5]\n",
    "\n",
    "gcca = GCCA(latent_dims=latent_dims,c=c,view_weights=view_weights)\n",
    "\n",
    "gcca.fit(train_view_1, train_view_2,train_view_1,K=K)\n",
    "\n",
    "gcca_results = np.stack((gcca.score(train_view_1, train_view_2), gcca.score(test_view_1, test_view_2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Rgularised CCA solutions based on alternating minimisation/alternating least squares\n",
    "\n",
    "We implement Witten's penalized matrix decomposition form of sparse CCA using 'pmd'\n",
    "\n",
    "We implement Waaijenborg's penalized CCA using elastic net using 'elastic'\n",
    "\n",
    "We implement Mai's sparse CCA using 'scca'\n",
    "\n",
    "Furthermore, any of these methods can be extended to multiple views. Witten describes this method explicitly."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from cca_zoo.models import rCCA, PMD,SCCA,ElasticCCA\n",
    "\"\"\"\n",
    "### Ridge CCA (can pass more than 2 views)\n",
    "\"\"\"\n",
    "c1 = [0.1, 0.3, 0.7, 0.9]\n",
    "c2 = [0.1, 0.3, 0.7, 0.9]\n",
    "param_candidates = {'c': list(itertools.product(c1, c2))}\n",
    "\n",
    "ridge = rCCA(latent_dims=latent_dims).gridsearch_fit(\n",
    "    train_view_1,\n",
    "    train_view_2,\n",
    "    param_candidates=param_candidates,\n",
    "    folds=cv_folds,\n",
    "    verbose=True, jobs=jobs,\n",
    "    plot=True)\n",
    "\n",
    "ridge_results = np.stack((ridge.score(train_view_1,train_view_2), ridge.score(test_view_1, test_view_2)))\n",
    "\n",
    "\"\"\"\n",
    "### Sparse CCA (Penalized Matrix Decomposition) (can pass more than 2 views)\n",
    "\"\"\"\n",
    "\n",
    "# PMD\n",
    "c1 = [1, 3, 7, 9]\n",
    "c2 = [1, 3, 7, 9]\n",
    "param_candidates = {'c': list(itertools.product(c1, c2))}\n",
    "\n",
    "pmd = PMD(latent_dims=latent_dims, max_iter=max_iter).gridsearch_fit(\n",
    "    train_view_1,\n",
    "    train_view_2,\n",
    "    param_candidates=param_candidates,\n",
    "    folds=cv_folds,\n",
    "    verbose=True, jobs=jobs,\n",
    "    plot=True)\n",
    "\n",
    "pmd_results = np.stack((pmd.score(train_view_1,train_view_2), pmd.score(test_view_1, test_view_2)))\n",
    "\n",
    "\"\"\"\n",
    "### Sparse CCA (can pass more than 2 views)\n",
    "\"\"\"\n",
    "\n",
    "# Sparse CCA\n",
    "c1 = [0.00001, 0.0001]\n",
    "c2 = [0.00001, 0.0001]\n",
    "param_candidates = {'c': list(itertools.product(c1, c2))}\n",
    "\n",
    "scca = SCCA(latent_dims=latent_dims, max_iter=max_iter).gridsearch_fit(\n",
    "    train_view_1,\n",
    "    train_view_2,\n",
    "    param_candidates=param_candidates,\n",
    "    folds=cv_folds,\n",
    "    verbose=True,\n",
    "    jobs=jobs, plot=True)\n",
    "\n",
    "scca_results = np.stack(\n",
    "    (scca.score(train_view_1,train_view_2), scca.score(test_view_1, test_view_2)))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "### Elastic CCA (can pass more than 2 views)\n",
    "\"\"\"\n",
    "\n",
    "# Elastic CCA\n",
    "c1 = [0.001, 0.0001]\n",
    "c2 = [0.001, 0.0001]\n",
    "l1_1 = [0.01, 0.1]\n",
    "l1_2 = [0.01, 0.1]\n",
    "param_candidates = {'c': list(itertools.product(c1, c2)), 'l1_ratio': list(itertools.product(l1_1, l1_2))}\n",
    "\n",
    "elastic = ElasticCCA(latent_dims=latent_dims,\n",
    "                              max_iter=max_iter).gridsearch_fit(train_view_1,\n",
    "                                                                train_view_2,\n",
    "                                                                param_candidates=param_candidates,\n",
    "                                                                folds=cv_folds,\n",
    "                                                                verbose=True,\n",
    "                                                                jobs=jobs,\n",
    "                                                                plot=True)\n",
    "\n",
    "elastic_results = np.stack(\n",
    "    (elastic.score(train_view_1,train_view_2), elastic.score(test_view_1, test_view_2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Kernel CCA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from cca_zoo.models import KCCA\n",
    "\"\"\"\n",
    "### Kernel CCA\n",
    "\n",
    "Similarly, we can use kernel CCA methods with [method='kernel']\n",
    "\n",
    "We can use different kernels and their associated parameters in a similar manner to before\n",
    "- regularized linear kernel CCA: parameters :  'kernel'='linear', 0<'c'<1\n",
    "- polynomial kernel CCA: parameters : 'kernel'='poly', 'degree', 0<'c'<1\n",
    "- gaussian rbf kernel CCA: parameters : 'kernel'='gaussian', 'sigma', 0<'c'<1\n",
    "\"\"\"\n",
    "# %%\n",
    "# r-kernel cca\n",
    "c1 = [0.9, 0.99]\n",
    "c2 = [0.9, 0.99]\n",
    "\n",
    "param_candidates = {'kernel': [['linear', 'linear']], 'c': list(itertools.product(c1, c2))}\n",
    "\n",
    "kernel_reg = KCCA(latent_dims=latent_dims).gridsearch_fit(train_view_1, train_view_2,\n",
    "                                                          folds=cv_folds,\n",
    "                                                          param_candidates=param_candidates,\n",
    "                                                          verbose=True, jobs=jobs,\n",
    "                                                          plot=True)\n",
    "kernel_reg_results = np.stack((\n",
    "    kernel_reg.score(train_view_1,train_view_2),\n",
    "    kernel_reg.score(test_view_1, test_view_2)[0, 1, :]))\n",
    "\n",
    "# kernel cca (poly)\n",
    "degree1 = [2, 3]\n",
    "degree2 = [2, 3]\n",
    "\n",
    "param_candidates = {'kernel': [['poly', 'poly']], 'degree': list(itertools.product(degree1, degree2)),\n",
    "                    'c': list(itertools.product(c1, c2))}\n",
    "\n",
    "kernel_poly = KCCA(latent_dims=latent_dims).gridsearch_fit(train_view_1, train_view_2,\n",
    "                                                           folds=cv_folds,\n",
    "                                                           param_candidates=param_candidates,\n",
    "                                                           verbose=True, jobs=jobs,\n",
    "                                                           plot=True)\n",
    "\n",
    "kernel_poly_results = np.stack((\n",
    "    kernel_poly.score(train_view_1,train_view_2),\n",
    "    kernel_poly.score(test_view_1, test_view_2)[0, 1, :]))\n",
    "\n",
    "# kernel cca (gaussian)\n",
    "gamma1 = [1e+1, 1e+2, 1e+3]\n",
    "gamma2 = [1e+1, 1e+2, 1e+3]\n",
    "\n",
    "param_candidates = {'kernel': [['rbf', 'rbf']], 'gamma': list(itertools.product(gamma1, gamma2)),\n",
    "                    'c': list(itertools.product(c1, c2))}\n",
    "\n",
    "kernel_gaussian = KCCA(latent_dims=latent_dims).gridsearch_fit(train_view_1, train_view_2,\n",
    "                                                               folds=cv_folds,\n",
    "                                                               param_candidates=param_candidates,\n",
    "                                                               verbose=True, jobs=jobs,\n",
    "                                                               plot=True)\n",
    "\n",
    "kernel_gaussian_results = np.stack((\n",
    "    kernel_gaussian.score(train_view_1,train_view_2),\n",
    "    kernel_gaussian.score(test_view_1, test_view_2)[0, 1, :]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Deep CCA\n",
    "\n",
    "DCCA can be optimized using Andrew's original tracenorm objective or Wang's DCCA by nonlinear orthogonal iterations using the argument als=True."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### Deep Learning\n",
    "\n",
    "We also have deep CCA methods (and autoencoder variants)\n",
    "- Deep CCA (DCCA)\n",
    "- Deep Canonically Correlated Autoencoders (DCCAE)\n",
    "\n",
    "We introduce a Config class from configuration.py. This contains a number of default settings for running\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# DCCA\n",
    "print('DCCA')\n",
    "encoder_1 = architectures.Encoder(latent_dims=latent_dims, feature_size=784)\n",
    "encoder_2 = architectures.Encoder(latent_dims=latent_dims, feature_size=784)\n",
    "dcca_model = DCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2])\n",
    "\n",
    "dcca_model = DeepWrapper(dcca_model)\n",
    "\n",
    "dcca_model.fit(train_dataset, val_dataset=val_dataset, epochs=epochs)\n",
    "\n",
    "dcca_results = np.stack((dcca_model.score(train_dataset), dcca_model.score(test_dataset)))\n",
    "\n",
    "# DCCA_NOI\n",
    "print('DCCA by non-linear orthogonal iterations')\n",
    "encoder_1 = architectures.Encoder(latent_dims=latent_dims, feature_size=784)\n",
    "encoder_2 = architectures.Encoder(latent_dims=latent_dims, feature_size=784)\n",
    "dcca_noi_model = DCCA_NOI(latent_dims=latent_dims, encoders=[encoder_1, encoder_2])\n",
    "\n",
    "dcca_noi_model = DeepWrapper(dcca_noi_model)\n",
    "\n",
    "dcca_noi_model.fit(train_dataset, val_dataset=val_dataset, epochs=epochs)\n",
    "\n",
    "dcca_noi_results = np.stack(\n",
    "    (dcca_noi_model.score(train_dataset), dcca_noi_model.score(test_dataset)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DCCA with custom optimizers and schedulers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# DCCA\n",
    "dcca_model = DCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2],\n",
    "                                objective=objectives.CCA)\n",
    "optimizer = optim.Adam(dcca_model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 1)\n",
    "# hidden_layer_sizes are shown explicitly but these are also the defaults\n",
    "dcca_model = DeepWrapper(dcca_model)\n",
    "dcca_model.fit(train_dataset, val_dataset=val_dataset,epochs=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DGCCA and DMCCA for more than 2 views\n",
    "\n",
    "The only change we need to make is to the objective argument to perform DGCCA and DMCCA."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# DGCCA\n",
    "print('DGCCA')\n",
    "encoder_1 = architectures.Encoder(latent_dims=latent_dims, feature_size=784)\n",
    "encoder_2 = architectures.Encoder(latent_dims=latent_dims, feature_size=784)\n",
    "dgcca_model = DCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2], objective=objectives.GCCA)\n",
    "\n",
    "dgcca_model = DeepWrapper(dgcca_model)\n",
    "\n",
    "dgcca_model.fit(train_dataset, val_dataset=val_dataset, epochs=epochs)\n",
    "\n",
    "dgcca_results = np.stack(\n",
    "    (dgcca_model.score(train_dataset), dgcca_model.score(test_dataset)))\n",
    "\n",
    "# DMCCA\n",
    "print('DMCCA')\n",
    "encoder_1 = architectures.Encoder(latent_dims=latent_dims, feature_size=784)\n",
    "encoder_2 = architectures.Encoder(latent_dims=latent_dims, feature_size=784)\n",
    "dmcca_model = DCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2], objective=objectives.MCCA)\n",
    "\n",
    "dmcca_model = DeepWrapper(dmcca_model)\n",
    "\n",
    "dmcca_model.fit(train_dataset, val_dataset=val_dataset, epochs=epochs)\n",
    "\n",
    "dmcca_results = np.stack(\n",
    "    (dmcca_model.score(train_dataset), dmcca_model.score(test_dataset)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Deep Canonically Correlated Autoencoders\n",
    "We need to add decoders in order to model deep canonically correlated autoencoders and we also use the DCCAE class which inherits from DCCA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# DCCAE\n",
    "print('DCCAE')\n",
    "encoder_1 = architectures.Encoder(latent_dims=latent_dims, feature_size=784)\n",
    "encoder_2 = architectures.Encoder(latent_dims=latent_dims, feature_size=784)\n",
    "decoder_1 = architectures.Decoder(latent_dims=latent_dims, feature_size=784)\n",
    "decoder_2 = architectures.Decoder(latent_dims=latent_dims, feature_size=784)\n",
    "dccae_model = DCCAE(latent_dims=latent_dims, encoders=[encoder_1, encoder_2], decoders=[decoder_1, decoder_2])\n",
    "\n",
    "dccae_model = DeepWrapper(dccae_model)\n",
    "\n",
    "#can also pass a tuple of numpy arrays\n",
    "dccae_model.fit((train_view_1, train_view_2), epochs=epochs)\n",
    "\n",
    "dccae_results = np.stack(\n",
    "    (dccae_model.score(train_dataset), dccae_model.score(test_dataset)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Deep Variational CCA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### Deep Variational Learning\n",
    "Finally we have Deep Variational CCA methods.\n",
    "- Deep Variational CCA (DVCCA)\n",
    "- Deep Variational CCA - private (DVVCA_p)\n",
    "\n",
    "These are both implemented by the DVCCA class with private=True/False and both_encoders=True/False. If both_encoders,\n",
    "the encoder to the shared information Q(z_shared|x) is modelled for both x_1 and x_2 whereas if both_encoders is false\n",
    "it is modelled for x_1 as in the paper\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# DVCCA (technically bi-DVCCA)\n",
    "print('DVCCA')\n",
    "encoder_1 = architectures.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\n",
    "encoder_2 = architectures.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\n",
    "decoder_1 = architectures.Decoder(latent_dims=latent_dims, feature_size=784, norm_output=True)\n",
    "decoder_2 = architectures.Decoder(latent_dims=latent_dims, feature_size=784, norm_output=True)\n",
    "dvcca_model = DVCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2], decoders=[decoder_1, decoder_2])\n",
    "\n",
    "dvcca_model = DeepWrapper(dvcca_model)\n",
    "\n",
    "dvcca_model.fit(train_dataset, val_dataset=val_dataset, epochs=epochs)\n",
    "\n",
    "dvcca_model_results = np.stack(\n",
    "    (dvcca_model.score(train_dataset), dvcca_model.score(test_dataset)))\n",
    "\n",
    "# DVCCA_private (technically bi-DVCCA_private)\n",
    "print('DVCCA_private')\n",
    "encoder_1 = architectures.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\n",
    "encoder_2 = architectures.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\n",
    "private_encoder_1 = architectures.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\n",
    "private_encoder_2 = architectures.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\n",
    "decoder_1 = architectures.Decoder(latent_dims=latent_dims * 2, feature_size=784, norm_output=True)\n",
    "decoder_2 = architectures.Decoder(latent_dims=latent_dims * 2, feature_size=784, norm_output=True)\n",
    "dvccap_model = DVCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2], decoders=[decoder_1, decoder_2],\n",
    "                           private_encoders=[private_encoder_1, private_encoder_2])\n",
    "\n",
    "dvccap_model = DeepWrapper(dvccap_model)\n",
    "\n",
    "dvccap_model.fit(train_dataset, val_dataset=val_dataset, epochs=epochs)\n",
    "\n",
    "dvccap_model_results = np.stack(\n",
    "    (dvccap_model.score(train_dataset), dvccap_model.score(test_dataset)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convolutional Deep CCA (and using other architectures)\n",
    "We provide a standard CNN encoder and decoder but users can build their own encoders and decoders by inheriting BaseEncoder and BaseDecoder for seamless integration with the pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Convolutional DCCA')\n",
    "encoder_1 = architectures.CNNEncoder(latent_dims=latent_dims, channels=[3, 3])\n",
    "encoder_2 = architectures.CNNEncoder(latent_dims=latent_dims, channels=[3, 3])\n",
    "dcca_conv_model = DCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2])\n",
    "\n",
    "dcca_conv_model = DeepWrapper(dcca_conv_model)\n",
    "\n",
    "# to change the models used change the cfg.encoder_models. We implement a CNN_Encoder and CNN_decoder as well\n",
    "# as some based on brainnet architecture in cca_zoo.architectures. Equally you could pass your own encoder/decoder models\n",
    "\n",
    "dcca_conv_model.fit((train_view_1.reshape((-1, 1, 28, 28)), train_view_2.reshape((-1, 1, 28, 28))), epochs=epochs)\n",
    "\n",
    "dcca_conv_results = np.stack(\n",
    "    (dcca_conv_model.score((test_view_1.reshape((-1, 1, 28, 28)),test_view_2.reshape((-1, 1, 28, 28))), dcca_conv_model.score((test_view_1.reshape((-1, 1, 28, 28)),test_view_2.reshape((-1, 1, 28, 28)))))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DTCCA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %%\n",
    "# DTCCA\n",
    "print('DTCCA')\n",
    "encoder_1 = architectures.Encoder(latent_dims=latent_dims, feature_size=784)\n",
    "encoder_2 = architectures.Encoder(latent_dims=latent_dims, feature_size=784)\n",
    "dtcca_model = DTCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2])\n",
    "\n",
    "dtcca_model = DeepWrapper(dtcca_model)\n",
    "\n",
    "dtcca_model.fit(train_dataset, val_dataset=val_dataset, epochs=epochs)\n",
    "\n",
    "dtcca_results = np.stack((dtcca_model.score(train_dataset), dtcca_model.score(test_dataset)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate Some Plots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### Make results plot to compare methods\n",
    "\"\"\"\n",
    "# %%\n",
    "\n",
    "all_results = np.stack(\n",
    "    [linear_cca_results, gcca_results, mcca_results, pls_results, pmd_results, elastic_results,\n",
    "     scca_results, kernel_reg_results, kernel_poly_results,\n",
    "     kernel_gaussian_results, dcca_results, dgcca_results, dmcca_results, dvcca_model_results,\n",
    "     dcca_conv_results, dtcca_results],\n",
    "    axis=0)\n",
    "all_labels = ['linear', 'gcca', 'mcca', 'pls', 'pmd', 'elastic', 'scca', 'linear kernel', 'polynomial kernel',\n",
    "              'gaussian kernel', 'deep CCA', 'deep generalized CCA', 'deep multiset CCA', 'deep VCCA',\n",
    "              'deep convolutional cca', 'DTCCA']\n",
    "\n",
    "from cca_zoo.utils import plot_utils\n",
    "\n",
    "plot_utils.plot_results(all_results, all_labels)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}