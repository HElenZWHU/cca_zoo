{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "name": "cca_zoo_tutorial.ipynb",
   "provenance": [],
   "include_colab_link": true
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jameschapman19/cca_zoo/blob/main/tutorial_notebooks/cca_zoo_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "wR3y1wFxvLTg"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jameschapman19/cca_zoo/blob/master/tutorial_notebooks/cca_zoo_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "Gn1KbNv1vLTj"
   },
   "source": [
    "# A tutorial comparing the train and test correlations of different models on MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "gYoDpAd1vLTk",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3e927908-a3b5-4e5a-bce3-d807688c7a9a"
   },
   "source": [
    "!pip install --upgrade cca-zoo[deep,probabilistic]"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: cca-zoo[deep,probabilistic] in /usr/local/lib/python3.7/dist-packages (1.8.0)\n",
      "Requirement already satisfied: mvlearn in /usr/local/lib/python3.7/dist-packages (from cca-zoo[deep,probabilistic]) (0.4.1)\n",
      "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.7/dist-packages (from cca-zoo[deep,probabilistic]) (1.7.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from cca-zoo[deep,probabilistic]) (3.2.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from cca-zoo[deep,probabilistic]) (1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from cca-zoo[deep,probabilistic]) (1.19.5)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from cca-zoo[deep,probabilistic]) (0.11.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from cca-zoo[deep,probabilistic]) (1.1.5)\n",
      "Requirement already satisfied: tensorly in /usr/local/lib/python3.7/dist-packages (from cca-zoo[deep,probabilistic]) (0.6.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from cca-zoo[deep,probabilistic]) (1.0.1)\n",
      "Requirement already satisfied: jax~=0.2.20 in /usr/local/lib/python3.7/dist-packages (from cca-zoo[deep,probabilistic]) (0.2.20)\n",
      "Requirement already satisfied: arviz in /usr/local/lib/python3.7/dist-packages (from cca-zoo[deep,probabilistic]) (0.11.2)\n",
      "Requirement already satisfied: numpyro in /usr/local/lib/python3.7/dist-packages (from cca-zoo[deep,probabilistic]) (0.8.0)\n",
      "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from cca-zoo[deep,probabilistic]) (1.9.0+cu102)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from cca-zoo[deep,probabilistic]) (0.10.0+cu102)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from cca-zoo[deep,probabilistic]) (7.1.2)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax~=0.2.20->cca-zoo[deep,probabilistic]) (0.12.0)\n",
      "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax~=0.2.20->cca-zoo[deep,probabilistic]) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.9.0->cca-zoo[deep,probabilistic]) (3.7.4.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->jax~=0.2.20->cca-zoo[deep,probabilistic]) (1.15.0)\n",
      "Requirement already satisfied: xarray>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from arviz->cca-zoo[deep,probabilistic]) (0.18.2)\n",
      "Requirement already satisfied: netcdf4 in /usr/local/lib/python3.7/dist-packages (from arviz->cca-zoo[deep,probabilistic]) (1.5.7)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from arviz->cca-zoo[deep,probabilistic]) (21.0)\n",
      "Requirement already satisfied: setuptools>=38.4 in /usr/local/lib/python3.7/dist-packages (from arviz->cca-zoo[deep,probabilistic]) (57.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cca-zoo[deep,probabilistic]) (1.3.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cca-zoo[deep,probabilistic]) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cca-zoo[deep,probabilistic]) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cca-zoo[deep,probabilistic]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->cca-zoo[deep,probabilistic]) (2018.9)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->cca-zoo[deep,probabilistic]) (2.2.0)\n",
      "Requirement already satisfied: cftime in /usr/local/lib/python3.7/dist-packages (from netcdf4->arviz->cca-zoo[deep,probabilistic]) (1.5.0)\n",
      "Requirement already satisfied: jaxlib>=0.1.65 in /usr/local/lib/python3.7/dist-packages (from numpyro->cca-zoo[deep,probabilistic]) (0.1.71+cuda111)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from numpyro->cca-zoo[deep,probabilistic]) (4.62.2)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.65->numpyro->cca-zoo[deep,probabilistic]) (1.12)\n",
      "Requirement already satisfied: nose in /usr/local/lib/python3.7/dist-packages (from tensorly->cca-zoo[deep,probabilistic]) (1.3.7)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "O5VEWk1BvLTl",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5870455a-2f40-40ec-8878-6ecc9d9e2a89"
   },
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from cca_zoo.data import Noisy_MNIST_Dataset, CCA_Dataset\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from torch import optim\n",
    "from cca_zoo.deepmodels import objectives, architectures, CCALightning, DCCA,DCCA_NOI,DVCCA,DCCAE,DTCCA, get_dataloaders\n",
    "from sklearn.utils.fixes import loguniform\n",
    "import pytorch_lightning as pl\n",
    "# Load MNIST Data\n",
    "N = 500\n",
    "dataset = Noisy_MNIST_Dataset(mnist_type='FashionMNIST', train=True)\n",
    "ids = np.arange(min(2 * N, len(dataset)))\n",
    "np.random.shuffle(ids)\n",
    "train_ids, val_ids = np.array_split(ids, 2)\n",
    "val_dataset = Subset(dataset, val_ids)\n",
    "train_dataset = Subset(dataset, train_ids)\n",
    "test_dataset = Noisy_MNIST_Dataset(mnist_type='FashionMNIST', train=False)\n",
    "test_ids = np.arange(min(N, len(test_dataset)))\n",
    "np.random.shuffle(test_ids)\n",
    "test_dataset = Subset(test_dataset, test_ids)\n",
    "(train_view_1, train_view_2),_ = train_dataset.dataset.to_numpy(\n",
    "    train_dataset.indices)\n",
    "(val_view_1, val_view_2),_ = val_dataset.dataset.to_numpy(val_dataset.indices)\n",
    "(test_view_1, test_view_2),_ = test_dataset.dataset.to_numpy(\n",
    "    test_dataset.indices)\n",
    "train_loader, val_loader = get_dataloaders(train_dataset, val_dataset)\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset))\n",
    "# Settings\n",
    "\n",
    "# The number of latent dimensions across models\n",
    "latent_dims = 2\n",
    "# The number of cv used for cross-validation/hyperparameter tuning\n",
    "cv = 3\n",
    "# For running hyperparameter tuning in parallel (0 if not)\n",
    "jobs = 4\n",
    "# Number of iterations for iterative algorithms\n",
    "max_iter = 2\n",
    "# number of epochs for deep models\n",
    "epochs = 50"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "C97m5-5tvLTn"
   },
   "source": [
    "# Canonical Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "gKYi0wtkvLTn"
   },
   "source": [
    "from cca_zoo.models import CCA, CCA_ALS\n",
    "\"\"\"\n",
    "### Linear CCA by eigendecomposition\n",
    "\"\"\"\n",
    "linear_cca = CCA(latent_dims=latent_dims)\n",
    "\n",
    "linear_cca.fit((train_view_1, train_view_2))\n",
    "\n",
    "linear_cca_results = np.stack(\n",
    "    (linear_cca.score((train_view_1, train_view_2)), linear_cca.score((test_view_1, test_view_2))))\n",
    "\n",
    "\"\"\"\n",
    "### Linear CCA by alternating least squares (can pass more than 2 views)\n",
    "\"\"\"\n",
    "\n",
    "linear_cca_als = CCA_ALS(latent_dims=latent_dims)\n",
    "\n",
    "linear_cca_als.fit((train_view_1, train_view_2))\n",
    "\n",
    "linear_cca_als_results = np.stack(\n",
    "    (linear_cca_als.score((train_view_1, train_view_2)), linear_cca_als.score((test_view_1, test_view_2))))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "OeqtGYW6vLTo"
   },
   "source": [
    "# Partial Least Squares\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "-Z4jHKvovLTp"
   },
   "source": [
    "from cca_zoo.models import PLS, PLS_ALS\n",
    "\"\"\"\n",
    "### PLS (2 views)\n",
    "\"\"\"\n",
    "pls = PLS(latent_dims=latent_dims)\n",
    "\n",
    "pls.fit((train_view_1, train_view_2))\n",
    "\n",
    "pls_results = np.stack(\n",
    "    (pls.score((train_view_1, train_view_2)), pls.score((test_view_1, test_view_2))))\n",
    "\n",
    "pls_als = PLS_ALS(latent_dims=latent_dims)\n",
    "\n",
    "pls_als.fit((train_view_1, train_view_2))\n",
    "\n",
    "pls_als_results = np.stack(\n",
    "    (pls_als.score((train_view_1, train_view_2)), pls_als.score((test_view_1, test_view_2))))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "thDJioUZvLTp"
   },
   "source": [
    "# Extension to multiple views\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "CYTlHO8qvLTq",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7f043566-28b6-4a0c-91ea-bd4efb9083f1"
   },
   "source": [
    "from cca_zoo.models import GCCA, MCCA, PLS_ALS\n",
    "\"\"\"\n",
    "### (Regularized) Generalized CCA(can pass more than 2 views)\n",
    "\"\"\"\n",
    "train_view_3=train_view_1+np.random.rand(*train_view_1.shape)\n",
    "test_view_3=test_view_1+np.random.rand(*test_view_1.shape)\n",
    "\n",
    "# small ammount of regularisation added since data is not full rank\n",
    "c=[0.5,0.5,0.5]\n",
    "\n",
    "gcca = GCCA(latent_dims=latent_dims,c=c)\n",
    "\n",
    "gcca.fit((train_view_1, train_view_2,train_view_3))\n",
    "\n",
    "gcca_results = np.stack((gcca.score((train_view_1, train_view_2, train_view_3)), gcca.score((test_view_1, test_view_2, test_view_3))))\n",
    "\n",
    "\"\"\"\n",
    "### (Regularized) Multiset CCA(can pass more than 2 views)\n",
    "\"\"\"\n",
    "\n",
    "mcca = MCCA(latent_dims=latent_dims, c=c)\n",
    "\n",
    "mcca.fit((train_view_1, train_view_2,train_view_1))\n",
    "\n",
    "mcca_results = np.stack((mcca.score((train_view_1, train_view_2, train_view_3)), mcca.score((test_view_1, test_view_2, test_view_3))))\n",
    "\n",
    "\"\"\"\n",
    "### Multiset CCA by alternating least squares\n",
    "\"\"\"\n",
    "mcca_als = CCA_ALS(latent_dims=latent_dims, max_iter=max_iter)\n",
    "\n",
    "mcca_als.fit((train_view_1, train_view_2,train_view_3))\n",
    "\n",
    "mcca_als_results = np.stack(\n",
    "    (mcca_als.score((train_view_1, train_view_2, train_view_3)), mcca_als.score((test_view_1, test_view_2, test_view_3))))\n",
    "\n",
    "\"\"\"\n",
    "### Multiset PLS by alternating least squares\n",
    "\"\"\"\n",
    "mcca_pls = PLS_ALS(latent_dims=latent_dims)\n",
    "\n",
    "mcca_pls.fit((train_view_1, train_view_2,train_view_1))\n",
    "\n",
    "mcca_pls_results = np.stack(\n",
    "    (mcca_als.score((train_view_1, train_view_2, train_view_3)), mcca_pls.score((test_view_1, test_view_2, test_view_3))))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/cca_zoo/models/innerloop.py:82: UserWarning: For more than 2 views require generalized=True\n",
      "  warnings.warn(\"For more than 2 views require generalized=True\")\n",
      "/usr/local/lib/python3.7/dist-packages/cca_zoo/models/innerloop.py:82: UserWarning: For more than 2 views require generalized=True\n",
      "  warnings.warn(\"For more than 2 views require generalized=True\")\n",
      "/usr/local/lib/python3.7/dist-packages/cca_zoo/models/innerloop.py:82: UserWarning: For more than 2 views require generalized=True\n",
      "  warnings.warn(\"For more than 2 views require generalized=True\")\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "7gMOkBrsvLTr"
   },
   "source": [
    "# Tensor CCA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "7ee38U6BvLTr",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1543df60-fedf-447d-bada-4e97b15fb816"
   },
   "source": [
    "from cca_zoo.models import TCCA\n",
    "\"\"\"\n",
    "### (Regularized) Tensor CCA(can pass more than 2 views)\n",
    "\"\"\"\n",
    "\n",
    "tcca = TCCA(latent_dims=latent_dims, c=c)\n",
    "\n",
    "#memory requirement for tensor is massive so take first 100 features\n",
    "tcca.fit((train_view_1[:,:100], train_view_2[:,:100],train_view_3[:,:100]))\n",
    "\n",
    "tcca_results = np.stack((tcca.score((train_view_1[:,:100], train_view_2[:,:100], train_view_3[:,:100])), tcca.score((test_view_1[:,:100], test_view_2[:,:100], test_view_3[:,:100]))))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "reconstruction error=0.9661771276746018\n",
      "iteration 1, reconstruction error: 0.9518385892645673, decrease = 0.014338538410034518, unnormalized = 24.974625897501497\n",
      "iteration 2, reconstruction error: 0.9507160541458431, decrease = 0.0011225351187241772, unnormalized = 24.945172484955357\n",
      "iteration 3, reconstruction error: 0.9507116250799326, decrease = 4.429065910582786e-06, unnormalized = 24.945056273797878\n",
      "iteration 4, reconstruction error: 0.950711606421758, decrease = 1.8658174560926e-08, unnormalized = 24.945055784239106\n",
      "iteration 5, reconstruction error: 0.950711606295279, decrease = 1.26479049455952e-10, unnormalized = 24.945055780920512\n",
      "PARAFAC converged after 5 iterations\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "lsuPKE35vLTs"
   },
   "source": [
    "# Weighted GCCA/Missing Observation GCCA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "QgHS4svTvLTt"
   },
   "source": [
    "#observation_matrix\n",
    "K = np.ones((3, N))\n",
    "K[0, 200:] = 0\n",
    "K[1, :100] = 0\n",
    "\n",
    "#view weights\n",
    "view_weights=[1,2,1.2]\n",
    "\n",
    "c=[0.5,0.5,0.5]\n",
    "\n",
    "gcca = GCCA(latent_dims=latent_dims,c=c,view_weights=view_weights)\n",
    "\n",
    "gcca.fit((train_view_1, train_view_2,train_view_1),K=K)\n",
    "\n",
    "gcca_results = np.stack((gcca.score((train_view_1, train_view_2)), gcca.score((test_view_1, test_view_2))))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "4O9JHGcBvLTt"
   },
   "source": [
    "# Regularised CCA solutions based on alternating minimisation/alternating least squares\n",
    "\n",
    "We implement Witten's penalized matrix decomposition form of sparse CCA using 'pmd'\n",
    "\n",
    "We implement Waaijenborg's penalized CCA using elastic net using 'elastic'\n",
    "\n",
    "We implement Mai's sparse CCA using 'scca'\n",
    "\n",
    "Furthermore, any of these methods can be extended to multiple views. Witten describes this method explicitly."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "-PdP_V7WvLTt",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0ef4ca0c-36d5-43c3-e38b-914b52687254"
   },
   "source": [
    "from cca_zoo.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from cca_zoo.models import rCCA, PMD,SCCA,ElasticCCA\n",
    "\n",
    "def scorer(estimator,X):\n",
    "  dim_corrs=estimator.score(X)\n",
    "  return dim_corrs.mean()\n",
    "\n",
    "\"\"\"\n",
    "### Ridge CCA (can pass more than 2 views)\n",
    "\"\"\"\n",
    "c1 = [0.1, 0.3, 0.7, 0.9]\n",
    "c2 = [0.1, 0.3, 0.7, 0.9]\n",
    "param_grid = {'c': [c1,c2]}\n",
    "\n",
    "ridge = GridSearchCV(rCCA(latent_dims=latent_dims),param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    verbose=True,scoring=scorer).fit([train_view_1,train_view_2]).best_estimator_\n",
    "\n",
    "ridge_results = np.stack((ridge.score((train_view_1,train_view_2)), ridge.score((test_view_1, test_view_2))))\n",
    "\n",
    "\"\"\"\n",
    "### Sparse CCA (Penalized Matrix Decomposition) (can pass more than 2 views)\n",
    "\"\"\"\n",
    "\n",
    "# PMD\n",
    "c1 = [1, 3, 7, 9]\n",
    "c2 = [1, 3, 7, 9]\n",
    "param_grid = {'c': [c1,c2]}\n",
    "\n",
    "pmd = GridSearchCV(PMD(latent_dims=latent_dims),param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    verbose=True,scoring=scorer).fit([train_view_1,train_view_2]).best_estimator_\n",
    "\n",
    "pmd_results = np.stack((pmd.score((train_view_1,train_view_2)), pmd.score((test_view_1, test_view_2))))\n",
    "\n",
    "\"\"\"\n",
    "### Sparse CCA (can pass more than 2 views)\n",
    "\"\"\"\n",
    "\n",
    "# Sparse CCA\n",
    "c1 = [0.00001, 0.0001]\n",
    "c2 = [0.00001, 0.0001]\n",
    "param_grid = {'c': [c1,c2]}\n",
    "\n",
    "scca = GridSearchCV(SCCA(latent_dims=latent_dims),param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    verbose=True,scoring=scorer).fit([train_view_1,train_view_2]).best_estimator_\n",
    "\n",
    "scca_results = np.stack(\n",
    "    (scca.score((train_view_1,train_view_2)), scca.score((test_view_1, test_view_2))))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "### Elastic CCA (can pass more than 2 views)\n",
    "\"\"\"\n",
    "\n",
    "# Elastic CCA\n",
    "c1 = loguniform(1e-4, 1e0)\n",
    "c2 = loguniform(1e-4, 1e0)\n",
    "l1_1 = loguniform(1e-4, 1e0)\n",
    "l1_2 = loguniform(1e-4, 1e0)\n",
    "param_grid = {'c': [c1,c2], 'l1_ratio': [l1_1,l1_2]}\n",
    "\n",
    "elastic = RandomizedSearchCV(ElasticCCA(latent_dims=latent_dims),param_distributions=param_grid,\n",
    "    cv=cv,\n",
    "    verbose=True,n_iter=5,scoring=scorer).fit([train_view_1,train_view_2]).best_estimator_\n",
    "\n",
    "elastic_results = np.stack(\n",
    "    (elastic.score((train_view_1,train_view_2)), elastic.score((test_view_1, test_view_2))))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "RLvrF3bGvLTu"
   },
   "source": [
    "# Kernel CCA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "cdu62DxIvLTv",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1d94ef2a-0242-421e-bdd2-69a80414d682"
   },
   "source": [
    "from cca_zoo.models import KCCA\n",
    "\"\"\"\n",
    "### Kernel CCA\n",
    "\n",
    "Similarly, we can use kernel CCA methods with [method='kernel']\n",
    "\n",
    "We can use different kernels and their associated parameters in a similar manner to before\n",
    "- regularized linear kernel CCA: parameters :  'kernel'='linear', 0<'c'<1\n",
    "- polynomial kernel CCA: parameters : 'kernel'='poly', 'degree', 0<'c'<1\n",
    "- gaussian rbf kernel CCA: parameters : 'kernel'='gaussian', 'sigma', 0<'c'<1\n",
    "\"\"\"\n",
    "# %%\n",
    "# r-kernel cca\n",
    "c1 = [0.9, 0.99]\n",
    "c2 = [0.9, 0.99]\n",
    "\n",
    "param_grid = {'kernel': ['linear'], 'c': [c1,c2]}\n",
    "\n",
    "kernel_reg = GridSearchCV(KCCA(latent_dims=latent_dims),param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    verbose=True,scoring=scorer).fit([train_view_1,train_view_2]).best_estimator_\n",
    "kernel_reg_results = np.stack((\n",
    "    kernel_reg.score((train_view_1,train_view_2)),\n",
    "    kernel_reg.score((test_view_1, test_view_2))))\n",
    "\n",
    "# kernel cca (poly)\n",
    "degree1 = [2, 3]\n",
    "degree2 = [2, 3]\n",
    "\n",
    "param_grid = {'kernel': ['poly'], 'degree': [degree1,degree2],\n",
    "                    'c': [c1,c2]}\n",
    "\n",
    "kernel_poly = GridSearchCV(KCCA(latent_dims=latent_dims),param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    verbose=True,scoring=scorer).fit([train_view_1,train_view_2]).best_estimator_\n",
    "\n",
    "kernel_poly_results = np.stack((\n",
    "    kernel_poly.score((train_view_1,train_view_2)),\n",
    "    kernel_poly.score((test_view_1, test_view_2))))\n",
    "\n",
    "# kernel cca (gaussian)\n",
    "gamma1 = [1e+1, 1e+2, 1e+3]\n",
    "gamma2 = [1e+1, 1e+2, 1e+3]\n",
    "\n",
    "param_grid = {'kernel': ['rbf'], 'gamma': [gamma1,gamma2],\n",
    "                    'c': [c1,c2]}\n",
    "\n",
    "kernel_gaussian = GridSearchCV(KCCA(latent_dims=latent_dims),param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    verbose=True,scoring=scorer).fit([train_view_1,train_view_2]).best_estimator_\n",
    "\n",
    "kernel_gaussian_results = np.stack((\n",
    "    kernel_gaussian.score((train_view_1,train_view_2)),\n",
    "    kernel_gaussian.score((test_view_1, test_view_2))))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  category=UserWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "iJfzMn4KvLTv"
   },
   "source": [
    "# Deep CCA\n",
    "\n",
    "DCCA can be optimized using Andrew's original tracenorm objective or Wang's DCCA by nonlinear orthogonal iterations using the argument als=True."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "KvW0LO4KvLTw",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3e57f638-f6c1-483b-a088-aaf23fd1b333"
   },
   "source": [
    "\"\"\"\n",
    "### Deep Learning\n",
    "\n",
    "We also have deep CCA methods (and autoencoder variants)\n",
    "- Deep CCA (DCCA)\n",
    "- Deep Canonically Correlated Autoencoders (DCCAE)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# DCCA\n",
    "print('DCCA')\n",
    "encoder_1 = architectures.Encoder(latent_dims=latent_dims, feature_size=784)\n",
    "encoder_2 = architectures.Encoder(latent_dims=latent_dims, feature_size=784)\n",
    "dcca_model = DCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2])\n",
    "\n",
    "dcca_model = CCALightning(dcca_model)\n",
    "trainer = pl.Trainer(max_epochs=epochs, progress_bar_refresh_rate=1, log_every_n_steps=1, logger=False)\n",
    "trainer.fit(dcca_model, train_loader, val_loader)\n",
    "\n",
    "dcca_results = np.stack((dcca_model.score(train_dataset), dcca_model.score(test_loader)))\n",
    "\n",
    "# DCCA_NOI\n",
    "print('DCCA by non-linear orthogonal iterations')\n",
    "encoder_1 = architectures.Encoder(latent_dims=latent_dims, feature_size=784)\n",
    "encoder_2 = architectures.Encoder(latent_dims=latent_dims, feature_size=784)\n",
    "dcca_noi_model = DCCA_NOI(latent_dims=latent_dims, encoders=[encoder_1, encoder_2],N=len(train_dataset))\n",
    "\n",
    "dcca_noi_model = CCALightning(dcca_noi_model)\n",
    "trainer = pl.Trainer(max_epochs=epochs, progress_bar_refresh_rate=1, log_every_n_steps=1, logger=False)\n",
    "trainer.fit(dcca_noi_model, train_loader, val_loader)\n",
    "\n",
    "dcca_noi_results = np.stack(\n",
    "    (dcca_noi_model.score(train_dataset), dcca_noi_model.score(test_dataset)))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DCCA\n",
      "total parameters:  201476\n",
      "====> Epoch: 1 Average train loss: -0.2531\n",
      "====> Epoch: 1 Average val loss: -0.1096\n",
      "Min loss -0.11\n",
      "====> Epoch: 2 Average train loss: -0.1009\n",
      "====> Epoch: 2 Average val loss: -0.1308\n",
      "Min loss -0.13\n",
      "====> Epoch: 3 Average train loss: -0.2040\n",
      "====> Epoch: 3 Average val loss: -0.1842\n",
      "Min loss -0.18\n",
      "====> Epoch: 4 Average train loss: -0.1796\n",
      "====> Epoch: 4 Average val loss: -0.1576\n",
      "====> Epoch: 5 Average train loss: -0.2058\n",
      "====> Epoch: 5 Average val loss: -0.3233\n",
      "Min loss -0.32\n",
      "====> Epoch: 6 Average train loss: -0.3632\n",
      "====> Epoch: 6 Average val loss: -0.4711\n",
      "Min loss -0.47\n",
      "====> Epoch: 7 Average train loss: -0.4117\n",
      "====> Epoch: 7 Average val loss: -0.4762\n",
      "Min loss -0.48\n",
      "====> Epoch: 8 Average train loss: -0.4564\n",
      "====> Epoch: 8 Average val loss: -0.4032\n",
      "====> Epoch: 9 Average train loss: -0.5325\n",
      "====> Epoch: 9 Average val loss: -0.4755\n",
      "====> Epoch: 10 Average train loss: -0.5422\n",
      "====> Epoch: 10 Average val loss: -0.5092\n",
      "Min loss -0.51\n",
      "====> Epoch: 11 Average train loss: -0.7966\n",
      "====> Epoch: 11 Average val loss: -0.7684\n",
      "Min loss -0.77\n",
      "====> Epoch: 12 Average train loss: -0.8014\n",
      "====> Epoch: 12 Average val loss: -0.7995\n",
      "Min loss -0.80\n",
      "====> Epoch: 13 Average train loss: -0.8132\n",
      "====> Epoch: 13 Average val loss: -0.7553\n",
      "====> Epoch: 14 Average train loss: -0.8314\n",
      "====> Epoch: 14 Average val loss: -0.7947\n",
      "====> Epoch: 15 Average train loss: -0.8431\n",
      "====> Epoch: 15 Average val loss: -0.7909\n",
      "====> Epoch: 16 Average train loss: -0.7976\n",
      "====> Epoch: 16 Average val loss: -0.8460\n",
      "Min loss -0.85\n",
      "====> Epoch: 17 Average train loss: -0.8252\n",
      "====> Epoch: 17 Average val loss: -0.8178\n",
      "====> Epoch: 18 Average train loss: -0.5628\n",
      "====> Epoch: 18 Average val loss: -0.5937\n",
      "====> Epoch: 19 Average train loss: -0.6322\n",
      "====> Epoch: 19 Average val loss: -0.6510\n",
      "====> Epoch: 20 Average train loss: -0.7647\n",
      "====> Epoch: 20 Average val loss: -0.7421\n",
      "====> Epoch: 21 Average train loss: -0.7851\n",
      "====> Epoch: 21 Average val loss: -0.7247\n",
      "====> Epoch: 22 Average train loss: -0.7602\n",
      "====> Epoch: 22 Average val loss: -0.8007\n",
      "====> Epoch: 23 Average train loss: -0.8833\n",
      "====> Epoch: 23 Average val loss: -0.7915\n",
      "====> Epoch: 24 Average train loss: -0.9343\n",
      "====> Epoch: 24 Average val loss: -1.0192\n",
      "Min loss -1.02\n",
      "====> Epoch: 25 Average train loss: -1.0146\n",
      "====> Epoch: 25 Average val loss: -0.9402\n",
      "====> Epoch: 26 Average train loss: -1.1286\n",
      "====> Epoch: 26 Average val loss: -1.1075\n",
      "Min loss -1.11\n",
      "====> Epoch: 27 Average train loss: -1.3057\n",
      "====> Epoch: 27 Average val loss: -1.1418\n",
      "Min loss -1.14\n",
      "====> Epoch: 28 Average train loss: -1.2272\n",
      "====> Epoch: 28 Average val loss: -1.2574\n",
      "Min loss -1.26\n",
      "====> Epoch: 29 Average train loss: -1.2456\n",
      "====> Epoch: 29 Average val loss: -1.2860\n",
      "Min loss -1.29\n",
      "====> Epoch: 30 Average train loss: -1.1873\n",
      "====> Epoch: 30 Average val loss: -1.2548\n",
      "====> Epoch: 31 Average train loss: -0.4281\n",
      "====> Epoch: 31 Average val loss: -0.4875\n",
      "====> Epoch: 32 Average train loss: -0.4639\n",
      "====> Epoch: 32 Average val loss: -0.4214\n",
      "====> Epoch: 33 Average train loss: -0.5640\n",
      "====> Epoch: 33 Average val loss: -0.5791\n",
      "====> Epoch: 34 Average train loss: -0.5631\n",
      "====> Epoch: 34 Average val loss: -0.5806\n",
      "====> Epoch: 35 Average train loss: -0.6183\n",
      "====> Epoch: 35 Average val loss: -0.7391\n",
      "====> Epoch: 36 Average train loss: -0.7337\n",
      "====> Epoch: 36 Average val loss: -0.7412\n",
      "====> Epoch: 37 Average train loss: -0.8041\n",
      "====> Epoch: 37 Average val loss: -0.7272\n",
      "====> Epoch: 38 Average train loss: -0.8215\n",
      "====> Epoch: 38 Average val loss: -0.7341\n",
      "====> Epoch: 39 Average train loss: -0.9231\n",
      "====> Epoch: 39 Average val loss: -0.8679\n",
      "====> Epoch: 40 Average train loss: -0.9075\n",
      "====> Epoch: 40 Average val loss: -0.9036\n",
      "====> Epoch: 41 Average train loss: -0.9635\n",
      "====> Epoch: 41 Average val loss: -1.0391\n",
      "====> Epoch: 42 Average train loss: -0.5608\n",
      "====> Epoch: 42 Average val loss: -0.5265\n",
      "====> Epoch: 43 Average train loss: -0.5490\n",
      "====> Epoch: 43 Average val loss: -0.4652\n",
      "====> Epoch: 44 Average train loss: -0.5735\n",
      "====> Epoch: 44 Average val loss: -0.5087\n",
      "====> Epoch: 45 Average train loss: -0.4709\n",
      "====> Epoch: 45 Average val loss: -0.5251\n",
      "====> Epoch: 46 Average train loss: -0.5153\n",
      "====> Epoch: 46 Average val loss: -0.5300\n",
      "====> Epoch: 47 Average train loss: -0.6953\n",
      "====> Epoch: 47 Average val loss: -0.6359\n",
      "====> Epoch: 48 Average train loss: -0.7484\n",
      "====> Epoch: 48 Average val loss: -0.7373\n",
      "====> Epoch: 49 Average train loss: -0.7750\n",
      "====> Epoch: 49 Average val loss: -0.6816\n",
      "====> Epoch: 50 Average train loss: -0.4636\n",
      "====> Epoch: 50 Average val loss: -0.3775\n",
      "DCCA by non-linear orthogonal iterations\n",
      "total parameters:  201484\n",
      "====> Epoch: 1 Average train loss: 0.0077\n",
      "====> Epoch: 1 Average val loss: 0.0074\n",
      "Min loss 0.01\n",
      "====> Epoch: 2 Average train loss: 0.0071\n",
      "====> Epoch: 2 Average val loss: 0.0069\n",
      "Min loss 0.01\n",
      "====> Epoch: 3 Average train loss: 0.0072\n",
      "====> Epoch: 3 Average val loss: 0.0069\n",
      "====> Epoch: 4 Average train loss: 0.0067\n",
      "====> Epoch: 4 Average val loss: 0.0070\n",
      "====> Epoch: 5 Average train loss: 0.0064\n",
      "====> Epoch: 5 Average val loss: 0.0069\n",
      "====> Epoch: 6 Average train loss: 0.0066\n",
      "====> Epoch: 6 Average val loss: 0.0070\n",
      "====> Epoch: 7 Average train loss: 0.0067\n",
      "====> Epoch: 7 Average val loss: 0.0068\n",
      "Min loss 0.01\n",
      "====> Epoch: 8 Average train loss: 0.0066\n",
      "====> Epoch: 8 Average val loss: 0.0063\n",
      "Min loss 0.01\n",
      "====> Epoch: 9 Average train loss: 0.0068\n",
      "====> Epoch: 9 Average val loss: 0.0064\n",
      "====> Epoch: 10 Average train loss: 0.0066\n",
      "====> Epoch: 10 Average val loss: 0.0065\n",
      "====> Epoch: 11 Average train loss: 0.0067\n",
      "====> Epoch: 11 Average val loss: 0.0063\n",
      "Min loss 0.01\n",
      "====> Epoch: 12 Average train loss: 0.0066\n",
      "====> Epoch: 12 Average val loss: 0.0068\n",
      "====> Epoch: 13 Average train loss: 0.0065\n",
      "====> Epoch: 13 Average val loss: 0.0066\n",
      "====> Epoch: 14 Average train loss: 0.0065\n",
      "====> Epoch: 14 Average val loss: 0.0066\n",
      "====> Epoch: 15 Average train loss: 0.0063\n",
      "====> Epoch: 15 Average val loss: 0.0064\n",
      "====> Epoch: 16 Average train loss: 0.0060\n",
      "====> Epoch: 16 Average val loss: 0.0057\n",
      "Min loss 0.01\n",
      "====> Epoch: 17 Average train loss: 0.0057\n",
      "====> Epoch: 17 Average val loss: 0.0054\n",
      "Min loss 0.01\n",
      "====> Epoch: 18 Average train loss: 0.0045\n",
      "====> Epoch: 18 Average val loss: 0.0045\n",
      "Min loss 0.00\n",
      "====> Epoch: 19 Average train loss: 0.0044\n",
      "====> Epoch: 19 Average val loss: 0.0043\n",
      "Min loss 0.00\n",
      "====> Epoch: 20 Average train loss: 0.0042\n",
      "====> Epoch: 20 Average val loss: 0.0045\n",
      "====> Epoch: 21 Average train loss: 0.0042\n",
      "====> Epoch: 21 Average val loss: 0.0042\n",
      "Min loss 0.00\n",
      "====> Epoch: 22 Average train loss: 0.0042\n",
      "====> Epoch: 22 Average val loss: 0.0042\n",
      "Min loss 0.00\n",
      "====> Epoch: 23 Average train loss: 0.0042\n",
      "====> Epoch: 23 Average val loss: 0.0041\n",
      "Min loss 0.00\n",
      "====> Epoch: 24 Average train loss: 0.0042\n",
      "====> Epoch: 24 Average val loss: 0.0040\n",
      "Min loss 0.00\n",
      "====> Epoch: 25 Average train loss: 0.0042\n",
      "====> Epoch: 25 Average val loss: 0.0043\n",
      "====> Epoch: 26 Average train loss: 0.0041\n",
      "====> Epoch: 26 Average val loss: 0.0043\n",
      "====> Epoch: 27 Average train loss: 0.0042\n",
      "====> Epoch: 27 Average val loss: 0.0044\n",
      "====> Epoch: 28 Average train loss: 0.0041\n",
      "====> Epoch: 28 Average val loss: 0.0042\n",
      "====> Epoch: 29 Average train loss: 0.0041\n",
      "====> Epoch: 29 Average val loss: 0.0043\n",
      "====> Epoch: 30 Average train loss: 0.0039\n",
      "====> Epoch: 30 Average val loss: 0.0039\n",
      "Min loss 0.00\n",
      "====> Epoch: 31 Average train loss: 0.0038\n",
      "====> Epoch: 31 Average val loss: 0.0037\n",
      "Min loss 0.00\n",
      "====> Epoch: 32 Average train loss: 0.0079\n",
      "====> Epoch: 32 Average val loss: 0.0079\n",
      "====> Epoch: 33 Average train loss: 0.0081\n",
      "====> Epoch: 33 Average val loss: 0.0077\n",
      "====> Epoch: 34 Average train loss: 0.0072\n",
      "====> Epoch: 34 Average val loss: 0.0075\n",
      "====> Epoch: 35 Average train loss: 0.0065\n",
      "====> Epoch: 35 Average val loss: 0.0062\n",
      "====> Epoch: 36 Average train loss: 0.0060\n",
      "====> Epoch: 36 Average val loss: 0.0056\n",
      "====> Epoch: 37 Average train loss: 0.0057\n",
      "====> Epoch: 37 Average val loss: 0.0057\n",
      "====> Epoch: 38 Average train loss: 0.0045\n",
      "====> Epoch: 38 Average val loss: 0.0045\n",
      "====> Epoch: 39 Average train loss: 0.0043\n",
      "====> Epoch: 39 Average val loss: 0.0044\n",
      "====> Epoch: 40 Average train loss: 0.0042\n",
      "====> Epoch: 40 Average val loss: 0.0042\n",
      "====> Epoch: 41 Average train loss: 0.0040\n",
      "====> Epoch: 41 Average val loss: 0.0039\n",
      "====> Epoch: 42 Average train loss: 0.0040\n",
      "====> Epoch: 42 Average val loss: 0.0040\n",
      "====> Epoch: 43 Average train loss: 0.0042\n",
      "====> Epoch: 43 Average val loss: 0.0041\n",
      "====> Epoch: 44 Average train loss: 0.0040\n",
      "====> Epoch: 44 Average val loss: 0.0038\n",
      "====> Epoch: 45 Average train loss: 0.0040\n",
      "====> Epoch: 45 Average val loss: 0.0037\n",
      "Min loss 0.00\n",
      "====> Epoch: 46 Average train loss: 0.0041\n",
      "====> Epoch: 46 Average val loss: 0.0038\n",
      "====> Epoch: 47 Average train loss: 0.0039\n",
      "====> Epoch: 47 Average val loss: 0.0040\n",
      "====> Epoch: 48 Average train loss: 0.0035\n",
      "====> Epoch: 48 Average val loss: 0.0034\n",
      "Min loss 0.00\n",
      "====> Epoch: 49 Average train loss: 0.0033\n",
      "====> Epoch: 49 Average val loss: 0.0035\n",
      "====> Epoch: 50 Average train loss: 0.0034\n",
      "====> Epoch: 50 Average val loss: 0.0033\n",
      "Min loss 0.00\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "LvhEwkx2vLTx"
   },
   "source": [
    "# DCCA with custom optimizers and schedulers"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "pyNA7lBEvLTx",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ff1b9c97-a2d6-4f18-9204-343ff3fd0dc8"
   },
   "source": [
    "# DCCA\n",
    "print('DCCA')\n",
    "encoder_1 = architectures.Encoder(latent_dims=latent_dims, feature_size=784)\n",
    "encoder_2 = architectures.Encoder(latent_dims=latent_dims, feature_size=784)\n",
    "dcca_model = DCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2])\n",
    "optimizer = optim.Adam(dcca_model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 1)\n",
    "dcca_model = CCALightning(dcca_model)\n",
    "trainer = pl.Trainer(max_epochs=epochs, progress_bar_refresh_rate=1, log_every_n_steps=1, logger=False)\n",
    "trainer.fit(dcca_model, train_loader, val_loader)\n",
    "\n",
    "dcca_results = np.stack((dcca_model.score(train_dataset), dcca_model.score(test_dataset)))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DCCA\n",
      "total parameters:  201476\n",
      "====> Epoch: 1 Average train loss: -0.2345\n",
      "====> Epoch: 1 Average val loss: -0.1404\n",
      "Min loss -0.14\n",
      "====> Epoch: 2 Average train loss: -0.1096\n",
      "====> Epoch: 2 Average val loss: -0.1372\n",
      "====> Epoch: 3 Average train loss: -0.0880\n",
      "====> Epoch: 3 Average val loss: -0.0736\n",
      "====> Epoch: 4 Average train loss: -0.0473\n",
      "====> Epoch: 4 Average val loss: -0.1699\n",
      "Min loss -0.17\n",
      "====> Epoch: 5 Average train loss: -0.1097\n",
      "====> Epoch: 5 Average val loss: -0.1187\n",
      "====> Epoch: 6 Average train loss: -0.1023\n",
      "====> Epoch: 6 Average val loss: -0.0718\n",
      "====> Epoch: 7 Average train loss: -0.1285\n",
      "====> Epoch: 7 Average val loss: -0.1539\n",
      "====> Epoch: 8 Average train loss: -0.0861\n",
      "====> Epoch: 8 Average val loss: -0.0859\n",
      "====> Epoch: 9 Average train loss: -0.0531\n",
      "====> Epoch: 9 Average val loss: -0.0679\n",
      "====> Epoch: 10 Average train loss: -0.0867\n",
      "====> Epoch: 10 Average val loss: -0.0726\n",
      "====> Epoch: 11 Average train loss: -0.0745\n",
      "====> Epoch: 11 Average val loss: -0.0786\n",
      "====> Epoch: 12 Average train loss: -0.0469\n",
      "====> Epoch: 12 Average val loss: -0.1140\n",
      "====> Epoch: 13 Average train loss: -0.0485\n",
      "====> Epoch: 13 Average val loss: -0.1343\n",
      "====> Epoch: 14 Average train loss: -0.1541\n",
      "====> Epoch: 14 Average val loss: -0.0680\n",
      "====> Epoch: 15 Average train loss: -0.1251\n",
      "====> Epoch: 15 Average val loss: -0.1210\n",
      "====> Epoch: 16 Average train loss: -0.0867\n",
      "====> Epoch: 16 Average val loss: -0.0625\n",
      "====> Epoch: 17 Average train loss: -0.0633\n",
      "====> Epoch: 17 Average val loss: -0.0377\n",
      "====> Epoch: 18 Average train loss: -0.0532\n",
      "====> Epoch: 18 Average val loss: -0.0286\n",
      "====> Epoch: 19 Average train loss: -0.1026\n",
      "====> Epoch: 19 Average val loss: -0.1444\n",
      "====> Epoch: 20 Average train loss: -0.1870\n",
      "====> Epoch: 20 Average val loss: -0.1416\n",
      "====> Epoch: 21 Average train loss: -0.1480\n",
      "====> Epoch: 21 Average val loss: -0.0909\n",
      "====> Epoch: 22 Average train loss: -0.1719\n",
      "====> Epoch: 22 Average val loss: -0.1753\n",
      "Min loss -0.18\n",
      "====> Epoch: 23 Average train loss: -0.0477\n",
      "====> Epoch: 23 Average val loss: -0.1516\n",
      "====> Epoch: 24 Average train loss: -0.1052\n",
      "====> Epoch: 24 Average val loss: -0.0912\n",
      "====> Epoch: 25 Average train loss: -0.0992\n",
      "====> Epoch: 25 Average val loss: -0.0723\n",
      "====> Epoch: 26 Average train loss: -0.1183\n",
      "====> Epoch: 26 Average val loss: -0.0333\n",
      "====> Epoch: 27 Average train loss: -0.0867\n",
      "====> Epoch: 27 Average val loss: -0.1468\n",
      "====> Epoch: 28 Average train loss: -0.0383\n",
      "====> Epoch: 28 Average val loss: -0.0647\n",
      "====> Epoch: 29 Average train loss: -0.1259\n",
      "====> Epoch: 29 Average val loss: -0.0760\n",
      "====> Epoch: 30 Average train loss: -0.1398\n",
      "====> Epoch: 30 Average val loss: -0.0601\n",
      "====> Epoch: 31 Average train loss: -0.1736\n",
      "====> Epoch: 31 Average val loss: -0.1128\n",
      "====> Epoch: 32 Average train loss: -0.1219\n",
      "====> Epoch: 32 Average val loss: -0.0435\n",
      "====> Epoch: 33 Average train loss: -0.0648\n",
      "====> Epoch: 33 Average val loss: -0.1038\n",
      "====> Epoch: 34 Average train loss: -0.2130\n",
      "====> Epoch: 34 Average val loss: -0.0537\n",
      "====> Epoch: 35 Average train loss: -0.0897\n",
      "====> Epoch: 35 Average val loss: -0.1286\n",
      "====> Epoch: 36 Average train loss: -0.0613\n",
      "====> Epoch: 36 Average val loss: -0.1210\n",
      "====> Epoch: 37 Average train loss: -0.2377\n",
      "====> Epoch: 37 Average val loss: -0.0619\n",
      "====> Epoch: 38 Average train loss: -0.0458\n",
      "====> Epoch: 38 Average val loss: -0.1473\n",
      "====> Epoch: 39 Average train loss: -0.0578\n",
      "====> Epoch: 39 Average val loss: -0.1190\n",
      "====> Epoch: 40 Average train loss: -0.1635\n",
      "====> Epoch: 40 Average val loss: -0.1229\n",
      "====> Epoch: 41 Average train loss: -0.1248\n",
      "====> Epoch: 41 Average val loss: -0.0981\n",
      "====> Epoch: 42 Average train loss: -0.0984\n",
      "====> Epoch: 42 Average val loss: -0.0647\n",
      "====> Epoch: 43 Average train loss: -0.1104\n",
      "====> Epoch: 43 Average val loss: -0.1612\n",
      "====> Epoch: 44 Average train loss: -0.0655\n",
      "====> Epoch: 44 Average val loss: -0.1284\n",
      "====> Epoch: 45 Average train loss: -0.0875\n",
      "====> Epoch: 45 Average val loss: -0.0430\n",
      "====> Epoch: 46 Average train loss: -0.1070\n",
      "====> Epoch: 46 Average val loss: -0.1176\n",
      "====> Epoch: 47 Average train loss: -0.0518\n",
      "====> Epoch: 47 Average val loss: -0.0676\n",
      "====> Epoch: 48 Average train loss: -0.2479\n",
      "====> Epoch: 48 Average val loss: -0.1518\n",
      "====> Epoch: 49 Average train loss: -0.0629\n",
      "====> Epoch: 49 Average val loss: -0.1117\n",
      "====> Epoch: 50 Average train loss: -0.1809\n",
      "====> Epoch: 50 Average val loss: -0.1175\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "5eV-WnWRvLTy"
   },
   "source": [
    "# DGCCA and DMCCA for more than 2 views\n",
    "\n",
    "The only change we need to make is to the objective argument to perform DGCCA and DMCCA."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "_XKkNitdvLTy",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3e35ad57-ea2b-4631-e0d2-8f14282affb5"
   },
   "source": [
    "# DGCCA\n",
    "print('DGCCA')\n",
    "encoder_1 = architectures.Encoder(latent_dims=latent_dims, feature_size=784)\n",
    "encoder_2 = architectures.Encoder(latent_dims=latent_dims, feature_size=784)\n",
    "dgcca_model = DCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2], objective=objectives.GCCA)\n",
    "\n",
    "dgcca_model = CCALightning(dgcca_model)\n",
    "trainer = pl.Trainer(max_epochs=epochs, progress_bar_refresh_rate=1, log_every_n_steps=1, logger=False)\n",
    "trainer.fit(dgcca_model, train_loader, val_loader)\n",
    "\n",
    "dgcca_results = np.stack(\n",
    "    (dgcca_model.score(train_dataset), dgcca_model.score(test_dataset)))\n",
    "\n",
    "# DMCCA\n",
    "print('DMCCA')\n",
    "encoder_1 = architectures.Encoder(latent_dims=latent_dims, feature_size=784)\n",
    "encoder_2 = architectures.Encoder(latent_dims=latent_dims, feature_size=784)\n",
    "dmcca_model = DCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2], objective=objectives.MCCA)\n",
    "\n",
    "dmcca_model = CCALightning(dmcca_model)\n",
    "trainer = pl.Trainer(max_epochs=epochs, progress_bar_refresh_rate=1, log_every_n_steps=1, logger=False)\n",
    "trainer.fit(dmcca_model, train_loader, val_loader)\n",
    "\n",
    "dmcca_results = np.stack(\n",
    "    (dmcca_model.score(train_dataset), dmcca_model.score(test_dataset)))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DGCCA\n",
      "total parameters:  201476\n",
      "====> Epoch: 1 Average train loss: -0.3717\n",
      "====> Epoch: 1 Average val loss: -0.2874\n",
      "Min loss -0.29\n",
      "====> Epoch: 2 Average train loss: -0.4010\n",
      "====> Epoch: 2 Average val loss: -0.3402\n",
      "Min loss -0.34\n",
      "====> Epoch: 3 Average train loss: -0.5026\n",
      "====> Epoch: 3 Average val loss: -0.4891\n",
      "Min loss -0.49\n",
      "====> Epoch: 4 Average train loss: -0.4654\n",
      "====> Epoch: 4 Average val loss: -0.4745\n",
      "====> Epoch: 5 Average train loss: -0.6690\n",
      "====> Epoch: 5 Average val loss: -0.5786\n",
      "Min loss -0.58\n",
      "====> Epoch: 6 Average train loss: -0.5903\n",
      "====> Epoch: 6 Average val loss: -0.5848\n",
      "Min loss -0.58\n",
      "====> Epoch: 7 Average train loss: -0.6430\n",
      "====> Epoch: 7 Average val loss: -0.6894\n",
      "Min loss -0.69\n",
      "====> Epoch: 8 Average train loss: -0.7384\n",
      "====> Epoch: 8 Average val loss: -0.6960\n",
      "Min loss -0.70\n",
      "====> Epoch: 9 Average train loss: -0.7716\n",
      "====> Epoch: 9 Average val loss: -0.7567\n",
      "Min loss -0.76\n",
      "====> Epoch: 10 Average train loss: -0.8274\n",
      "====> Epoch: 10 Average val loss: -0.7267\n",
      "====> Epoch: 11 Average train loss: -0.8185\n",
      "====> Epoch: 11 Average val loss: -0.7173\n",
      "====> Epoch: 12 Average train loss: -0.8574\n",
      "====> Epoch: 12 Average val loss: -0.7553\n",
      "====> Epoch: 13 Average train loss: -0.8279\n",
      "====> Epoch: 13 Average val loss: -0.7826\n",
      "Min loss -0.78\n",
      "====> Epoch: 14 Average train loss: -0.8461\n",
      "====> Epoch: 14 Average val loss: -0.7677\n",
      "====> Epoch: 15 Average train loss: -0.9792\n",
      "====> Epoch: 15 Average val loss: -0.8070\n",
      "Min loss -0.81\n",
      "====> Epoch: 16 Average train loss: -0.8722\n",
      "====> Epoch: 16 Average val loss: -0.8461\n",
      "Min loss -0.85\n",
      "====> Epoch: 17 Average train loss: -0.8155\n",
      "====> Epoch: 17 Average val loss: -0.8062\n",
      "====> Epoch: 18 Average train loss: -0.8851\n",
      "====> Epoch: 18 Average val loss: -0.8348\n",
      "====> Epoch: 19 Average train loss: -1.0884\n",
      "====> Epoch: 19 Average val loss: -0.8903\n",
      "Min loss -0.89\n",
      "====> Epoch: 20 Average train loss: -0.9305\n",
      "====> Epoch: 20 Average val loss: -0.9799\n",
      "Min loss -0.98\n",
      "====> Epoch: 21 Average train loss: -0.8848\n",
      "====> Epoch: 21 Average val loss: -0.9489\n",
      "====> Epoch: 22 Average train loss: -0.9700\n",
      "====> Epoch: 22 Average val loss: -0.9913\n",
      "Min loss -0.99\n",
      "====> Epoch: 23 Average train loss: -1.0768\n",
      "====> Epoch: 23 Average val loss: -0.9465\n",
      "====> Epoch: 24 Average train loss: -0.9855\n",
      "====> Epoch: 24 Average val loss: -0.9430\n",
      "====> Epoch: 25 Average train loss: -0.9074\n",
      "====> Epoch: 25 Average val loss: -0.9642\n",
      "====> Epoch: 26 Average train loss: -1.0501\n",
      "====> Epoch: 26 Average val loss: -1.0461\n",
      "Min loss -1.05\n",
      "====> Epoch: 27 Average train loss: -1.0541\n",
      "====> Epoch: 27 Average val loss: -1.0062\n",
      "====> Epoch: 28 Average train loss: -1.0942\n",
      "====> Epoch: 28 Average val loss: -1.0910\n",
      "Min loss -1.09\n",
      "====> Epoch: 29 Average train loss: -1.0717\n",
      "====> Epoch: 29 Average val loss: -1.0549\n",
      "====> Epoch: 30 Average train loss: -1.0560\n",
      "====> Epoch: 30 Average val loss: -1.0381\n",
      "====> Epoch: 31 Average train loss: -1.0791\n",
      "====> Epoch: 31 Average val loss: -1.0678\n",
      "====> Epoch: 32 Average train loss: -0.7371\n",
      "====> Epoch: 32 Average val loss: -0.6544\n",
      "====> Epoch: 33 Average train loss: -0.7659\n",
      "====> Epoch: 33 Average val loss: -0.6864\n",
      "====> Epoch: 34 Average train loss: -0.7129\n",
      "====> Epoch: 34 Average val loss: -0.6451\n",
      "====> Epoch: 35 Average train loss: -0.7985\n",
      "====> Epoch: 35 Average val loss: -0.8138\n",
      "====> Epoch: 36 Average train loss: -0.7538\n",
      "====> Epoch: 36 Average val loss: -0.6864\n",
      "====> Epoch: 37 Average train loss: -0.7906\n",
      "====> Epoch: 37 Average val loss: -0.7654\n",
      "====> Epoch: 38 Average train loss: -0.8417\n",
      "====> Epoch: 38 Average val loss: -0.8218\n",
      "====> Epoch: 39 Average train loss: -0.8689\n",
      "====> Epoch: 39 Average val loss: -0.8711\n",
      "====> Epoch: 40 Average train loss: -0.8193\n",
      "====> Epoch: 40 Average val loss: -0.7741\n",
      "====> Epoch: 41 Average train loss: -0.9110\n",
      "====> Epoch: 41 Average val loss: -0.8667\n",
      "====> Epoch: 42 Average train loss: -0.9737\n",
      "====> Epoch: 42 Average val loss: -0.9454\n",
      "====> Epoch: 43 Average train loss: -0.9981\n",
      "====> Epoch: 43 Average val loss: -0.9658\n",
      "====> Epoch: 44 Average train loss: -1.1852\n",
      "====> Epoch: 44 Average val loss: -1.1355\n",
      "Min loss -1.14\n",
      "====> Epoch: 45 Average train loss: -0.9776\n",
      "====> Epoch: 45 Average val loss: -0.7820\n",
      "====> Epoch: 46 Average train loss: -0.7977\n",
      "====> Epoch: 46 Average val loss: -0.7567\n",
      "====> Epoch: 47 Average train loss: -1.1455\n",
      "====> Epoch: 47 Average val loss: -0.9938\n",
      "====> Epoch: 48 Average train loss: -1.0858\n",
      "====> Epoch: 48 Average val loss: -1.0856\n",
      "====> Epoch: 49 Average train loss: -1.0088\n",
      "====> Epoch: 49 Average val loss: -1.0482\n",
      "====> Epoch: 50 Average train loss: -1.0798\n",
      "====> Epoch: 50 Average val loss: -1.1690\n",
      "Min loss -1.17\n",
      "DMCCA\n",
      "total parameters:  201476\n",
      "====> Epoch: 1 Average train loss: -0.7272\n",
      "====> Epoch: 1 Average val loss: -0.5648\n",
      "Min loss -0.56\n",
      "====> Epoch: 2 Average train loss: -0.5396\n",
      "====> Epoch: 2 Average val loss: -0.5257\n",
      "====> Epoch: 3 Average train loss: -0.5592\n",
      "====> Epoch: 3 Average val loss: -0.5761\n",
      "Min loss -0.58\n",
      "====> Epoch: 4 Average train loss: -0.8326\n",
      "====> Epoch: 4 Average val loss: -0.6956\n",
      "Min loss -0.70\n",
      "====> Epoch: 5 Average train loss: -0.7508\n",
      "====> Epoch: 5 Average val loss: -0.7319\n",
      "Min loss -0.73\n",
      "====> Epoch: 6 Average train loss: -0.7918\n",
      "====> Epoch: 6 Average val loss: -0.7501\n",
      "Min loss -0.75\n",
      "====> Epoch: 7 Average train loss: -0.7197\n",
      "====> Epoch: 7 Average val loss: -0.7025\n",
      "====> Epoch: 8 Average train loss: -0.8067\n",
      "====> Epoch: 8 Average val loss: -0.7396\n",
      "====> Epoch: 9 Average train loss: -0.7109\n",
      "====> Epoch: 9 Average val loss: -0.7343\n",
      "====> Epoch: 10 Average train loss: -0.7181\n",
      "====> Epoch: 10 Average val loss: -0.6935\n",
      "====> Epoch: 11 Average train loss: -0.7715\n",
      "====> Epoch: 11 Average val loss: -0.7396\n",
      "====> Epoch: 12 Average train loss: -0.8081\n",
      "====> Epoch: 12 Average val loss: -0.7593\n",
      "Min loss -0.76\n",
      "====> Epoch: 13 Average train loss: -0.8056\n",
      "====> Epoch: 13 Average val loss: -0.7780\n",
      "Min loss -0.78\n",
      "====> Epoch: 14 Average train loss: -0.7139\n",
      "====> Epoch: 14 Average val loss: -0.7234\n",
      "====> Epoch: 15 Average train loss: -0.8010\n",
      "====> Epoch: 15 Average val loss: -0.7624\n",
      "====> Epoch: 16 Average train loss: -0.8537\n",
      "====> Epoch: 16 Average val loss: -0.8110\n",
      "Min loss -0.81\n",
      "====> Epoch: 17 Average train loss: -0.8014\n",
      "====> Epoch: 17 Average val loss: -0.7729\n",
      "====> Epoch: 18 Average train loss: -0.9397\n",
      "====> Epoch: 18 Average val loss: -0.7617\n",
      "====> Epoch: 19 Average train loss: -0.9068\n",
      "====> Epoch: 19 Average val loss: -0.8688\n",
      "Min loss -0.87\n",
      "====> Epoch: 20 Average train loss: -0.9523\n",
      "====> Epoch: 20 Average val loss: -0.9657\n",
      "Min loss -0.97\n",
      "====> Epoch: 21 Average train loss: -0.9830\n",
      "====> Epoch: 21 Average val loss: -0.9828\n",
      "Min loss -0.98\n",
      "====> Epoch: 22 Average train loss: -0.8908\n",
      "====> Epoch: 22 Average val loss: -1.0201\n",
      "Min loss -1.02\n",
      "====> Epoch: 23 Average train loss: -1.0304\n",
      "====> Epoch: 23 Average val loss: -1.0090\n",
      "====> Epoch: 24 Average train loss: -1.0930\n",
      "====> Epoch: 24 Average val loss: -1.0294\n",
      "Min loss -1.03\n",
      "====> Epoch: 25 Average train loss: -1.1140\n",
      "====> Epoch: 25 Average val loss: -1.0150\n",
      "====> Epoch: 26 Average train loss: -0.8270\n",
      "====> Epoch: 26 Average val loss: -0.8099\n",
      "====> Epoch: 27 Average train loss: -0.8180\n",
      "====> Epoch: 27 Average val loss: -0.7855\n",
      "====> Epoch: 28 Average train loss: -0.8484\n",
      "====> Epoch: 28 Average val loss: -0.8272\n",
      "====> Epoch: 29 Average train loss: -0.9530\n",
      "====> Epoch: 29 Average val loss: -0.9293\n",
      "====> Epoch: 30 Average train loss: -1.0448\n",
      "====> Epoch: 30 Average val loss: -1.0305\n",
      "Min loss -1.03\n",
      "====> Epoch: 31 Average train loss: -1.1297\n",
      "====> Epoch: 31 Average val loss: -1.1626\n",
      "Min loss -1.16\n",
      "====> Epoch: 32 Average train loss: -1.2066\n",
      "====> Epoch: 32 Average val loss: -1.2592\n",
      "Min loss -1.26\n",
      "====> Epoch: 33 Average train loss: -1.2493\n",
      "====> Epoch: 33 Average val loss: -1.2980\n",
      "Min loss -1.30\n",
      "====> Epoch: 34 Average train loss: -1.1872\n",
      "====> Epoch: 34 Average val loss: -1.2153\n",
      "====> Epoch: 35 Average train loss: -1.2708\n",
      "====> Epoch: 35 Average val loss: -1.2851\n",
      "====> Epoch: 36 Average train loss: -1.2831\n",
      "====> Epoch: 36 Average val loss: -1.3056\n",
      "Min loss -1.31\n",
      "====> Epoch: 37 Average train loss: -1.2999\n",
      "====> Epoch: 37 Average val loss: -1.3194\n",
      "Min loss -1.32\n",
      "====> Epoch: 38 Average train loss: -1.3256\n",
      "====> Epoch: 38 Average val loss: -1.3528\n",
      "Min loss -1.35\n",
      "====> Epoch: 39 Average train loss: -1.3218\n",
      "====> Epoch: 39 Average val loss: -1.2652\n",
      "====> Epoch: 40 Average train loss: -1.3106\n",
      "====> Epoch: 40 Average val loss: -1.2634\n",
      "====> Epoch: 41 Average train loss: -0.8961\n",
      "====> Epoch: 41 Average val loss: -0.7964\n",
      "====> Epoch: 42 Average train loss: -1.3604\n",
      "====> Epoch: 42 Average val loss: -1.3359\n",
      "====> Epoch: 43 Average train loss: -1.2987\n",
      "====> Epoch: 43 Average val loss: -1.2966\n",
      "====> Epoch: 44 Average train loss: -1.4320\n",
      "====> Epoch: 44 Average val loss: -1.4049\n",
      "Min loss -1.40\n",
      "====> Epoch: 45 Average train loss: -1.4297\n",
      "====> Epoch: 45 Average val loss: -1.3719\n",
      "====> Epoch: 46 Average train loss: -1.3900\n",
      "====> Epoch: 46 Average val loss: -1.4160\n",
      "Min loss -1.42\n",
      "====> Epoch: 47 Average train loss: -1.4094\n",
      "====> Epoch: 47 Average val loss: -1.4063\n",
      "====> Epoch: 48 Average train loss: -1.4272\n",
      "====> Epoch: 48 Average val loss: -1.4198\n",
      "Min loss -1.42\n",
      "====> Epoch: 49 Average train loss: -1.3373\n",
      "====> Epoch: 49 Average val loss: -1.3366\n",
      "====> Epoch: 50 Average train loss: -1.3213\n",
      "====> Epoch: 50 Average val loss: -1.3334\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "i6Czf36DvLTy"
   },
   "source": [
    "# Deep Canonically Correlated Autoencoders\n",
    "We need to add decoders in order to model deep canonically correlated autoencoders and we also use the DCCAE class which inherits from DCCA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "jphk92IhvLTz",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4982a7e6-e80a-4bef-cd4d-2557d39a8a45"
   },
   "source": [
    "# DCCAE\n",
    "print('DCCAE')\n",
    "encoder_1 = architectures.Encoder(latent_dims=latent_dims, feature_size=784)\n",
    "encoder_2 = architectures.Encoder(latent_dims=latent_dims, feature_size=784)\n",
    "decoder_1 = architectures.Decoder(latent_dims=latent_dims, feature_size=784)\n",
    "decoder_2 = architectures.Decoder(latent_dims=latent_dims, feature_size=784)\n",
    "dccae_model = DCCAE(latent_dims=latent_dims, encoders=[encoder_1, encoder_2], decoders=[decoder_1, decoder_2])\n",
    "\n",
    "dccae_model = CCALightning(dccae_model)\n",
    "trainer = pl.Trainer(max_epochs=epochs, progress_bar_refresh_rate=1, log_every_n_steps=1, logger=False)\n",
    "trainer.fit(dccae_model, train_loader, val_loader)\n",
    "\n",
    "dccae_results = np.stack(\n",
    "    (dccae_model.score(train_dataset), dccae_model.score(test_dataset)))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DCCAE\n",
      "total parameters:  404516\n",
      "====> Epoch: 1 Average train loss: -0.0019\n",
      "====> Epoch: 2 Average train loss: -0.0677\n",
      "====> Epoch: 3 Average train loss: -0.1219\n",
      "====> Epoch: 4 Average train loss: -0.1684\n",
      "====> Epoch: 5 Average train loss: -0.2075\n",
      "====> Epoch: 6 Average train loss: -0.2417\n",
      "====> Epoch: 7 Average train loss: -0.2722\n",
      "====> Epoch: 8 Average train loss: -0.3001\n",
      "====> Epoch: 9 Average train loss: -0.3262\n",
      "====> Epoch: 10 Average train loss: -0.3502\n",
      "====> Epoch: 11 Average train loss: -0.3730\n",
      "====> Epoch: 12 Average train loss: -0.3943\n",
      "====> Epoch: 13 Average train loss: -0.4143\n",
      "====> Epoch: 14 Average train loss: -0.4332\n",
      "====> Epoch: 15 Average train loss: -0.4514\n",
      "====> Epoch: 16 Average train loss: -0.4691\n",
      "====> Epoch: 17 Average train loss: -0.4865\n",
      "====> Epoch: 18 Average train loss: -0.5030\n",
      "====> Epoch: 19 Average train loss: -0.5188\n",
      "====> Epoch: 20 Average train loss: -0.5341\n",
      "====> Epoch: 21 Average train loss: -0.5490\n",
      "====> Epoch: 22 Average train loss: -0.5638\n",
      "====> Epoch: 23 Average train loss: -0.5781\n",
      "====> Epoch: 24 Average train loss: -0.5919\n",
      "====> Epoch: 25 Average train loss: -0.6053\n",
      "====> Epoch: 26 Average train loss: -0.6185\n",
      "====> Epoch: 27 Average train loss: -0.6317\n",
      "====> Epoch: 28 Average train loss: -0.6447\n",
      "====> Epoch: 29 Average train loss: -0.6575\n",
      "====> Epoch: 30 Average train loss: -0.6700\n",
      "====> Epoch: 31 Average train loss: -0.6821\n",
      "====> Epoch: 32 Average train loss: -0.6939\n",
      "====> Epoch: 33 Average train loss: -0.7054\n",
      "====> Epoch: 34 Average train loss: -0.7167\n",
      "====> Epoch: 35 Average train loss: -0.7276\n",
      "====> Epoch: 36 Average train loss: -0.7384\n",
      "====> Epoch: 37 Average train loss: -0.7490\n",
      "====> Epoch: 38 Average train loss: -0.7595\n",
      "====> Epoch: 39 Average train loss: -0.7698\n",
      "====> Epoch: 40 Average train loss: -0.7800\n",
      "====> Epoch: 41 Average train loss: -0.7901\n",
      "====> Epoch: 42 Average train loss: -0.7999\n",
      "====> Epoch: 43 Average train loss: -0.8096\n",
      "====> Epoch: 44 Average train loss: -0.8191\n",
      "====> Epoch: 45 Average train loss: -0.8285\n",
      "====> Epoch: 46 Average train loss: -0.8378\n",
      "====> Epoch: 47 Average train loss: -0.8471\n",
      "====> Epoch: 48 Average train loss: -0.8563\n",
      "====> Epoch: 49 Average train loss: -0.8654\n",
      "====> Epoch: 50 Average train loss: -0.8743\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "WEK3sUSuvLTz"
   },
   "source": [
    "# Deep Variational CCA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "9lqcopiSvLTz",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "484a9a77-0b35-41b7-ddef-6aacbb8be6c0"
   },
   "source": [
    "\"\"\"\n",
    "### Deep Variational Learning\n",
    "Finally we have Deep Variational CCA methods.\n",
    "- Deep Variational CCA (DVCCA)\n",
    "- Deep Variational CCA - private (DVVCA_p)\n",
    "\n",
    "These are both implemented by the DVCCA class with private=True/False and both_encoders=True/False. If both_encoders,\n",
    "the encoder to the shared information Q(z_shared|x) is modelled for both x_1 and x_2 whereas if both_encoders is false\n",
    "it is modelled for x_1 as in the paper\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# DVCCA (technically bi-DVCCA)\n",
    "print('DVCCA')\n",
    "encoder_1 = architectures.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\n",
    "encoder_2 = architectures.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\n",
    "decoder_1 = architectures.Decoder(latent_dims=latent_dims, feature_size=784, norm_output=True)\n",
    "decoder_2 = architectures.Decoder(latent_dims=latent_dims, feature_size=784, norm_output=True)\n",
    "dvcca_model = DVCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2], decoders=[decoder_1, decoder_2])\n",
    "\n",
    "dvcca_model = CCALightning(dvcca_model)\n",
    "trainer = pl.Trainer(max_epochs=epochs, progress_bar_refresh_rate=1, log_every_n_steps=1, logger=False)\n",
    "trainer.fit(dvcca_model, train_loader, val_loader)\n",
    "\n",
    "dvcca_model_results = np.stack(\n",
    "    (dvcca_model.score(train_dataset), dvcca_model.score(test_dataset)))\n",
    "\n",
    "# DVCCA_private (technically bi-DVCCA_private)\n",
    "print('DVCCA_private')\n",
    "encoder_1 = architectures.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\n",
    "encoder_2 = architectures.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\n",
    "private_encoder_1 = architectures.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\n",
    "private_encoder_2 = architectures.Encoder(latent_dims=latent_dims, feature_size=784, variational=True)\n",
    "decoder_1 = architectures.Decoder(latent_dims=latent_dims * 2, feature_size=784, norm_output=True)\n",
    "decoder_2 = architectures.Decoder(latent_dims=latent_dims * 2, feature_size=784, norm_output=True)\n",
    "dvccap_model = DVCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2], decoders=[decoder_1, decoder_2],\n",
    "                           private_encoders=[private_encoder_1, private_encoder_2])\n",
    "\n",
    "dvccap_model = CCALightning(dvccap_model)\n",
    "trainer = pl.Trainer(max_epochs=epochs, progress_bar_refresh_rate=1, log_every_n_steps=1, logger=False)\n",
    "trainer.fit(dvccap_model, train_loader, val_loader)\n",
    "\n",
    "dvccap_model_results = np.stack(\n",
    "    (dvccap_model.score(train_dataset), dvccap_model.score(test_dataset)))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DVCCA\n",
      "total parameters:  405032\n",
      "====> Epoch: 1 Average train loss: 1109.5615\n",
      "====> Epoch: 1 Average val loss: 1106.4091\n",
      "Min loss 1106.41\n",
      "====> Epoch: 2 Average train loss: 1106.5356\n",
      "====> Epoch: 2 Average val loss: 1103.5577\n",
      "Min loss 1103.56\n",
      "====> Epoch: 3 Average train loss: 1103.5905\n",
      "====> Epoch: 3 Average val loss: 1100.6377\n",
      "Min loss 1100.64\n",
      "====> Epoch: 4 Average train loss: 1100.4827\n",
      "====> Epoch: 4 Average val loss: 1097.5350\n",
      "Min loss 1097.54\n",
      "====> Epoch: 5 Average train loss: 1097.5166\n",
      "====> Epoch: 5 Average val loss: 1094.5754\n",
      "Min loss 1094.58\n",
      "====> Epoch: 6 Average train loss: 1094.8094\n",
      "====> Epoch: 6 Average val loss: 1091.9133\n",
      "Min loss 1091.91\n",
      "====> Epoch: 7 Average train loss: 1092.1809\n",
      "====> Epoch: 7 Average val loss: 1089.2421\n",
      "Min loss 1089.24\n",
      "====> Epoch: 8 Average train loss: 1089.0867\n",
      "====> Epoch: 8 Average val loss: 1086.4995\n",
      "Min loss 1086.50\n",
      "====> Epoch: 9 Average train loss: 1086.4094\n",
      "====> Epoch: 9 Average val loss: 1083.7737\n",
      "Min loss 1083.77\n",
      "====> Epoch: 10 Average train loss: 1083.9321\n",
      "====> Epoch: 10 Average val loss: 1081.5156\n",
      "Min loss 1081.52\n",
      "====> Epoch: 11 Average train loss: 1081.5007\n",
      "====> Epoch: 11 Average val loss: 1078.8384\n",
      "Min loss 1078.84\n",
      "====> Epoch: 12 Average train loss: 1078.7391\n",
      "====> Epoch: 12 Average val loss: 1076.0708\n",
      "Min loss 1076.07\n",
      "====> Epoch: 13 Average train loss: 1076.5303\n",
      "====> Epoch: 13 Average val loss: 1073.5686\n",
      "Min loss 1073.57\n",
      "====> Epoch: 14 Average train loss: 1073.3767\n",
      "====> Epoch: 14 Average val loss: 1071.1628\n",
      "Min loss 1071.16\n",
      "====> Epoch: 15 Average train loss: 1071.1952\n",
      "====> Epoch: 15 Average val loss: 1068.8904\n",
      "Min loss 1068.89\n",
      "====> Epoch: 16 Average train loss: 1069.1177\n",
      "====> Epoch: 16 Average val loss: 1066.5808\n",
      "Min loss 1066.58\n",
      "====> Epoch: 17 Average train loss: 1066.5830\n",
      "====> Epoch: 17 Average val loss: 1064.4114\n",
      "Min loss 1064.41\n",
      "====> Epoch: 18 Average train loss: 1063.8755\n",
      "====> Epoch: 18 Average val loss: 1061.8417\n",
      "Min loss 1061.84\n",
      "====> Epoch: 19 Average train loss: 1062.0535\n",
      "====> Epoch: 19 Average val loss: 1059.6287\n",
      "Min loss 1059.63\n",
      "====> Epoch: 20 Average train loss: 1059.5776\n",
      "====> Epoch: 20 Average val loss: 1057.6716\n",
      "Min loss 1057.67\n",
      "====> Epoch: 21 Average train loss: 1057.6267\n",
      "====> Epoch: 21 Average val loss: 1055.5505\n",
      "Min loss 1055.55\n",
      "====> Epoch: 22 Average train loss: 1055.3225\n",
      "====> Epoch: 22 Average val loss: 1053.0654\n",
      "Min loss 1053.07\n",
      "====> Epoch: 23 Average train loss: 1053.1990\n",
      "====> Epoch: 23 Average val loss: 1051.1343\n",
      "Min loss 1051.13\n",
      "====> Epoch: 24 Average train loss: 1051.1526\n",
      "====> Epoch: 24 Average val loss: 1049.0571\n",
      "Min loss 1049.06\n",
      "====> Epoch: 25 Average train loss: 1048.9647\n",
      "====> Epoch: 25 Average val loss: 1046.9143\n",
      "Min loss 1046.91\n",
      "====> Epoch: 26 Average train loss: 1047.0123\n",
      "====> Epoch: 26 Average val loss: 1044.8156\n",
      "Min loss 1044.82\n",
      "====> Epoch: 27 Average train loss: 1044.7405\n",
      "====> Epoch: 27 Average val loss: 1043.0496\n",
      "Min loss 1043.05\n",
      "====> Epoch: 28 Average train loss: 1043.0582\n",
      "====> Epoch: 28 Average val loss: 1041.3112\n",
      "Min loss 1041.31\n",
      "====> Epoch: 29 Average train loss: 1041.1470\n",
      "====> Epoch: 29 Average val loss: 1039.2390\n",
      "Min loss 1039.24\n",
      "====> Epoch: 30 Average train loss: 1039.4268\n",
      "====> Epoch: 30 Average val loss: 1037.7975\n",
      "Min loss 1037.80\n",
      "====> Epoch: 31 Average train loss: 1037.5386\n",
      "====> Epoch: 31 Average val loss: 1035.5798\n",
      "Min loss 1035.58\n",
      "====> Epoch: 32 Average train loss: 1035.8229\n",
      "====> Epoch: 32 Average val loss: 1033.9326\n",
      "Min loss 1033.93\n",
      "====> Epoch: 33 Average train loss: 1033.8650\n",
      "====> Epoch: 33 Average val loss: 1031.8835\n",
      "Min loss 1031.88\n",
      "====> Epoch: 34 Average train loss: 1032.1606\n",
      "====> Epoch: 34 Average val loss: 1030.4136\n",
      "Min loss 1030.41\n",
      "====> Epoch: 35 Average train loss: 1030.4910\n",
      "====> Epoch: 35 Average val loss: 1028.5079\n",
      "Min loss 1028.51\n",
      "====> Epoch: 36 Average train loss: 1028.8259\n",
      "====> Epoch: 36 Average val loss: 1026.8826\n",
      "Min loss 1026.88\n",
      "====> Epoch: 37 Average train loss: 1027.3547\n",
      "====> Epoch: 37 Average val loss: 1025.3986\n",
      "Min loss 1025.40\n",
      "====> Epoch: 38 Average train loss: 1025.0544\n",
      "====> Epoch: 38 Average val loss: 1023.9811\n",
      "Min loss 1023.98\n",
      "====> Epoch: 39 Average train loss: 1024.1343\n",
      "====> Epoch: 39 Average val loss: 1021.9122\n",
      "Min loss 1021.91\n",
      "====> Epoch: 40 Average train loss: 1022.0138\n",
      "====> Epoch: 40 Average val loss: 1019.9561\n",
      "Min loss 1019.96\n",
      "====> Epoch: 41 Average train loss: 1020.5950\n",
      "====> Epoch: 41 Average val loss: 1019.5484\n",
      "Min loss 1019.55\n",
      "====> Epoch: 42 Average train loss: 1018.7665\n",
      "====> Epoch: 42 Average val loss: 1017.3838\n",
      "Min loss 1017.38\n",
      "====> Epoch: 43 Average train loss: 1017.5677\n",
      "====> Epoch: 43 Average val loss: 1016.0297\n",
      "Min loss 1016.03\n",
      "====> Epoch: 44 Average train loss: 1016.1881\n",
      "====> Epoch: 44 Average val loss: 1014.4371\n",
      "Min loss 1014.44\n",
      "====> Epoch: 45 Average train loss: 1014.6393\n",
      "====> Epoch: 45 Average val loss: 1013.1492\n",
      "Min loss 1013.15\n",
      "====> Epoch: 46 Average train loss: 1013.3342\n",
      "====> Epoch: 46 Average val loss: 1012.0658\n",
      "Min loss 1012.07\n",
      "====> Epoch: 47 Average train loss: 1011.7484\n",
      "====> Epoch: 47 Average val loss: 1010.7506\n",
      "Min loss 1010.75\n",
      "====> Epoch: 48 Average train loss: 1010.6251\n",
      "====> Epoch: 48 Average val loss: 1008.8579\n",
      "Min loss 1008.86\n",
      "====> Epoch: 49 Average train loss: 1009.0502\n",
      "====> Epoch: 49 Average val loss: 1007.8226\n",
      "Min loss 1007.82\n",
      "====> Epoch: 50 Average train loss: 1007.1901\n",
      "====> Epoch: 50 Average val loss: 1005.9260\n",
      "Min loss 1005.93\n",
      "DVCCA_private\n",
      "total parameters:  607536\n",
      "====> Epoch: 1 Average train loss: 1111.1758\n",
      "====> Epoch: 1 Average val loss: 1108.3516\n",
      "Min loss 1108.35\n",
      "====> Epoch: 2 Average train loss: 1108.4519\n",
      "====> Epoch: 2 Average val loss: 1105.1642\n",
      "Min loss 1105.16\n",
      "====> Epoch: 3 Average train loss: 1105.5024\n",
      "====> Epoch: 3 Average val loss: 1102.2720\n",
      "Min loss 1102.27\n",
      "====> Epoch: 4 Average train loss: 1102.6145\n",
      "====> Epoch: 4 Average val loss: 1099.6088\n",
      "Min loss 1099.61\n",
      "====> Epoch: 5 Average train loss: 1099.9021\n",
      "====> Epoch: 5 Average val loss: 1097.1158\n",
      "Min loss 1097.12\n",
      "====> Epoch: 6 Average train loss: 1097.0347\n",
      "====> Epoch: 6 Average val loss: 1094.3152\n",
      "Min loss 1094.32\n",
      "====> Epoch: 7 Average train loss: 1094.4141\n",
      "====> Epoch: 7 Average val loss: 1091.6289\n",
      "Min loss 1091.63\n",
      "====> Epoch: 8 Average train loss: 1091.6658\n",
      "====> Epoch: 8 Average val loss: 1088.9984\n",
      "Min loss 1089.00\n",
      "====> Epoch: 9 Average train loss: 1089.0031\n",
      "====> Epoch: 9 Average val loss: 1086.1648\n",
      "Min loss 1086.16\n",
      "====> Epoch: 10 Average train loss: 1086.3365\n",
      "====> Epoch: 10 Average val loss: 1083.7288\n",
      "Min loss 1083.73\n",
      "====> Epoch: 11 Average train loss: 1083.8301\n",
      "====> Epoch: 11 Average val loss: 1081.3557\n",
      "Min loss 1081.36\n",
      "====> Epoch: 12 Average train loss: 1081.5806\n",
      "====> Epoch: 12 Average val loss: 1078.7136\n",
      "Min loss 1078.71\n",
      "====> Epoch: 13 Average train loss: 1078.9102\n",
      "====> Epoch: 13 Average val loss: 1076.4788\n",
      "Min loss 1076.48\n",
      "====> Epoch: 14 Average train loss: 1076.6189\n",
      "====> Epoch: 14 Average val loss: 1074.0825\n",
      "Min loss 1074.08\n",
      "====> Epoch: 15 Average train loss: 1074.3435\n",
      "====> Epoch: 15 Average val loss: 1071.4995\n",
      "Min loss 1071.50\n",
      "====> Epoch: 16 Average train loss: 1072.0078\n",
      "====> Epoch: 16 Average val loss: 1069.3938\n",
      "Min loss 1069.39\n",
      "====> Epoch: 17 Average train loss: 1069.2450\n",
      "====> Epoch: 17 Average val loss: 1067.1929\n",
      "Min loss 1067.19\n",
      "====> Epoch: 18 Average train loss: 1067.4008\n",
      "====> Epoch: 18 Average val loss: 1064.8755\n",
      "Min loss 1064.88\n",
      "====> Epoch: 19 Average train loss: 1065.0360\n",
      "====> Epoch: 19 Average val loss: 1062.5830\n",
      "Min loss 1062.58\n",
      "====> Epoch: 20 Average train loss: 1062.9507\n",
      "====> Epoch: 20 Average val loss: 1060.5204\n",
      "Min loss 1060.52\n",
      "====> Epoch: 21 Average train loss: 1060.8132\n",
      "====> Epoch: 21 Average val loss: 1058.4624\n",
      "Min loss 1058.46\n",
      "====> Epoch: 22 Average train loss: 1058.6918\n",
      "====> Epoch: 22 Average val loss: 1056.5654\n",
      "Min loss 1056.57\n",
      "====> Epoch: 23 Average train loss: 1056.6611\n",
      "====> Epoch: 23 Average val loss: 1054.4075\n",
      "Min loss 1054.41\n",
      "====> Epoch: 24 Average train loss: 1054.8269\n",
      "====> Epoch: 24 Average val loss: 1052.1930\n",
      "Min loss 1052.19\n",
      "====> Epoch: 25 Average train loss: 1052.5613\n",
      "====> Epoch: 25 Average val loss: 1050.3650\n",
      "Min loss 1050.36\n",
      "====> Epoch: 26 Average train loss: 1050.4044\n",
      "====> Epoch: 26 Average val loss: 1048.1295\n",
      "Min loss 1048.13\n",
      "====> Epoch: 27 Average train loss: 1048.4557\n",
      "====> Epoch: 27 Average val loss: 1046.2268\n",
      "Min loss 1046.23\n",
      "====> Epoch: 28 Average train loss: 1046.7646\n",
      "====> Epoch: 28 Average val loss: 1044.4366\n",
      "Min loss 1044.44\n",
      "====> Epoch: 29 Average train loss: 1044.8062\n",
      "====> Epoch: 29 Average val loss: 1042.5750\n",
      "Min loss 1042.57\n",
      "====> Epoch: 30 Average train loss: 1042.6490\n",
      "====> Epoch: 30 Average val loss: 1040.4587\n",
      "Min loss 1040.46\n",
      "====> Epoch: 31 Average train loss: 1040.9629\n",
      "====> Epoch: 31 Average val loss: 1038.8336\n",
      "Min loss 1038.83\n",
      "====> Epoch: 32 Average train loss: 1038.8879\n",
      "====> Epoch: 32 Average val loss: 1036.8384\n",
      "Min loss 1036.84\n",
      "====> Epoch: 33 Average train loss: 1037.3240\n",
      "====> Epoch: 33 Average val loss: 1035.5549\n",
      "Min loss 1035.55\n",
      "====> Epoch: 34 Average train loss: 1035.4932\n",
      "====> Epoch: 34 Average val loss: 1033.6082\n",
      "Min loss 1033.61\n",
      "====> Epoch: 35 Average train loss: 1033.9220\n",
      "====> Epoch: 35 Average val loss: 1031.9670\n",
      "Min loss 1031.97\n",
      "====> Epoch: 36 Average train loss: 1032.3682\n",
      "====> Epoch: 36 Average val loss: 1030.0439\n",
      "Min loss 1030.04\n",
      "====> Epoch: 37 Average train loss: 1030.5251\n",
      "====> Epoch: 37 Average val loss: 1028.3313\n",
      "Min loss 1028.33\n",
      "====> Epoch: 38 Average train loss: 1028.4504\n",
      "====> Epoch: 38 Average val loss: 1026.9329\n",
      "Min loss 1026.93\n",
      "====> Epoch: 39 Average train loss: 1027.0562\n",
      "====> Epoch: 39 Average val loss: 1025.2065\n",
      "Min loss 1025.21\n",
      "====> Epoch: 40 Average train loss: 1025.8102\n",
      "====> Epoch: 40 Average val loss: 1023.5693\n",
      "Min loss 1023.57\n",
      "====> Epoch: 41 Average train loss: 1023.5449\n",
      "====> Epoch: 41 Average val loss: 1022.0502\n",
      "Min loss 1022.05\n",
      "====> Epoch: 42 Average train loss: 1022.1390\n",
      "====> Epoch: 42 Average val loss: 1020.6116\n",
      "Min loss 1020.61\n",
      "====> Epoch: 43 Average train loss: 1020.8058\n",
      "====> Epoch: 43 Average val loss: 1019.0730\n",
      "Min loss 1019.07\n",
      "====> Epoch: 44 Average train loss: 1019.7094\n",
      "====> Epoch: 44 Average val loss: 1018.3165\n",
      "Min loss 1018.32\n",
      "====> Epoch: 45 Average train loss: 1017.3981\n",
      "====> Epoch: 45 Average val loss: 1016.1403\n",
      "Min loss 1016.14\n",
      "====> Epoch: 46 Average train loss: 1016.0779\n",
      "====> Epoch: 46 Average val loss: 1014.8041\n",
      "Min loss 1014.80\n",
      "====> Epoch: 47 Average train loss: 1014.8489\n",
      "====> Epoch: 47 Average val loss: 1013.4117\n",
      "Min loss 1013.41\n",
      "====> Epoch: 48 Average train loss: 1013.5171\n",
      "====> Epoch: 48 Average val loss: 1011.6441\n",
      "Min loss 1011.64\n",
      "====> Epoch: 49 Average train loss: 1012.0751\n",
      "====> Epoch: 49 Average val loss: 1010.4889\n",
      "Min loss 1010.49\n",
      "====> Epoch: 50 Average train loss: 1011.1703\n",
      "====> Epoch: 50 Average val loss: 1009.1624\n",
      "Min loss 1009.16\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "-li2xlrmvLT0"
   },
   "source": [
    "# Convolutional Deep CCA (and using other architectures)\n",
    "We provide a standard CNN encoder and decoder but users can build their own encoders and decoders by inheriting BaseEncoder and BaseDecoder for seamless integration with the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "AzfBwb3NvLT0",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "93bed1b4-1d78-40b8-c505-6caad6375276"
   },
   "source": [
    "print('Convolutional DCCA')\n",
    "encoder_1 = architectures.CNNEncoder(latent_dims=latent_dims, channels=[3, 3])\n",
    "encoder_2 = architectures.CNNEncoder(latent_dims=latent_dims, channels=[3, 3])\n",
    "dcca_conv_model = DCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2])\n",
    "\n",
    "conv_train_view_1=train_view_1.reshape((-1, 1, 28, 28))\n",
    "conv_train_view_2=train_view_2.reshape((-1, 1, 28, 28))\n",
    "conv_test_view_1=test_view_1.reshape((-1, 1, 28, 28))\n",
    "conv_test_view_2=test_view_2.reshape((-1, 1, 28, 28))\n",
    "conv_dataset=CCA_Dataset((conv_train_view_1,conv_train_view_2))\n",
    "test_conv_dataset=CCA_Dataset((conv_test_view_1,conv_test_view_2))\n",
    "conv_train_loader=get_dataloaders(conv_dataset)\n",
    "conv_test_loader=get_dataloaders(test_conv_dataset)\n",
    "\n",
    "dcca_conv_model = CCALightning(dcca_conv_model)\n",
    "trainer = pl.Trainer(max_epochs=epochs, progress_bar_refresh_rate=1, log_every_n_steps=1, logger=False)\n",
    "trainer.fit(dcca_conv_model, train_loader)\n",
    "\n",
    "dcca_conv_results = np.stack((\n",
    "    dcca_conv_model.score(conv_train_loader),\n",
    "    dcca_conv_model.score(conv_test_loader)))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Convolutional DCCA\n",
      "total parameters:  9568\n",
      "====> Epoch: 1 Average train loss: -0.6154\n",
      "====> Epoch: 2 Average train loss: -0.7844\n",
      "====> Epoch: 3 Average train loss: -0.9141\n",
      "====> Epoch: 4 Average train loss: -1.0193\n",
      "====> Epoch: 5 Average train loss: -1.1371\n",
      "====> Epoch: 6 Average train loss: -1.2470\n",
      "====> Epoch: 7 Average train loss: -1.3430\n",
      "====> Epoch: 8 Average train loss: -1.4286\n",
      "====> Epoch: 9 Average train loss: -1.4995\n",
      "====> Epoch: 10 Average train loss: -1.5591\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "78IxzigYvLT0"
   },
   "source": [
    "# DTCCA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "MHvAzaiGvLT1",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2fd16f5f-0579-44c6-acc0-1f66a450ba40"
   },
   "source": [
    "# %%\n",
    "# DTCCA\n",
    "print('DTCCA')\n",
    "encoder_1 = architectures.Encoder(latent_dims=latent_dims, feature_size=784)\n",
    "encoder_2 = architectures.Encoder(latent_dims=latent_dims, feature_size=784)\n",
    "dtcca_model = DTCCA(latent_dims=latent_dims, encoders=[encoder_1, encoder_2])\n",
    "\n",
    "dtcca_model = CCALightning(dtcca_model)\n",
    "trainer = pl.Trainer(max_epochs=epochs, progress_bar_refresh_rate=1, log_every_n_steps=1, logger=False)\n",
    "trainer.fit(dtcca_model, train_loader, val_loader)\n",
    "\n",
    "dtcca_results = np.stack((dtcca_model.score(train_dataset), dtcca_model.score(test_dataset)))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DTCCA\n",
      "total parameters:  201476\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorly/backend/core.py:885: UserWarning: In partial_svd: converting to NumPy. Check SVD_FUNS for available alternatives if you want to avoid this.\n",
      "  warnings.warn('In partial_svd: converting to NumPy.'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "====> Epoch: 1 Average train loss: 0.0000\n",
      "====> Epoch: 1 Average val loss: 0.0000\n",
      "Min loss 0.00\n",
      "====> Epoch: 2 Average train loss: 0.0000\n",
      "====> Epoch: 2 Average val loss: 0.0000\n",
      "Min loss 0.00\n",
      "====> Epoch: 3 Average train loss: 0.0000\n",
      "====> Epoch: 3 Average val loss: 0.0000\n",
      "====> Epoch: 4 Average train loss: 0.0000\n",
      "====> Epoch: 4 Average val loss: 0.0000\n",
      "====> Epoch: 5 Average train loss: 0.0000\n",
      "====> Epoch: 5 Average val loss: 0.0000\n",
      "====> Epoch: 6 Average train loss: 0.0000\n",
      "====> Epoch: 6 Average val loss: 0.0000\n",
      "====> Epoch: 7 Average train loss: 0.0000\n",
      "====> Epoch: 7 Average val loss: 0.0000\n",
      "====> Epoch: 8 Average train loss: 0.0000\n",
      "====> Epoch: 8 Average val loss: 0.0000\n",
      "====> Epoch: 9 Average train loss: 0.0000\n",
      "====> Epoch: 9 Average val loss: 0.0000\n",
      "====> Epoch: 10 Average train loss: 0.0000\n",
      "====> Epoch: 10 Average val loss: 0.0000\n",
      "====> Epoch: 11 Average train loss: 0.0000\n",
      "====> Epoch: 11 Average val loss: 0.0000\n",
      "====> Epoch: 12 Average train loss: 0.0000\n",
      "====> Epoch: 12 Average val loss: 0.0000\n",
      "====> Epoch: 13 Average train loss: 0.0000\n",
      "====> Epoch: 13 Average val loss: 0.0000\n",
      "====> Epoch: 14 Average train loss: 0.0000\n",
      "====> Epoch: 14 Average val loss: 0.0000\n",
      "====> Epoch: 15 Average train loss: 0.0000\n",
      "====> Epoch: 15 Average val loss: 0.0000\n",
      "====> Epoch: 16 Average train loss: 0.0000\n",
      "====> Epoch: 16 Average val loss: 0.0000\n",
      "====> Epoch: 17 Average train loss: 0.0000\n",
      "====> Epoch: 17 Average val loss: 0.0000\n",
      "====> Epoch: 18 Average train loss: 0.0000\n",
      "====> Epoch: 18 Average val loss: 0.0000\n",
      "====> Epoch: 19 Average train loss: 0.0000\n",
      "====> Epoch: 19 Average val loss: 0.0000\n",
      "====> Epoch: 20 Average train loss: 0.0000\n",
      "====> Epoch: 20 Average val loss: 0.0000\n",
      "====> Epoch: 21 Average train loss: 0.0000\n",
      "====> Epoch: 21 Average val loss: 0.0000\n",
      "====> Epoch: 22 Average train loss: 0.0000\n",
      "====> Epoch: 22 Average val loss: 0.0000\n",
      "====> Epoch: 23 Average train loss: 0.0000\n",
      "====> Epoch: 23 Average val loss: 0.0000\n",
      "====> Epoch: 24 Average train loss: 0.0000\n",
      "====> Epoch: 24 Average val loss: 0.0000\n",
      "====> Epoch: 25 Average train loss: 0.0000\n",
      "====> Epoch: 25 Average val loss: 0.0000\n",
      "====> Epoch: 26 Average train loss: 0.0000\n",
      "====> Epoch: 26 Average val loss: 0.0000\n",
      "====> Epoch: 27 Average train loss: 0.0000\n",
      "====> Epoch: 27 Average val loss: 0.0000\n",
      "====> Epoch: 28 Average train loss: 0.0000\n",
      "====> Epoch: 28 Average val loss: 0.0000\n",
      "====> Epoch: 29 Average train loss: 0.0000\n",
      "====> Epoch: 29 Average val loss: 0.0000\n",
      "====> Epoch: 30 Average train loss: 0.0000\n",
      "====> Epoch: 30 Average val loss: 0.0000\n",
      "====> Epoch: 31 Average train loss: 0.0000\n",
      "====> Epoch: 31 Average val loss: 0.0000\n",
      "====> Epoch: 32 Average train loss: 0.0000\n",
      "====> Epoch: 32 Average val loss: 0.0000\n",
      "====> Epoch: 33 Average train loss: 0.0000\n",
      "====> Epoch: 33 Average val loss: 0.0000\n",
      "====> Epoch: 34 Average train loss: 0.0000\n",
      "====> Epoch: 34 Average val loss: 0.0000\n",
      "====> Epoch: 35 Average train loss: 0.0000\n",
      "====> Epoch: 35 Average val loss: 0.0000\n",
      "====> Epoch: 36 Average train loss: 0.0000\n",
      "====> Epoch: 36 Average val loss: 0.0000\n",
      "====> Epoch: 37 Average train loss: 0.0000\n",
      "====> Epoch: 37 Average val loss: 0.0000\n",
      "====> Epoch: 38 Average train loss: 0.0000\n",
      "====> Epoch: 38 Average val loss: 0.0000\n",
      "====> Epoch: 39 Average train loss: 0.0000\n",
      "====> Epoch: 39 Average val loss: 0.0000\n",
      "====> Epoch: 40 Average train loss: 0.0000\n",
      "====> Epoch: 40 Average val loss: 0.0000\n",
      "====> Epoch: 41 Average train loss: 0.0000\n",
      "====> Epoch: 41 Average val loss: 0.0000\n",
      "====> Epoch: 42 Average train loss: 0.0000\n",
      "====> Epoch: 42 Average val loss: 0.0000\n",
      "====> Epoch: 43 Average train loss: 0.0000\n",
      "====> Epoch: 43 Average val loss: 0.0000\n",
      "====> Epoch: 44 Average train loss: 0.0000\n",
      "====> Epoch: 44 Average val loss: 0.0000\n",
      "====> Epoch: 45 Average train loss: 0.0000\n",
      "====> Epoch: 45 Average val loss: 0.0000\n",
      "====> Epoch: 46 Average train loss: 0.0000\n",
      "====> Epoch: 46 Average val loss: 0.0000\n",
      "====> Epoch: 47 Average train loss: 0.0000\n",
      "====> Epoch: 47 Average val loss: 0.0000\n",
      "====> Epoch: 48 Average train loss: 0.0000\n",
      "====> Epoch: 48 Average val loss: 0.0000\n",
      "====> Epoch: 49 Average train loss: 0.0000\n",
      "====> Epoch: 49 Average val loss: 0.0000\n",
      "====> Epoch: 50 Average train loss: 0.0000\n",
      "====> Epoch: 50 Average val loss: 0.0000\n",
      "reconstruction error=1.7372686071707115e-08\n",
      "iteration 1, reconstruction error: 1.7372686071707115e-08, decrease = 0.0, unnormalized = 2.634178031930877e-09\n",
      "PARAFAC converged after 1 iterations\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4PLCBruxlAAu"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}